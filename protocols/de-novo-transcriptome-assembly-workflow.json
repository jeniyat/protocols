{"uri":"de-novo-transcriptome-assembly-workflow-ghebt3e","version_id":"0","protocol_name":"De novo transcriptome assembly workflow","protocol_name_html":"De novo transcriptome assembly workflow","is_prepublished":"0","can_edit":"0","parent_id":null,"api_version":"2","is_new_mode":"1","last_modified":"1527161921","type_id":"1","link":"https:\/\/dx.doi.org\/10.1038\/s41598-017-09334-7","fork_id":"","public_fork_note":"","number_of_steps":"21","has_versions":"0","first_published_date":"1488795656","publish_date":"2017-03-06 10:20:56","documents":null,"have_protocol_in_step":"0","is_protocol_in_step":"0","vendor_name":"Contributed by users","vendor_link":"https:\/\/www.protocols.io","vendor_logo":"\/img\/vendors\/1.png","mod_mins":"-28","mod_secs":"29","description":"<p><span style=\"font-weight: 400;\">This protocol describes\u00a0the production of\u00a0a reference-quality\u00a0<em>de novo<\/em>\u00a0transcriptome assembly for the spiny mouse (<em>Acomys cahirinus<\/em>).<\/span><span style=\"font-weight: 400;\">\u00a0These methods can be applied to other RNA-Seq datasets to generate high-quality transcriptome assemblies in other species.\u00a0V<\/span>alidation and description of assembly output is described in 'De novo transcriptome assembly for the spiny mouse (<em>Acomys cahirinus<\/em>)'\u00a0<em>bioRxiv<\/em>, p.076067.<\/p>","is_bookmarked":"1","can_reassign":"1","before_start":"","has_guidelines":"0","materials":[],"warning":"","version_class":"4358","public":"1","is_owner":"1","is_original_owner":"1","created_on":"1479880283","protocol_affiliation":"Hudson Institute of Medical Research","affiliation":"Hudson Institute of Medical Research","doi":"dx.doi.org\/10.17504\/protocols.io.ghebt3e","doi_status":"2","changed_fork_steps":null,"profile_url":"JaredMamrot-w20344z2w2","protocol_img":"https:\/\/s3.amazonaws.com\/pr-journal\/inzef86.png","profile_image":"https:\/\/s3.amazonaws.com\/pr-journal\/d4bef86.jpg","full_name":"Jared Mamrot","created_by":"Jared Mamrot","private_link":"D5BC9ACFF788B1CC222B223090F51504","original_img":"1","username":"jared-mamrot","is_retracted":"0","retraction_reason":null,"plos_id":null,"manuscript_citation":"Mamrot J,  Legaie R,  Ellery SJ,  Wilson T,  Seemann T,  Powell DR,  Gardner DK,  Walker DW,  Temple-Smith P,  Papenfuss AT,  Dickinson H, Array. Scientific Reports  doi: <a target=\"_blank\" href=\"https:\/\/dx.doi.org\/10.1038\/s41598-017-09334-7\">10.1038\/s41598-017-09334-7<\/a> ","journal_name":"Scientific Reports","is_donations_disabled":"0","is_donations_disabled_by_user":"9","item_record_id":229859,"fork_info":[],"compare_forks":[],"protocols":[],"groups":[],"number_of_shared_runs":[],"ownership_history":[],"keywords":"de novo, transcriptome assembly, Trinity, SOAPdenovo-Trans, Velvet, Oases, transfuse, EvidentialGene, tr2aacds, BUSCO, computational pipeline","transfer_to_user":[],"sub_transfer":false,"is_transfer_pending":false,"number_of_bookmarks":"20","collections":[],"tags":[{"tag_id":"502","tag_name":"de novo transcriptome assembly"}],"archived":0,"sub_authors":[],"sub_protocols_number":0,"can_edit_shared":0,"shared_runs":[],"is_shared_run":0,"is_shared":1,"banner":null,"contact_badges":[{"badge_id":"1","badge_image":"\/img\/ambassador.svg","badge_description":"Ambassador"},{"badge_id":"2","badge_image":"\/img\/badges\/bronze.svg","badge_description":"Author!"},{"badge_id":"5","badge_image":"\/img\/badges\/earlyadopter.svg","badge_description":"Early adopter"},{"badge_id":"6","badge_image":"\/img\/badges\/socialbutterfly.svg","badge_description":"Social butterfly"}],"number_of_comments":10,"big_protocol_img":"https:\/\/s3.amazonaws.com\/pr-journal\/inyef86.png","big_protocol_img_ofn":"trinity_bandage_inverted_laptop.png","is_locked":0,"is_locked_by":false,"authors":"Jared Mamrot, Roxane Legaie, Stacey J Ellery, Trevor Wilson, Torsten Seemann, David Gardner, David W Walker, Peter Temple-Smith, Anthony T Papenfuss, Hayley Dickinson","authors_list":[{"name":"Jared Mamrot","affiliation":"Hudson Institute of Medical Research","username":null,"profile_image":null},{"name":" Roxane Legaie","affiliation":"Hudson Institute of Medical Research","username":null,"profile_image":null},{"name":" Stacey J Ellery","affiliation":"Hudson Institute of Medical Research","username":null,"profile_image":null},{"name":" Trevor Wilson","affiliation":"Hudson Institute of Medical Research","username":null,"profile_image":null},{"name":" Torsten Seemann","affiliation":"Hudson Institute of Medical Research","username":null,"profile_image":null},{"name":" David Gardner","affiliation":"Hudson Institute of Medical Research","username":null,"profile_image":null},{"name":" David W Walker","affiliation":"Hudson Institute of Medical Research","username":null,"profile_image":null},{"name":" Peter Temple-Smith","affiliation":"Hudson Institute of Medical Research","username":null,"profile_image":null},{"name":" Anthony T Papenfuss","affiliation":"Hudson Institute of Medical Research","username":null,"profile_image":null},{"name":" Hayley Dickinson","affiliation":"Hudson Institute of Medical Research","username":null,"profile_image":null}],"user":{"profile_image":"https:\/\/s3.amazonaws.com\/pr-journal\/d4bef86.jpg","username":"jared-mamrot","full_name":"Jared Mamrot","created_by":"Jared Mamrot"},"access":{"can_view":"1","can_remove":"0","can_add":"0","can_edit":0,"can_publish":0,"can_get_doi":0,"can_share":"0","can_move":"1","can_transfer":"1","can_download":"1","is_locked":"0"},"is_contact_suspended":0,"guidelines":"","status_id":"1","is_research":"1","status_info":null,"steps":[{"id":"192073","is_changed":"0","original_id":"0","is_skipped":"0","is_checked":"0","guid":"1BC9259501E445C1815CCC019D6ACEB7","previous_guid":null,"previous_id":"0","last_modified":"1488675760","components":[{"component_id":"235265","previous_id":0,"original_id":"0","guid":"85489434027D4376897B93A5A5D554A4","previous_guid":null,"component_type_id":"1","data_id":"0","data":"<p>Download\u00a0raw data from the NCBI to working directory and archive a copy (read-only). To efficiently transfer data\u00a0the NCBI recommends using Aspera connect, a FASP\u00ae\u00a0transfer program which facilitates high-speed data transfer.<\/p>\n<p>\u00a0<\/p>\n<p>Many commands in this protocol take hours\/days to complete: to avoid processes being killed if connection to the server is lost,\u00a0employ the 'nohup' command and\/or run processes\u00a0in the background ('&amp;') and disown them from the terminal ('disown %1'). Where possible, follow\u00a0good scientific practices eg. Wilson, G., Bryan, J., Cranston, K., Kitzes, J., Nederbragt, L. and Teal, T.K., 2016. Good Enough Practices in Scientific Computing. <em>arXiv preprint <a href=\"https:\/\/arxiv.org\/abs\/1609.00037\" target=\"_blank\">arXiv:1609.00037<\/a><\/em>.<\/p>\n<p>\u00a0<\/p>\n<p>Aspera connect:<br \/>Download - <a href=\"http:\/\/downloads.asperasoft.com\/en\/downloads\/8?list\" target=\"_blank\">http:\/\/downloads.asperasoft.com\/en\/downloads\/8?list<\/a>\u00a0(ver3.6.2)<\/p>\n<p>Documentation - <a href=\"https:\/\/www.ncbi.nlm.nih.gov\/books\/NBK242625\/\" target=\"_blank\">https:\/\/www.ncbi.nlm.nih.gov\/books\/NBK242625\/<\/a><br \/>Requirements - NCBI SRA toolkit<\/p>\n<p>\u00a0<\/p>\n<p>NCBI SRA toolkit:<br \/>Download - <a href=\"https:\/\/trace.ncbi.nlm.nih.gov\/Traces\/sra\/sra.cgi?view=software\" target=\"_blank\">https:\/\/trace.ncbi.nlm.nih.gov\/Traces\/sra\/sra.cgi?view=software<\/a> (ver2.8.1-3)<br \/>Documentation - <a href=\"https:\/\/trace.ncbi.nlm.nih.gov\/Traces\/sra\/sra.cgi?view=toolkit_doc\" target=\"_blank\">https:\/\/trace.ncbi.nlm.nih.gov\/Traces\/sra\/sra.cgi?view=toolkit_doc<\/a><\/p>\n<p>\u00a0<\/p>","order_id":"0","name":"Description","data_by_id":"0","type_id":"1","source_data":{"description":"<p>Download\u00a0raw data from the NCBI to working directory and archive a copy (read-only). To efficiently transfer data\u00a0the NCBI recommends using Aspera connect, a FASP\u00ae\u00a0transfer program which facilitates high-speed data transfer.<\/p>\n<p>\u00a0<\/p>\n<p>Many commands in this protocol take hours\/days to complete: to avoid processes being killed if connection to the server is lost,\u00a0employ the 'nohup' command and\/or run processes\u00a0in the background ('&amp;') and disown them from the terminal ('disown %1'). Where possible, follow\u00a0good scientific practices eg. Wilson, G., Bryan, J., Cranston, K., Kitzes, J., Nederbragt, L. and Teal, T.K., 2016. Good Enough Practices in Scientific Computing. <em>arXiv preprint <a href=\"https:\/\/arxiv.org\/abs\/1609.00037\" target=\"_blank\">arXiv:1609.00037<\/a><\/em>.<\/p>\n<p>\u00a0<\/p>\n<p>Aspera connect:<br \/>Download - <a href=\"http:\/\/downloads.asperasoft.com\/en\/downloads\/8?list\" target=\"_blank\">http:\/\/downloads.asperasoft.com\/en\/downloads\/8?list<\/a>\u00a0(ver3.6.2)<\/p>\n<p>Documentation - <a href=\"https:\/\/www.ncbi.nlm.nih.gov\/books\/NBK242625\/\" target=\"_blank\">https:\/\/www.ncbi.nlm.nih.gov\/books\/NBK242625\/<\/a><br \/>Requirements - NCBI SRA toolkit<\/p>\n<p>\u00a0<\/p>\n<p>NCBI SRA toolkit:<br \/>Download - <a href=\"https:\/\/trace.ncbi.nlm.nih.gov\/Traces\/sra\/sra.cgi?view=software\" target=\"_blank\">https:\/\/trace.ncbi.nlm.nih.gov\/Traces\/sra\/sra.cgi?view=software<\/a> (ver2.8.1-3)<br \/>Documentation - <a href=\"https:\/\/trace.ncbi.nlm.nih.gov\/Traces\/sra\/sra.cgi?view=toolkit_doc\" target=\"_blank\">https:\/\/trace.ncbi.nlm.nih.gov\/Traces\/sra\/sra.cgi?view=toolkit_doc<\/a><\/p>\n<p>\u00a0<\/p>"},"is_project":0},{"component_id":"235263","previous_id":"235265","original_id":"0","guid":"E814BB8CB513498587573F6C438F47CC","previous_guid":"85489434027D4376897B93A5A5D554A4","component_type_id":"6","data_id":"0","data":"Import and organise raw data","order_id":"1","name":"Section","data_by_id":"0","type_id":"6","source_data":{"section":"Import and organise raw data"},"is_project":0},{"component_id":"235264","previous_id":"235263","original_id":"0","guid":"5B6B8039BC6F47E584CBC7BE7CDA82F9","previous_guid":"E814BB8CB513498587573F6C438F47CC","component_type_id":"9","data_id":"12","data":"","order_id":"2","name":"Dataset","data_by_id":"1","type_id":"9","source_data":{"id":"12","name":"Illumina HiSeq 1500 RNA-Seq data NCBI BioProject Accession: PRJN","link":"https:\/\/www.ncbi.nlm.nih.gov\/bioproject\/342864","can_edit":"1"},"is_project":0},{"component_id":"260601","previous_id":"235264","original_id":"0","guid":"1F9A1C01C64F48779B49ED2171B18E23","previous_guid":"5B6B8039BC6F47E584CBC7BE7CDA82F9","component_type_id":"15","data_id":"1461","data":"","order_id":"3","name":"Command","data_by_id":"1","type_id":"15","source_data":{"name":"#Create working directory and directory for installed software\nmkdir $HOME\/projects $HOME\/projects\/spiny_mouse\nexport WORKDIR=$HOME\/projects\/spiny_mouse\/\ncd $WORKDIR && mkdir user_installed_software\nexport PROGRAMDIR=$WORKDIR\/user_installed_software\n\n#Download, unpack, and install aspera connect\ncd $PROGRAMDIR\nwget http:\/\/download.asperasoft.com\/download\/sw\/connect\/3.6.2\/aspera-connect-3.6.2.117442-linux-64.tar.gz -O aspera.tar.gz\ntar zxvf aspera.tar.gz && rm aspera.tar.gz\nbash aspera-connect*\ncd ~\/.aspera\/connect\/bin\n#add binaries to a directory contained in PATH, or add current directory to PATH\necho export PATH=\\$PATH:`pwd`\\ >> ~\/.bashrc && source ~\/.bashrc\n\n#Download reads from the NCBI\ncd $WORKDIR\nascp -i ~\/.aspera\/connect\/etc\/asperaweb_id_dsa.openssh -T anonftp@ftp-trace.ncbi.nlm.nih.gov:\/sra\/sra-instant\/reads\/ByRun\/sra\/SRR\/SRR427\/SRR4279903 anonftp@ftp-trace.ncbi.nlm.nih.gov:\/sra\/sra-instant\/reads\/ByRun\/sra\/SRR\/SRR427\/SRR4279904 .\n\n#Obtain reads in fastq format using the ncbi SRA Toolkit\nfind . -name \"*.sra\" -exec fastq-dump --split-spot --split-files --skip-technical -I -F -Q 33 -W -T -R pass '{}' \\;\ncd SRR4279903\/pass\/1 && mv fastq Lane1_R1.fastq\ncd ..\/2 && mv fastq Lane1_R2.fastq\ncd ..\/..\/..\/SRR4279904\/pass\/1 && mv fastq Lane2_R1.fastq\ncd ..\/2 && mv fastq Lane2_R2.fastq\n\n#Move fastq files to WORKDIR\ncd $WORKDIR\nfind . -name \"Lane*\" -exec mv '{}' $WORKDIR \\; && rm -R SRR427990*\n\n#Delete sra files\ncd $WORKDIR\/\nfind . -name \"*.sra\" -delete\n\n#Archive a read-only copy of the raw data\ncd $WORKDIR\/\nmkdir protected_data && cd protected_data\ncp ..\/Lane* .\nchmod 444 Lane*","description":"","os_name":"Unix","os_version":"bash","can_edit":"1"},"is_project":0}]},{"id":"206251","is_changed":"0","original_id":"0","is_skipped":"0","is_checked":"0","guid":"25141E9CCB604C518368057B05E4EEC0","previous_guid":"1BC9259501E445C1815CCC019D6ACEB7","previous_id":"192073","last_modified":"1488675935","components":[{"component_id":"261117","previous_id":0,"original_id":"0","guid":"AD73804263F641299146D947401C3E09","previous_guid":null,"component_type_id":"1","data_id":"0","data":"<p>Decompress gzipped files (*.gz), and use FastQC for preliminary read quality assessment.\u00a0GNU zip (gzip) is a popular compression utility free from patented algorithms. FastQC is a quality control tool for high throughput sequence data which assesses multiple metrics and provides a QC report.\u00a0<\/p>\n<p>\u00a0<\/p>\n<p>gzip:<br \/>Download - <a href=\"https:\/\/www.gnu.org\/software\/gzip\/\" target=\"_blank\">https:\/\/www.gnu.org\/software\/gzip\/<\/a>\u00a0(ver1.2.4)<br \/>Documentation - <a href=\"http:\/\/www.math.utah.edu\/docs\/info\/gzip_toc.html\" target=\"_blank\">http:\/\/www.math.utah.edu\/docs\/info\/gzip_toc.html<\/a><\/p>\n<p>\u00a0<\/p>\n<p>fastQC:<br \/>Download - <a href=\"http:\/\/www.bioinformatics.babraham.ac.uk\/projects\/download.html#fastqc\" target=\"_blank\">http:\/\/www.bioinformatics.babraham.ac.uk\/projects\/download.html#fastqc<\/a>\u00a0(ver0.11.15)<br \/>Documentation - <a href=\"http:\/\/www.bioinformatics.babraham.ac.uk\/projects\/fastqc\/Help\/\" target=\"_blank\">http:\/\/www.bioinformatics.babraham.ac.uk\/projects\/fastqc\/Help\/<\/a><br \/>Requirements - A suitable Java Runtime Environment (<a href=\"https:\/\/www.java.com\/en\/\" target=\"_blank\">https:\/\/www.java.com\/en\/<\/a>) and the Picard BAM\/SAM Libraries (included in download)<\/p>\n<p>\u00a0<\/p>","order_id":"0","name":"Description","data_by_id":"0","type_id":"1","source_data":{"description":"<p>Decompress gzipped files (*.gz), and use FastQC for preliminary read quality assessment.\u00a0GNU zip (gzip) is a popular compression utility free from patented algorithms. FastQC is a quality control tool for high throughput sequence data which assesses multiple metrics and provides a QC report.\u00a0<\/p>\n<p>\u00a0<\/p>\n<p>gzip:<br \/>Download - <a href=\"https:\/\/www.gnu.org\/software\/gzip\/\" target=\"_blank\">https:\/\/www.gnu.org\/software\/gzip\/<\/a>\u00a0(ver1.2.4)<br \/>Documentation - <a href=\"http:\/\/www.math.utah.edu\/docs\/info\/gzip_toc.html\" target=\"_blank\">http:\/\/www.math.utah.edu\/docs\/info\/gzip_toc.html<\/a><\/p>\n<p>\u00a0<\/p>\n<p>fastQC:<br \/>Download - <a href=\"http:\/\/www.bioinformatics.babraham.ac.uk\/projects\/download.html#fastqc\" target=\"_blank\">http:\/\/www.bioinformatics.babraham.ac.uk\/projects\/download.html#fastqc<\/a>\u00a0(ver0.11.15)<br \/>Documentation - <a href=\"http:\/\/www.bioinformatics.babraham.ac.uk\/projects\/fastqc\/Help\/\" target=\"_blank\">http:\/\/www.bioinformatics.babraham.ac.uk\/projects\/fastqc\/Help\/<\/a><br \/>Requirements - A suitable Java Runtime Environment (<a href=\"https:\/\/www.java.com\/en\/\" target=\"_blank\">https:\/\/www.java.com\/en\/<\/a>) and the Picard BAM\/SAM Libraries (included in download)<\/p>\n<p>\u00a0<\/p>"},"is_project":0},{"component_id":"260467","previous_id":"261117","original_id":"0","guid":"213616EE76C546FA9F18D167A171D093","previous_guid":"AD73804263F641299146D947401C3E09","component_type_id":"6","data_id":"0","data":"Decompress and examine RNA-Seq read quality","order_id":"1","name":"Section","data_by_id":"0","type_id":"6","source_data":{"section":"Decompress and examine RNA-Seq read quality"},"is_project":0},{"component_id":"261180","previous_id":"260467","original_id":"0","guid":"AEB9B7D7A1FA40479CEA3DD2DA45607C","previous_guid":"213616EE76C546FA9F18D167A171D093","component_type_id":"15","data_id":"1462","data":"","order_id":"2","name":"Command","data_by_id":"1","type_id":"15","source_data":{"name":"#Download and install GZIP and FastQC\ncd $PROGRAMDIR\nwget http:\/\/www.gzip.org\/gz124src.zip\nwget http:\/\/www.bioinformatics.babraham.ac.uk\/projects\/fastqc\/fastqc_v0.11.5.zip\n#unpack\nunzip *.zip\n#install\ncd gzip124src\n.\/configure --prefix=`pwd`\nmake\nmake install\n#add binaries to a directory contained in PATH, or add current directory to PATH\ncd bin && echo export PATH=\\$PATH:`pwd`\\ >> ~\/.bashrc && source ~\/.bashrc\n\n#Set file permissions for FastQC\ncd $PROGRAMDIR\/FastQC\nchmod 755 fastqc\n#add binaries to a directory contained in PATH, or add current directory to PATH\necho export PATH=\\$PATH:`pwd`\\ >> ~\/.bashrc && source ~\/.bashrc\n\n#If required, decompress fastq files downloaded from the NCBI (may not be necessary depending on SRAtoolkit version)\ncd $WORKDIR\ngunzip *.fastq.gz \n\n#Run FastQC on each sample to assess read quality\nfor f in Lane*; do fastqc $f; done","description":"","os_name":"Unix","os_version":"bash","can_edit":"1"},"is_project":0}]},{"id":"207009","is_changed":"0","original_id":"0","is_skipped":"0","is_checked":"0","guid":"1DFF821025B940EB8509258DF2BD2F9E","previous_guid":"25141E9CCB604C518368057B05E4EEC0","previous_id":"206251","last_modified":"1488273263","components":[{"component_id":"261214","previous_id":0,"original_id":"0","guid":"DA3CAA9336684C9EBA4420CC28A4DB61","previous_guid":null,"component_type_id":"1","data_id":"0","data":"<p>Trim_galore is a tool\u00a0that implements\u00a0cutadapt\u00a0to consistently apply quality and adapter trimming to FastQ files: it seeks out and removes adapter sequences from RNA-Seq data.<\/p>\n<p>\u00a0<\/p>\n<p>Trim_galore:<br \/>Download - <a href=\"https:\/\/github.com\/FelixKrueger\/TrimGalore\/releases\" target=\"_blank\">https:\/\/github.com\/FelixKrueger\/TrimGalore\/releases<\/a>\u00a0(ver0.4.2)<br \/>Documentation - <a href=\"http:\/\/www.bioinformatics.babraham.ac.uk\/projects\/trim_galore\/Trim_Galore_User_Guide_v0.4.2.pdf\" target=\"_blank\">http:\/\/www.bioinformatics.babraham.ac.uk\/projects\/trim_galore\/Trim_Galore_User_Guide_v0.4.2.pdf<\/a><br \/>Requirements: Cutadapt and FastQC<\/p>\n<p>\u00a0<\/p>\n<p>Cutadapt:<br \/>Download - <a href=\"https:\/\/pypi.python.org\/pypi\/cutadapt\" target=\"_blank\">https:\/\/pypi.python.org\/pypi\/cutadapt<\/a>\u00a0(ver1.9.1)<br \/>Documentation - <a href=\"https:\/\/media.readthedocs.org\/pdf\/cutadapt\/stable\/cutadapt.pdf\" target=\"_blank\">https:\/\/media.readthedocs.org\/pdf\/cutadapt\/stable\/cutadapt.pdf<\/a><br \/>Reference - Martin, M., 2011. Cutadapt removes adapter sequences from high-throughput sequencing reads. EMBnet. journal, 17(1), pp.pp-10.<\/p>\n<p>*Minimum read length parameter ('--length 80') is dependant on length of original reads (in this case 150bp, paired-end)<\/p>\n<p>\u00a0<\/p>","order_id":"0","name":"Description","data_by_id":"0","type_id":"1","source_data":{"description":"<p>Trim_galore is a tool\u00a0that implements\u00a0cutadapt\u00a0to consistently apply quality and adapter trimming to FastQ files: it seeks out and removes adapter sequences from RNA-Seq data.<\/p>\n<p>\u00a0<\/p>\n<p>Trim_galore:<br \/>Download - <a href=\"https:\/\/github.com\/FelixKrueger\/TrimGalore\/releases\" target=\"_blank\">https:\/\/github.com\/FelixKrueger\/TrimGalore\/releases<\/a>\u00a0(ver0.4.2)<br \/>Documentation - <a href=\"http:\/\/www.bioinformatics.babraham.ac.uk\/projects\/trim_galore\/Trim_Galore_User_Guide_v0.4.2.pdf\" target=\"_blank\">http:\/\/www.bioinformatics.babraham.ac.uk\/projects\/trim_galore\/Trim_Galore_User_Guide_v0.4.2.pdf<\/a><br \/>Requirements: Cutadapt and FastQC<\/p>\n<p>\u00a0<\/p>\n<p>Cutadapt:<br \/>Download - <a href=\"https:\/\/pypi.python.org\/pypi\/cutadapt\" target=\"_blank\">https:\/\/pypi.python.org\/pypi\/cutadapt<\/a>\u00a0(ver1.9.1)<br \/>Documentation - <a href=\"https:\/\/media.readthedocs.org\/pdf\/cutadapt\/stable\/cutadapt.pdf\" target=\"_blank\">https:\/\/media.readthedocs.org\/pdf\/cutadapt\/stable\/cutadapt.pdf<\/a><br \/>Reference - Martin, M., 2011. Cutadapt removes adapter sequences from high-throughput sequencing reads. EMBnet. journal, 17(1), pp.pp-10.<\/p>\n<p>*Minimum read length parameter ('--length 80') is dependant on length of original reads (in this case 150bp, paired-end)<\/p>\n<p>\u00a0<\/p>"},"is_project":0},{"component_id":"261195","previous_id":"261214","original_id":"0","guid":"1409E95A7AD140A7B71E331815D5F81E","previous_guid":"DA3CAA9336684C9EBA4420CC28A4DB61","component_type_id":"6","data_id":"0","data":"Trim adapters and re-examine read quality","order_id":"1","name":"Section","data_by_id":"0","type_id":"6","source_data":{"section":"Trim adapters and re-examine read quality"},"is_project":0},{"component_id":"261250","previous_id":"261195","original_id":"0","guid":"D888CFE1126A46D2ACF7541473C4BA19","previous_guid":"1409E95A7AD140A7B71E331815D5F81E","component_type_id":"15","data_id":"1463","data":"","order_id":"2","name":"Command","data_by_id":"1","type_id":"15","source_data":{"name":"#Download and install cutadapt using pip\ncd $PROGRAMDIR\npip install --user --upgrade cutadapt\n\n#Download and install cutadapt using anaconda (https:\/\/www.continuum.io\/downloads)\ncd $PROGRAMDIR\nconda install -c bioconda cutadapt && python setup.py install --user\n\n#Download trim_galore\ncd $PROGRAMDIR\nwget https:\/\/github.com\/FelixKrueger\/TrimGalore\/archive\/0.4.2.tar.gz -O trim_galore.tar.gz\n#unpack\ntar zxvf trim_galore.tar.gz && cd TrimGalore-0.4.2\n#add binary to a directory contained in PATH, or add current directory to PATH\necho export PATH=\\$PATH:`pwd`\\ >> ~\/.bashrc && source ~\/.bashrc\n\n#Run trim_galore on each lane\nmkdir $WORKDIR\/adapter_trimmed_reads && cd $WORKDIR\ntrim_galore --paired --retain_unpaired --length 80 --output .\/adapter_trimmed_reads Lane1_R1.fastq Lane1_R2.fastq 1>trim_galore_lane_1_reads.log 2>trim_galore_lane_1_reads.err &\n\ntrim_galore --paired --retain_unpaired --length 80 --output .\/adapter_trimmed_reads Lane2_R1.fastq Lane2_R2.fastq 1>trim_galore_lane_2_reads.log 2>trim_galore_lane_2_reads.err &\n\n#Stdout ('1>') and stderr ('2>') are redirected to .log\/.err files to aid in 'disowning' processes from the terminal session ('disown %1')","description":"","os_name":"Unix","os_version":"bash","can_edit":"1"},"is_project":0}]},{"id":"207133","is_changed":"0","original_id":"0","is_skipped":"0","is_checked":"0","guid":"B92EF347A0044CF497FB03AD03B658D4","previous_guid":"1DFF821025B940EB8509258DF2BD2F9E","previous_id":"207009","last_modified":"1501479243","components":[{"component_id":"261409","previous_id":0,"original_id":"0","guid":"9D61AB8CE2184F62BDB2769082F514FE","previous_guid":null,"component_type_id":"1","data_id":"0","data":"<p>Remove poor quality reads and trim poor quality nucleotides from read ends using trimmomatic. Trimmomatic is a flexible read trimming tool for Illumina NGS data. Re-assess 'cleaned' reads using FastQC to check read metrics\u00a0have been improved.<\/p>\n<p>\u00a0<\/p>\n<p>Using a reletively high quality threshold improves assembler performance and reduces memory requirements, however lowly expressed transcripts may be lost as proportionately more reads are excluded. Conversely,\u00a0a relatively low quality threshold may\u00a0improve retention of lowly expressed transcripts, but\u00a0negatively affect\u00a0assembler performance (https:\/\/doi.org\/10.3389\/fgene.2014.00013).\u00a0The optimal degree of read trimming and removal can differ for each dataset.<\/p>\n<p>\u00a0<\/p>\n<p>Several read quality thresholds were used\u00a0in the publication associated with this\u00a0protocol (Mamrot, J., Legaie, R., Ellery, S.J., Wilson, T., Gardner, D., Walker, D.W., Temple-Smith, P., Papenfuss, A.T. and Dickinson, H., 2016. De novo transcriptome assembly for the spiny mouse (Acomys cahirinus). <em>bioRxiv<\/em>, p.076067). Each dataset was assembled (Steps 5-9), validated and compared\u00a0for accuracy and completeness. For this dataset\u00a0a relatively low quality threshold (as outlined in the COMMAND section below) produced higher quality\u00a0assemblies.<\/p>\n<p>\u00a0<\/p>\n<p>In addition to differing levels of trimming\/filtering, read error correction was conducted using SEECER (http:\/\/sb.cs.cmu.edu\/seecer\/).\u00a0Assembly metrics\u00a0were slightly improved when error-corrected reads were assembled with Trinity (this 'error-corrected' assembly was included in downstream analyses), however\u00a0there were no\u00a0noticeable improvements assembling error-corrected reads with\u00a0SOAPdenovo-Trans and Velvet\/Oases with\u00a0this dataset. Despite this unexpected outcome, error correction is still recommended for best-practice transcriptome assembly (http:\/\/oyster-river-protocol.readthedocs.io\/en\/master\/; http:\/\/dx.doi.org\/10.1101\/035642; https:\/\/doi.org\/10.7717\/peerj.113)<\/p>\n<p>\u00a0<\/p>\n<p>Trimmomatic:<br \/>Download - <a href=\"http:\/\/www.usadellab.org\/cms\/?page=trimmomatic\" target=\"_blank\">http:\/\/www.usadellab.org\/cms\/?page=trimmomatic<\/a>\u00a0(ver0.36)<br \/>Documentation - <a href=\"http:\/\/www.usadellab.org\/cms\/uploads\/supplementary\/Trimmomatic\/TrimmomaticManual_V0.32.pdf\" target=\"_blank\">http:\/\/www.usadellab.org\/cms\/uploads\/supplementary\/Trimmomatic\/TrimmomaticManual_V0.32.pdf<\/a><br \/>Reference - Bolger, A. M., Lohse, M., &amp; Usadel, B. (2014). Trimmomatic: A flexible trimmer for Illumina Sequence Data. Bioinformatics, btu170.<\/p>\n<p>\u00a0<\/p>\n<p>SEECER:<\/p>\n<p>Download - <a href=\"http:\/\/sb.cs.cmu.edu\/seecer\/install.html#Download\" target=\"_blank\">http:\/\/sb.cs.cmu.edu\/seecer\/install.html#Download<\/a>\u00a0(ver1.3)<\/p>\n<p>Documentation - <a href=\"http:\/\/sb.cs.cmu.edu\/seecer\/downloads\/manual.pdf\" target=\"_blank\">http:\/\/sb.cs.cmu.edu\/seecer\/downloads\/manual.pdf<\/a><\/p>\n<p>Reference -\u00a0Hai-Son Le, Marcel H. Schulz, Brenna M. McCauley, Veronica F. Hinman and Ziv Bar-Joseph (2013). Probabilistic error correction for RNA sequencing. Nucleic Acids Research \/\u00a0<\/p>\n<p>Requirements - GNU Scientific Library, SeqAn, Jellyfish, OPENMP API<\/p>\n<p>\u00a0<\/p>","order_id":"0","name":"Description","data_by_id":"0","type_id":"1","source_data":{"description":"<p>Remove poor quality reads and trim poor quality nucleotides from read ends using trimmomatic. Trimmomatic is a flexible read trimming tool for Illumina NGS data. Re-assess 'cleaned' reads using FastQC to check read metrics\u00a0have been improved.<\/p>\n<p>\u00a0<\/p>\n<p>Using a reletively high quality threshold improves assembler performance and reduces memory requirements, however lowly expressed transcripts may be lost as proportionately more reads are excluded. Conversely,\u00a0a relatively low quality threshold may\u00a0improve retention of lowly expressed transcripts, but\u00a0negatively affect\u00a0assembler performance (https:\/\/doi.org\/10.3389\/fgene.2014.00013).\u00a0The optimal degree of read trimming and removal can differ for each dataset.<\/p>\n<p>\u00a0<\/p>\n<p>Several read quality thresholds were used\u00a0in the publication associated with this\u00a0protocol (Mamrot, J., Legaie, R., Ellery, S.J., Wilson, T., Gardner, D., Walker, D.W., Temple-Smith, P., Papenfuss, A.T. and Dickinson, H., 2016. De novo transcriptome assembly for the spiny mouse (Acomys cahirinus). <em>bioRxiv<\/em>, p.076067). Each dataset was assembled (Steps 5-9), validated and compared\u00a0for accuracy and completeness. For this dataset\u00a0a relatively low quality threshold (as outlined in the COMMAND section below) produced higher quality\u00a0assemblies.<\/p>\n<p>\u00a0<\/p>\n<p>In addition to differing levels of trimming\/filtering, read error correction was conducted using SEECER (http:\/\/sb.cs.cmu.edu\/seecer\/).\u00a0Assembly metrics\u00a0were slightly improved when error-corrected reads were assembled with Trinity (this 'error-corrected' assembly was included in downstream analyses), however\u00a0there were no\u00a0noticeable improvements assembling error-corrected reads with\u00a0SOAPdenovo-Trans and Velvet\/Oases with\u00a0this dataset. Despite this unexpected outcome, error correction is still recommended for best-practice transcriptome assembly (http:\/\/oyster-river-protocol.readthedocs.io\/en\/master\/; http:\/\/dx.doi.org\/10.1101\/035642; https:\/\/doi.org\/10.7717\/peerj.113)<\/p>\n<p>\u00a0<\/p>\n<p>Trimmomatic:<br \/>Download - <a href=\"http:\/\/www.usadellab.org\/cms\/?page=trimmomatic\" target=\"_blank\">http:\/\/www.usadellab.org\/cms\/?page=trimmomatic<\/a>\u00a0(ver0.36)<br \/>Documentation - <a href=\"http:\/\/www.usadellab.org\/cms\/uploads\/supplementary\/Trimmomatic\/TrimmomaticManual_V0.32.pdf\" target=\"_blank\">http:\/\/www.usadellab.org\/cms\/uploads\/supplementary\/Trimmomatic\/TrimmomaticManual_V0.32.pdf<\/a><br \/>Reference - Bolger, A. M., Lohse, M., &amp; Usadel, B. (2014). Trimmomatic: A flexible trimmer for Illumina Sequence Data. Bioinformatics, btu170.<\/p>\n<p>\u00a0<\/p>\n<p>SEECER:<\/p>\n<p>Download - <a href=\"http:\/\/sb.cs.cmu.edu\/seecer\/install.html#Download\" target=\"_blank\">http:\/\/sb.cs.cmu.edu\/seecer\/install.html#Download<\/a>\u00a0(ver1.3)<\/p>\n<p>Documentation - <a href=\"http:\/\/sb.cs.cmu.edu\/seecer\/downloads\/manual.pdf\" target=\"_blank\">http:\/\/sb.cs.cmu.edu\/seecer\/downloads\/manual.pdf<\/a><\/p>\n<p>Reference -\u00a0Hai-Son Le, Marcel H. Schulz, Brenna M. McCauley, Veronica F. Hinman and Ziv Bar-Joseph (2013). Probabilistic error correction for RNA sequencing. Nucleic Acids Research \/\u00a0<\/p>\n<p>Requirements - GNU Scientific Library, SeqAn, Jellyfish, OPENMP API<\/p>\n<p>\u00a0<\/p>"},"is_project":0},{"component_id":"261395","previous_id":"261409","original_id":"0","guid":"63373F442A0E43CAB6785DB7AC96A3D5","previous_guid":"9D61AB8CE2184F62BDB2769082F514FE","component_type_id":"6","data_id":"0","data":"Remove poor quality reads","order_id":"1","name":"Section","data_by_id":"0","type_id":"6","source_data":{"section":"Remove poor quality reads"},"is_project":0},{"component_id":"324735","previous_id":"261395","original_id":"0","guid":"E026BCEDAB8043ED8AB9B1EA7D9D1FBA","previous_guid":"63373F442A0E43CAB6785DB7AC96A3D5","component_type_id":"15","data_id":"1503","data":"","order_id":"2","name":"Command","data_by_id":"1","type_id":"15","source_data":{"name":"#There is substantial overlap in the capabilities of trim_galore and trimmomatic; each program was used here for different purposes: trim galore to seek out and remove adapters, trimmomatic for trimming poor quality bases\/reads.\n\n#Download and install trimmomatic using linuxbrew (http:\/\/linuxbrew.sh\/)\ncd $PROGRAMDIR\nbrew tap homebrew\/science\nbrew install trimmomatic\n#alternatively, download trimmomatic from source\ncd $PROGRAMDIR\nwget http:\/\/www.usadellab.org\/cms\/uploads\/supplementary\/Trimmomatic\/Trimmomatic-0.36.zip\nunzip Trimmomatic-0.36.zip && rm Trimmomatic-0.36.zip && cd Trimmomatic-0.36\/\n#add binary to a directory contained in PATH, or add current directory to PATH\necho export PATH=\\$PATH:`pwd`\\ >> ~\/.bashrc && source ~\/.bashrc\n\ncd $WORKDIR\/adapter_trimmed_reads\ntrimmomatic PE -phred33 Lane1_R1_val_1.fq Lane1_R2_val_2.fq lane1_R1_pairedout.fq lane1_R1_unpairedout.fq lane1_R2_pairedout.fq lane1_R2_unpairedout.fq LEADING:3 TRAILING:3 SLIDINGWINDOW:4:15 AVGQUAL:20 MINLEN:36 1>trimmomatic_1.log 2>trimmomatic_1.err &\ntrimmomatic PE -phred33 Lane2_R1_val_1.fq Lane2_R2_val_2.fq lane2_R1_pairedout.fq lane2_R1_unpairedout.fq lane2_R2_pairedout.fq lane2_R2_unpairedout.fq LEADING:3 TRAILING:3 SLIDINGWINDOW:4:15 AVGQUAL:20 MINLEN:36 1>trimmomatic_2.log 2>trimmomatic_2.err &\n\nmkdir $WORKDIR\/cleaned_trimmed_reads\nmv *_pairedout.fq $WORKDIR\/cleaned_trimmed_reads\/\n\n#Assess read quality using FastQC, and compare with untrimmed\/unfiltered reads \ncd $WORKDIR\/cleaned_trimmed_reads\nfor f in *pairedout.fq; do fastqc $f; done\n\n#Concatenate lanes\ncat lane1_R1_pairedout.fq lane2_R1_pairedout.fq > R1_pairedout.fastq\ncat lane1_R2_pairedout.fq lane2_R2_pairedout.fq > R2_pairedout.fastq\n\n#optionally, unpairedout.fq reads can be added to R2_pairedout.fq prior to assembly\n \n#Download and install SEECER\ncd $PROGRAMDIR\nwget http:\/\/sb.cs.cmu.edu\/seecer\/downloads\/SEECER-0.1.3.tar.gz\ntar zxvf SEECER-0.1.3.tar.gz && rm SEECER-0.1.3.tar.gz\ncd SEECER-0.1.3\n.\/configure --prefix=`pwd`\nmake\nmake install\n#add binary to a directory contained in PATH, or add current directory to PATH\ncd bin && echo export PATH=\\$PATH:`pwd`\\ >> ~\/.bashrc && source ~\/.bashrc\n\n#Conduct error correction on trimmed\/filtered reads using SEECER\n#run 'run_seecer.sh' on testdata to check install, then symlink real data into .\/testdata directory and run the 'run_seecer.sh' script\ncd $PROGRAMDIR\/SEECER-0.1.3\/testdata.\nln -s $WORKDIR\/cleaned_trimmed_reads\/R1_pairedout.fastq R1_pairedout.fastq\nln -s $WORKDIR\/cleaned_trimmed_reads\/R2_pairedout.fastq R2_pairedout.fastq\ncd $PROGRAMDIR\/SEECER-0.1.3\/\nbash .\/bin\/run_seecer.sh -t tmpDirectory .\/testdata\/R1_pairedout.fastq .\/testdata\/R2_pairedout.fastq 1>seecer.log 2>seecer.err &","description":"","os_name":"Unix","os_version":"bash","can_edit":"1"},"is_project":0},{"component_id":"964537","previous_id":"324735","original_id":"0","guid":"F2824CA570FA4B9F9335E4CE65AB370B","previous_guid":"E026BCEDAB8043ED8AB9B1EA7D9D1FBA","component_type_id":"13","data_id":"15947","data":"","order_id":"3","name":"Comment","data_by_id":"1","type_id":"13","source_data":{"annotation_id":"15947","thread_id":"15947","id":"15947","thread_title":"Annotation on step 4 of De novo transcriptome assembly workflow","uri":"annotation-on-step-4-of-de-novo-transcriptome-assembly","thread_uri":"annotation-on-step-4-of-de-novo-transcriptome-assembly","step_id":"207133","protocol_uri":"de-novo-transcriptome-assembly-workflow-ghebt3e","protocol_name":"De novo transcriptome assembly workflow","protocol_name_html":"De novo transcriptome assembly workflow","annotation":"<p>A consequence of SEECER is that your fastq reads are converted into fasta format (i.e. base quality scores are lost). This limits your options further down the pipeline. Rcorrector is a great\u00a0alternative provided you have a reasonable number of reads (eg &gt;30 million):\u00a0https:\/\/github.com\/mourisl\/Rcorrector \/ install via linuxbrew: \"brew install rcorrector\" \/ Song, L., Florea, L., Rcorrector: Efficient and accurate error correction for Illumina RNA-seq reads.\u00a0GigaScience. 2015, 4:48.<\/p>","thread_text":"<p>A consequence of SEECER is that your fastq reads are converted into fasta format (i.e. base quality scores are lost). This limits your options further down the pipeline. Rcorrector is a great\u00a0alternative provided you have a reasonable number of reads (eg &gt;30 million):\u00a0https:\/\/github.com\/mourisl\/Rcorrector \/ install via linuxbrew: \"brew install rcorrector\" \/ Song, L., Florea, L., Rcorrector: Efficient and accurate error correction for Illumina RNA-seq reads.\u00a0GigaScience. 2015, 4:48.<\/p>","body":"<p>A consequence of SEECER is that your fastq reads are converted into fasta format (i.e. base quality scores are lost). This limits your options further down the pipeline. Rcorrector is a great\u00a0alternative provided you have a reasonable number of reads (eg &gt;30 million):\u00a0https:\/\/github.com\/mourisl\/Rcorrector \/ install via linuxbrew: \"brew install rcorrector\" \/ Song, L., Florea, L., Rcorrector: Efficient and accurate error correction for Illumina RNA-seq reads.\u00a0GigaScience. 2015, 4:48.<\/p>","is_private":"0","public_protocol":"1","can_edit":0,"can_delete":"0","show_name":"0","created_date":"1501479243","created_on":"1501479243","modified_on":null,"last_updated":null,"profile_image":"https:\/\/s3.amazonaws.com\/pr-journal\/d4bef86.jpg","full_name":"Jared Mamrot","affiliation":"Hudson Institute of Medical Research","username":"jared-mamrot","email":"jaredmamrot@gmail.com","pa_useranme":"jared-mamrot","comments":[]},"is_project":0}]},{"id":"241578","is_changed":"0","original_id":"0","is_skipped":"0","is_checked":"0","guid":"C52D46072CD24526A1D2160377A4EAB3","previous_guid":"B92EF347A0044CF497FB03AD03B658D4","previous_id":"207133","last_modified":"1488676024","components":[{"component_id":"324905","previous_id":0,"original_id":"0","guid":"A7E1C744B3C1408C806E6F0A8F0C2629","previous_guid":null,"component_type_id":"1","data_id":"0","data":"<p>SOAPdenovo-Trans is a de Bruijn graph-based assembler for transcriptome data, derived from the SOAPdenovo2 genome assembler. It\u00a0incorporates the innovative error-removal model from Trinity and combines this with the robust heuristic graph traversal method for solving\u00a0isoform-related sub-graphs from Oases (both of Trinity and Oases\u00a0are subsequently\u00a0employed in this protocol). Further details on the algorithms and applications of SOAPdenovo-Trans are available at\u00a0 https:\/\/doi.org\/10.1093\/bioinformatics\/btu077<\/p>\n<p>\u00a0<\/p>\n<p>SOAPdenovo-Trans requires user-specified parameters to\u00a0be listed in a 'config' file.<\/p>\n<p>\u00a0<\/p>\n<p>SOAPdenovo-Trans:<br \/>Download - <a href=\"http:\/\/soap.genomics.org.cn\/SOAPdenovo-Trans.html\" target=\"_blank\">http:\/\/soap.genomics.org.cn\/SOAPdenovo-Trans.html\u00a0<\/a>(ver1.03)<br \/>Documentation - <a href=\"http:\/\/soap.genomics.org.cn\/SOAPdenovo-Trans.html\" target=\"_blank\">http:\/\/soap.genomics.org.cn\/SOAPdenovo-Trans.html<\/a> \/ <a href=\"https:\/\/github.com\/aquaskyline\/SOAPdenovo-Trans\" target=\"_blank\">https:\/\/github.com\/aquaskyline\/SOAPdenovo-Trans<\/a><br \/>Reference - Xie, Y., Wu, G., Tang, J., Luo, R., Patterson, J., Liu, S., Huang, W., He, G., Gu, S., Li, S. and Zhou, X., 2014. SOAPdenovo-Trans: de novo transcriptome assembly with short RNA-Seq reads. Bioinformatics, 30(12), pp.1660-1666.<\/p>\n<p>\u00a0<\/p>","order_id":"0","name":"Description","data_by_id":"0","type_id":"1","source_data":{"description":"<p>SOAPdenovo-Trans is a de Bruijn graph-based assembler for transcriptome data, derived from the SOAPdenovo2 genome assembler. It\u00a0incorporates the innovative error-removal model from Trinity and combines this with the robust heuristic graph traversal method for solving\u00a0isoform-related sub-graphs from Oases (both of Trinity and Oases\u00a0are subsequently\u00a0employed in this protocol). Further details on the algorithms and applications of SOAPdenovo-Trans are available at\u00a0 https:\/\/doi.org\/10.1093\/bioinformatics\/btu077<\/p>\n<p>\u00a0<\/p>\n<p>SOAPdenovo-Trans requires user-specified parameters to\u00a0be listed in a 'config' file.<\/p>\n<p>\u00a0<\/p>\n<p>SOAPdenovo-Trans:<br \/>Download - <a href=\"http:\/\/soap.genomics.org.cn\/SOAPdenovo-Trans.html\" target=\"_blank\">http:\/\/soap.genomics.org.cn\/SOAPdenovo-Trans.html\u00a0<\/a>(ver1.03)<br \/>Documentation - <a href=\"http:\/\/soap.genomics.org.cn\/SOAPdenovo-Trans.html\" target=\"_blank\">http:\/\/soap.genomics.org.cn\/SOAPdenovo-Trans.html<\/a> \/ <a href=\"https:\/\/github.com\/aquaskyline\/SOAPdenovo-Trans\" target=\"_blank\">https:\/\/github.com\/aquaskyline\/SOAPdenovo-Trans<\/a><br \/>Reference - Xie, Y., Wu, G., Tang, J., Luo, R., Patterson, J., Liu, S., Huang, W., He, G., Gu, S., Li, S. and Zhou, X., 2014. SOAPdenovo-Trans: de novo transcriptome assembly with short RNA-Seq reads. Bioinformatics, 30(12), pp.1660-1666.<\/p>\n<p>\u00a0<\/p>"},"is_project":0},{"component_id":"324897","previous_id":"324905","original_id":"0","guid":"0458F345B24E40A3A69C091E3FA7FB44","previous_guid":"A7E1C744B3C1408C806E6F0A8F0C2629","component_type_id":"6","data_id":"0","data":"Prepare for SOAPdenovo-Trans assembly","order_id":"1","name":"Section","data_by_id":"0","type_id":"6","source_data":{"section":"Prepare for SOAPdenovo-Trans assembly"},"is_project":0},{"component_id":"324969","previous_id":"324897","original_id":"0","guid":"7BC3B1B458914F979E5905450229B18D","previous_guid":"0458F345B24E40A3A69C091E3FA7FB44","component_type_id":"15","data_id":"1504","data":"","order_id":"2","name":"Command","data_by_id":"1","type_id":"15","source_data":{"name":"#Download\ncd $PROGRAMDIR\nmkdir SOAPdenovo-Trans\nwget https:\/\/downloads.sourceforge.net\/project\/soapdenovotrans\/SOAPdenovo-Trans\/bin\/v1.03\/SOAPdenovo-Trans-bin-v1.03.tar.gz -O SOAPdenovo-Trans\/SOAPdenovo-Trans-bin-v1.03.tar.gz\ncd SOAPdenovo-Trans\/\ntar zxvf SOAPdenovo-Trans-bin-v1.03.tar.gz\n#add binary to a directory contained in PATH, or add current directory to PATH\necho export PATH=\\$PATH:`pwd`\\ >> ~\/.bashrc && source ~\/.bashrc\n\n#Create config file- options are described\/explained in the SOAPdenovo-Trans documentation\ncd $WORKDIR\/cleaned_trimmed_reads\ncat > SOAP.config <<END_TEXT\nmax_rd_len=150\n[LIB]\navg_ins=192\nreverse_seq=0\nasm_flags=3\nq1=R1_pairedout.fastq\nq2=R2_pairedout.fastq\nEND_TEXT","description":"","os_name":"Unix","os_version":"bash","can_edit":"1"},"is_project":0}]},{"id":"241634","is_changed":"0","original_id":"0","is_skipped":"0","is_checked":"0","guid":"1C62867474B2414F9E92B01BC6ABFA1A","previous_guid":"C52D46072CD24526A1D2160377A4EAB3","previous_id":"241578","last_modified":"1488170741","components":[{"component_id":"325024","previous_id":0,"original_id":"0","guid":"C7BAF17D8BB241F4B3CC121C8FBAFD38","previous_guid":null,"component_type_id":"1","data_id":"0","data":"<p>Assemble reads at multiple kmer sizes using SOAPdenovo-Trans.<\/p>\n<p>\u00a0<\/p>\n<p>Use SOAPdenovo-Trans31mer for\u00a0kmer sizes 21\u00a0- 31.<\/p>\n<p>Use SOAPdenovo-Trans127mer for\u00a0kmer sizes 41 - 121.<\/p>\n<p>\u00a0<\/p>\n<p>After\u00a0assembly\u00a0is\u00a0complete, statistics are contained in the *.scafStat file, and scaffolded contigs in the *.scafSeq file.<\/p>\n<p>\u00a0<\/p>","order_id":"0","name":"Description","data_by_id":"0","type_id":"1","source_data":{"description":"<p>Assemble reads at multiple kmer sizes using SOAPdenovo-Trans.<\/p>\n<p>\u00a0<\/p>\n<p>Use SOAPdenovo-Trans31mer for\u00a0kmer sizes 21\u00a0- 31.<\/p>\n<p>Use SOAPdenovo-Trans127mer for\u00a0kmer sizes 41 - 121.<\/p>\n<p>\u00a0<\/p>\n<p>After\u00a0assembly\u00a0is\u00a0complete, statistics are contained in the *.scafStat file, and scaffolded contigs in the *.scafSeq file.<\/p>\n<p>\u00a0<\/p>"},"is_project":0},{"component_id":"325017","previous_id":"325024","original_id":"0","guid":"23EE3D6E6AF04B63A15A8B970DAFA7F3","previous_guid":"C7BAF17D8BB241F4B3CC121C8FBAFD38","component_type_id":"6","data_id":"0","data":"Assemble reads using SOAPdenovo-Trans","order_id":"1","name":"Section","data_by_id":"0","type_id":"6","source_data":{"section":"Assemble reads using SOAPdenovo-Trans"},"is_project":0},{"component_id":"325090","previous_id":"325017","original_id":"0","guid":"FB70C23367924AFDB347A090D538D56B","previous_guid":"23EE3D6E6AF04B63A15A8B970DAFA7F3","component_type_id":"15","data_id":"1505","data":"","order_id":"2","name":"Command","data_by_id":"1","type_id":"15","source_data":{"name":"cd $WORKDIR\/cleaned_trimmed_reads\nmkdir SOAPdenovo-Trans_output\nfor ((n=21; n<33; n=n+2)); do SOAPdenovo-Trans-31mer all -K $n -p 32 -s SOAP.config -o SOAPdenovo-Trans_output\/SOAP_$n 1>SOAP_k$n.log 2>SOAP_k$n.err; done\nfor ((n=41; n<131; n=n+10)); do SOAPdenovo-Trans-127mer all -K $n -p 32 -s SOAP.config -o SOAPdenovo-Trans_output\/SOAP_$n 1>SOAP_k$n.log 2>SOAP_k$n.err; done\nfor ((n=35; n<135; n=n+10)); do SOAPdenovo-Trans-127mer all -K $n -p 32 -s SOAP.config -o SOAPdenovo-Trans_output\/SOAP_$n 1>SOAP_k$n.log 2>SOAP_k$n.err; done\n\n#SOAPdenovo-Trans is a relatively fast assembler, however assembly may require a large amount of RAM (>500GB)","description":"","os_name":"Unix","os_version":"bash","can_edit":"1"},"is_project":0}]},{"id":"259115","is_changed":"0","original_id":"0","is_skipped":"0","is_checked":"0","guid":"800BFC842BF54A418AE23CBF2047DF62","previous_guid":"1C62867474B2414F9E92B01BC6ABFA1A","previous_id":"241634","last_modified":"1488596332","components":[{"component_id":"359014","previous_id":0,"original_id":"0","guid":"B59CBC9F6CB44C61A4ECE063664B18AB","previous_guid":null,"component_type_id":"1","data_id":"0","data":"<p>Assemble reads using Trinity (k-mer size set\u00a0at 25). Trinity is the most widely used\u00a0de novo transcriptome assembler: it is a de Bruijn graph-based assembler that implements an error removal model when constructing\u00a0transcripts. It retains and clusters\u00a0transcript isoforms, and is often\u00a0as a benchmark to evaluate novel assemblers.<\/p>\n<p>\u00a0<\/p>\n<p><span style=\"font-weight: 400;\"><em>In silico<\/em> normalization can be\u00a0employed in the Trinity pipeline to reduce read counts before assembly. The normalized\u00a0reads can be obtained (from \/trinity_out_dir\/insilico_read_normalization\/*.fq) and assembled using other assemblers (SOAPdenovo-Trans and Velvet\/Oases; Repeating steps 5-9).<\/span><\/p>\n<p>\u00a0<\/p>\n<p>Assembly statistics can be generated using the bundled 'TrinityStats.pl' script.<\/p>\n<p>\u00a0<\/p>\n<p>Trinity:<br \/>Download - <a href=\"https:\/\/github.com\/trinityrnaseq\/trinityrnaseq\/releases\" target=\"_blank\">https:\/\/github.com\/trinityrnaseq\/trinityrnaseq\/releases<\/a>\u00a0(ver2.3.2)<br \/>Documentation - <a href=\"https:\/\/github.com\/trinityrnaseq\/trinityrnaseq\/wiki\" target=\"_blank\">https:\/\/github.com\/trinityrnaseq\/trinityrnaseq\/wiki<\/a><\/p>\n<p>Requirements - Trinity comes bundled with required programs, including fastool, jellyfish, parafly, samtools and trimmomatic.<br \/>Reference - Grabherr, M.G., Haas, B.J., Yassour, M., Levin, J.Z., Thompson, D.A., Amit, I., Adiconis, X., Fan, L., Raychowdhury, R., Zeng, Q. and Chen, Z., 2011. Full-length transcriptome assembly from RNA-Seq data without a reference genome. Nature biotechnology, 29(7), pp.644-652.<\/p>\n<p>\u00a0<\/p>","order_id":"0","name":"Description","data_by_id":"0","type_id":"1","source_data":{"description":"<p>Assemble reads using Trinity (k-mer size set\u00a0at 25). Trinity is the most widely used\u00a0de novo transcriptome assembler: it is a de Bruijn graph-based assembler that implements an error removal model when constructing\u00a0transcripts. It retains and clusters\u00a0transcript isoforms, and is often\u00a0as a benchmark to evaluate novel assemblers.<\/p>\n<p>\u00a0<\/p>\n<p><span style=\"font-weight: 400;\"><em>In silico<\/em> normalization can be\u00a0employed in the Trinity pipeline to reduce read counts before assembly. The normalized\u00a0reads can be obtained (from \/trinity_out_dir\/insilico_read_normalization\/*.fq) and assembled using other assemblers (SOAPdenovo-Trans and Velvet\/Oases; Repeating steps 5-9).<\/span><\/p>\n<p>\u00a0<\/p>\n<p>Assembly statistics can be generated using the bundled 'TrinityStats.pl' script.<\/p>\n<p>\u00a0<\/p>\n<p>Trinity:<br \/>Download - <a href=\"https:\/\/github.com\/trinityrnaseq\/trinityrnaseq\/releases\" target=\"_blank\">https:\/\/github.com\/trinityrnaseq\/trinityrnaseq\/releases<\/a>\u00a0(ver2.3.2)<br \/>Documentation - <a href=\"https:\/\/github.com\/trinityrnaseq\/trinityrnaseq\/wiki\" target=\"_blank\">https:\/\/github.com\/trinityrnaseq\/trinityrnaseq\/wiki<\/a><\/p>\n<p>Requirements - Trinity comes bundled with required programs, including fastool, jellyfish, parafly, samtools and trimmomatic.<br \/>Reference - Grabherr, M.G., Haas, B.J., Yassour, M., Levin, J.Z., Thompson, D.A., Amit, I., Adiconis, X., Fan, L., Raychowdhury, R., Zeng, Q. and Chen, Z., 2011. Full-length transcriptome assembly from RNA-Seq data without a reference genome. Nature biotechnology, 29(7), pp.644-652.<\/p>\n<p>\u00a0<\/p>"},"is_project":0},{"component_id":"358709","previous_id":"359014","original_id":"0","guid":"DB718507F06442E18E403D1A61ED3998","previous_guid":"B59CBC9F6CB44C61A4ECE063664B18AB","component_type_id":"6","data_id":"0","data":"Assemble reads with Trinity","order_id":"1","name":"Section","data_by_id":"0","type_id":"6","source_data":{"section":"Assemble reads with Trinity"},"is_project":0},{"component_id":"359036","previous_id":"358709","original_id":"0","guid":"46EC58BB2CAE4E52A24D8E052D62B719","previous_guid":"DB718507F06442E18E403D1A61ED3998","component_type_id":"15","data_id":"1520","data":"","order_id":"2","name":"Command","data_by_id":"1","type_id":"15","source_data":{"name":"#Install Trinity\ncd $PROGRAMDIR\nwget https:\/\/github.com\/trinityrnaseq\/trinityrnaseq\/archive\/Trinity-v2.3.2.tar.gz -O Trinity-v2.3.2.tar.gz\ntar zxvf Trinity-v2.3.2.tar.gz\ncd trinityrnaseq\nmake\nmake plugins\n#test installation\ncd sample_data\/test_Trinity_Assembly\/ && .\/runMe.sh\n#if successful, add trinityrnaseq, trinity-plugins, util, misc, and support_scripts directories to PATH\necho export PATH=$PATH$( find $PROGRAMDIR\/trinityrnaseq\/ -type d -printf \":%p\" ) >> ~\/.bashrc && source ~\/.bashrc\n\n#Use Trinity to assemble error-corrected (fasta) and non-error-corrected (fastq) reads. Some user-defined parameters for Trinity are version-specific: check documentation before use\n\ncd $WORKDIR\/cleaned_trimmed_reads\nTrinity --seqType fq --JM 40G --left R1_pairedout.fastq --right R2_pairedout.fastq --CPU 12 --min_kmer_cov 2 --output Trinity-DN 1>trinity.log 2>trinity.err\n\n#Move Trinity assembly to Trinity-DN directory\nmv $WORKDIR\/cleaned_trimmed_reads\/Trinity-DN\/trinity_out_dir\/Trinity.fasta ..\n\n#Basic assembly statistics can be generated using the TrinityStats.pl script included in the package\ncd $WORKDIR\/cleaned_trimmed_reads\/Trinity-DN\/\nTrinityStats.pl Trinity.fasta > Stats.txt","description":"","os_name":"Unix","os_version":"bash","can_edit":"1"},"is_project":0}]},{"id":"296089","is_changed":"0","original_id":"0","is_skipped":"0","is_checked":"0","guid":"7E5BE0EF826D4FBDAA570C4122588A7D","previous_guid":"877292AD7129416FA951FA63EC60A91E","previous_id":"296298","last_modified":"1488582833","components":[{"component_id":"429365","previous_id":0,"original_id":"0","guid":"7492F22A86ED4E529CFB1D860DAE48E4","previous_guid":null,"component_type_id":"1","data_id":"0","data":"<p style=\"text-align: justify;\">Velvet is a de Bruijn graph based short-read assembler\u00a0designed for\u00a0de novo genome assembly. Oases takes contigs assembled using Velvet and solves sub-graphs caused by transcript isoforms to build transcripts.<\/p>\n<p>\u00a0<\/p>\n<p>Use Velvet to assemble reads at multiple kmer sizes (21, 23, 25, 27, 29, 31, 35, 41, 51, 61, 71, 81, 91, 101, 111, 121), then use Oases to assemble contigs into transcripts.<\/p>\n<p>\u00a0<\/p>\n<p>Assembly statistics are contained in the file 'stats.txt'.<\/p>\n<p>\u00a0<\/p>\n<p>Velvet:<br \/>Download - <a href=\"https:\/\/www.ebi.ac.uk\/~zerbino\/velvet\/\" target=\"_blank\">https:\/\/www.ebi.ac.uk\/~zerbino\/velvet\/<\/a>\u00a0(ver1.2.10)<br \/>Documentation - <a href=\"http:\/\/www.ebi.ac.uk\/~zerbino\/velvet\/Manual.pdf\" target=\"_blank\">http:\/\/www.ebi.ac.uk\/~zerbino\/velvet\/Manual.pdf<\/a><br \/>Reference - Velvet: algorithms for de novo short read assembly using de Bruijn graphs. D.R. Zerbino and E. Birney. Genome Research 18:821-829.<\/p>\n<p>\u00a0<\/p>\n<p>Oases:<br \/>Download - <a href=\"http:\/\/www.ebi.ac.uk\/~zerbino\/oases\/\" target=\"_blank\">http:\/\/www.ebi.ac.uk\/~zerbino\/oases\/<\/a>\u00a0(ver0.2.08)<br \/>Documentation - <a href=\"http:\/\/www.ebi.ac.uk\/~zerbino\/oases\/OasesManual.pdf\" target=\"_blank\">http:\/\/www.ebi.ac.uk\/~zerbino\/oases\/OasesManual.pdf<\/a><br \/>Reference -M.H. Schulz, D.R. Zerbino, M. Vingron and Ewan Birney. Oases: Robust de novo RNA-seq assembly across the dynamic range of expression levels. Bioinformatics, 2012. DOI: 10.1093\/bioinformatics\/bts094.<\/p>\n<p>\u00a0<\/p>","order_id":"0","name":"Description","data_by_id":"0","type_id":"1","source_data":{"description":"<p style=\"text-align: justify;\">Velvet is a de Bruijn graph based short-read assembler\u00a0designed for\u00a0de novo genome assembly. Oases takes contigs assembled using Velvet and solves sub-graphs caused by transcript isoforms to build transcripts.<\/p>\n<p>\u00a0<\/p>\n<p>Use Velvet to assemble reads at multiple kmer sizes (21, 23, 25, 27, 29, 31, 35, 41, 51, 61, 71, 81, 91, 101, 111, 121), then use Oases to assemble contigs into transcripts.<\/p>\n<p>\u00a0<\/p>\n<p>Assembly statistics are contained in the file 'stats.txt'.<\/p>\n<p>\u00a0<\/p>\n<p>Velvet:<br \/>Download - <a href=\"https:\/\/www.ebi.ac.uk\/~zerbino\/velvet\/\" target=\"_blank\">https:\/\/www.ebi.ac.uk\/~zerbino\/velvet\/<\/a>\u00a0(ver1.2.10)<br \/>Documentation - <a href=\"http:\/\/www.ebi.ac.uk\/~zerbino\/velvet\/Manual.pdf\" target=\"_blank\">http:\/\/www.ebi.ac.uk\/~zerbino\/velvet\/Manual.pdf<\/a><br \/>Reference - Velvet: algorithms for de novo short read assembly using de Bruijn graphs. D.R. Zerbino and E. Birney. Genome Research 18:821-829.<\/p>\n<p>\u00a0<\/p>\n<p>Oases:<br \/>Download - <a href=\"http:\/\/www.ebi.ac.uk\/~zerbino\/oases\/\" target=\"_blank\">http:\/\/www.ebi.ac.uk\/~zerbino\/oases\/<\/a>\u00a0(ver0.2.08)<br \/>Documentation - <a href=\"http:\/\/www.ebi.ac.uk\/~zerbino\/oases\/OasesManual.pdf\" target=\"_blank\">http:\/\/www.ebi.ac.uk\/~zerbino\/oases\/OasesManual.pdf<\/a><br \/>Reference -M.H. Schulz, D.R. Zerbino, M. Vingron and Ewan Birney. Oases: Robust de novo RNA-seq assembly across the dynamic range of expression levels. Bioinformatics, 2012. DOI: 10.1093\/bioinformatics\/bts094.<\/p>\n<p>\u00a0<\/p>"},"is_project":0},{"component_id":"429361","previous_id":"429365","original_id":"0","guid":"111A00E3BEC84717ADCDF067E862B182","previous_guid":"7492F22A86ED4E529CFB1D860DAE48E4","component_type_id":"6","data_id":"0","data":"Assembling reads with Velvet \/ Oases","order_id":"1","name":"Section","data_by_id":"0","type_id":"6","source_data":{"section":"Assembling reads with Velvet \/ Oases"},"is_project":0},{"component_id":"429455","previous_id":"429361","original_id":"0","guid":"58D2211D24954ADB9E2B7700DD02CF6A","previous_guid":"111A00E3BEC84717ADCDF067E862B182","component_type_id":"15","data_id":"1598","data":"","order_id":"2","name":"Command","data_by_id":"1","type_id":"15","source_data":{"name":"#Download velvet\ncd $PROGRAMDIR\nwget http:\/\/www.ebi.ac.uk\/~zerbino\/velvet\/velvet_1.2.10.tgz -O velvet_1.2.10.tar.gz\n#unpack\ntar zxvf velvet_1.2.10.tar.gz && cd velvet_1.2.10\n#specify number of threads to use for assembly and set variables for velvet\nexport OMP_NUM_THREADS=31\nexport OMP_THREAD_LIMIT=32\nmake 'MAXKMERLENGTH=141' 'BIGASSEMBLY=1' 'OPENMP=1' 'LONGSEQUENCES=1'\n#add binaries to a directory contained in PATH, or add current directory to PATH\necho export PATH=\\$PATH:`pwd`\\ >> ~\/.bashrc && source ~\/.bashrc\n\n#Download Oases\ncd $PROGRAMDIR\ngit clone --recursive https:\/\/github.com\/dzerbino\/oases.git\ncd oases\nexport OMP_NUM_THREADS=31\nexport OMP_THREAD_LIMIT=32\nmake 'MAXKMERLENGTH=141' 'BIGASSEMBLY=1' 'OPENMP=1' 'LONGSEQUENCES=1'\n#add binary to a directory contained in PATH, or add current directory to PATH\necho export PATH=\\$PATH:`pwd`\\ >> ~\/.bashrc && source ~\/.bashrc\n\n#Run velveth\ncd $WORKDIR\/cleaned_trimmed_reads\/\nmkdir velvet-oases_output && cd velvet-oases_output\/\n~\/velvet_1.2.10\/velveth dir 21,37,2 -shortPaired -fastq -separate ..\/R1_pairedout.fastq ..\/R2_pairedout.fastq 1>velveth_21-35.log 2>velveth_21-35.err\n~\/velvet_1.2.10\/velveth dir 41,131,10 -fastq -shortPaired -separate ..\/R1_pairedout.fastq ..\/R2_pairedout.fastq 1>velveth_41-121.log 2>velveth_41-121.err\n\n#Run velvetg\ncd $WORKDIR\/cleaned_trimmed_reads\/velvet-oases_output\/\nfor f in dir_*; do velvetg $f -read_trkg yes -ins_length 215 1>$f.log 2>$f.err; done\n\n#Run Oases (include insert length calculated in step 8)\ncd $WORKDIR\/cleaned_trimmed_reads\/velvet-oases_output\/\nfor f in dir_*; do oases $f -min_trans_lgth 100 -ins_length 215 1>oases_$f.log 2>oases_$f.err; done","description":"","os_name":"Unix","os_version":"bash","can_edit":"1"},"is_project":0}]},{"id":"296298","is_changed":"0","original_id":"0","is_skipped":"0","is_checked":"0","guid":"877292AD7129416FA951FA63EC60A91E","previous_guid":"800BFC842BF54A418AE23CBF2047DF62","previous_id":"259115","last_modified":"1488676060","components":[{"component_id":"430277","previous_id":0,"original_id":"0","guid":"3AF56BFC43484C7299789C456E3FB85B","previous_guid":null,"component_type_id":"1","data_id":"0","data":"<p>Align reads to assembled transcripts using Bowtie to provide\u00a0a measure of transcript 'completeness', and to calculate the\u00a0average insert size if unknown (required for Velvet \/ Oases).\u00a0Bowtie is a fast, memory-efficient short read aligner and Picard tools is a collection of command line utilities for processing next-gen sequencing data.<\/p>\n<p>\u00a0<\/p>\n<p>Bowtie:<br \/>Download - <a href=\"https:\/\/sourceforge.net\/projects\/bowtie-bio\/files\/bowtie\/1.2.0\/\" target=\"_blank\">https:\/\/sourceforge.net\/projects\/bowtie-bio\/files\/bowtie\/1.2.0\/<\/a>\u00a0(ver1.2)<br \/>Documentation - <a href=\"http:\/\/bowtie-bio.sourceforge.net\/index.shtml\" target=\"_blank\">http:\/\/bowtie-bio.sourceforge.net\/index.shtml<\/a><br \/>Reference - Langmead B, Trapnell C, Pop M, Salzberg SL. Ultrafast and memory-efficient alignment of short DNA sequences to the human genome. Genome Biol 10:R25.<\/p>\n<p>\u00a0<\/p>\n<p>Picard tools:<br \/>Download - <a href=\"https:\/\/broadinstitute.github.io\/picard\/\" target=\"_blank\">https:\/\/broadinstitute.github.io\/picard\/<\/a>\u00a0(ver2.1.1)<br \/>Documentation - <a href=\"https:\/\/broadinstitute.github.io\/picard\/command-line-overview.html\" target=\"_blank\">https:\/\/broadinstitute.github.io\/picard\/command-line-overview.html<\/a><br \/>Reference - https:\/\/broadinstitute.github.io\/picard\/<\/p>\n<p>\u00a0<\/p>","order_id":"0","name":"Description","data_by_id":"0","type_id":"1","source_data":{"description":"<p>Align reads to assembled transcripts using Bowtie to provide\u00a0a measure of transcript 'completeness', and to calculate the\u00a0average insert size if unknown (required for Velvet \/ Oases).\u00a0Bowtie is a fast, memory-efficient short read aligner and Picard tools is a collection of command line utilities for processing next-gen sequencing data.<\/p>\n<p>\u00a0<\/p>\n<p>Bowtie:<br \/>Download - <a href=\"https:\/\/sourceforge.net\/projects\/bowtie-bio\/files\/bowtie\/1.2.0\/\" target=\"_blank\">https:\/\/sourceforge.net\/projects\/bowtie-bio\/files\/bowtie\/1.2.0\/<\/a>\u00a0(ver1.2)<br \/>Documentation - <a href=\"http:\/\/bowtie-bio.sourceforge.net\/index.shtml\" target=\"_blank\">http:\/\/bowtie-bio.sourceforge.net\/index.shtml<\/a><br \/>Reference - Langmead B, Trapnell C, Pop M, Salzberg SL. Ultrafast and memory-efficient alignment of short DNA sequences to the human genome. Genome Biol 10:R25.<\/p>\n<p>\u00a0<\/p>\n<p>Picard tools:<br \/>Download - <a href=\"https:\/\/broadinstitute.github.io\/picard\/\" target=\"_blank\">https:\/\/broadinstitute.github.io\/picard\/<\/a>\u00a0(ver2.1.1)<br \/>Documentation - <a href=\"https:\/\/broadinstitute.github.io\/picard\/command-line-overview.html\" target=\"_blank\">https:\/\/broadinstitute.github.io\/picard\/command-line-overview.html<\/a><br \/>Reference - https:\/\/broadinstitute.github.io\/picard\/<\/p>\n<p>\u00a0<\/p>"},"is_project":0},{"component_id":"430207","previous_id":"430277","original_id":"0","guid":"7B400473EC1B4E8AB57B0EEC187F7AE5","previous_guid":"3AF56BFC43484C7299789C456E3FB85B","component_type_id":"6","data_id":"0","data":"Align reads to Trinity.fasta","order_id":"1","name":"Section","data_by_id":"0","type_id":"6","source_data":{"section":"Align reads to Trinity.fasta"},"is_project":0},{"component_id":"430434","previous_id":"430207","original_id":"0","guid":"6113471945884A82B25F2BBA4CA8D58D","previous_guid":"7B400473EC1B4E8AB57B0EEC187F7AE5","component_type_id":"15","data_id":"1599","data":"","order_id":"2","name":"Command","data_by_id":"1","type_id":"15","source_data":{"name":"#Install Bowtie with anaconda\nconda install bowtie\n#install bowtie from tarball\ncd $PROGRAMDIR\nwget https:\/\/downloads.sourceforge.net\/project\/bowtie-bio\/bowtie\/1.2.0\/bowtie-1.2-linux-x86_64.zip -O bowtie-1.2.zip\n#unpack\nunzip bowtie-1.2.zip && cd bowtie-1.2\n#add binaries to a directory contained in PATH, or add current directory to PATH\necho export PATH=\\$PATH:`pwd`\\ >> ~\/.bashrc && source ~\/.bashrc\n\n#Install Picard tools using linuxbrew\nbrew install picard-tools\n#install from source\nwget https:\/\/github.com\/broadinstitute\/picard\/releases\/download\/2.1.1\/picard-tools-2.1.1.zip -O picard-tools-2.1.1.zip\nunzip picard-tools-2.1.1.zip\n#add java binaries to a directory contained in PATH, or add current directory to PATH\necho export PATH=\\$PATH:`pwd`\\ >> ~\/.bashrc && source ~\/.bashrc\n\n#Build a bowtie alignment database\ncd $WORKDIR\/cleaned_trimmed_reads\/Trinity-DN\/\nbowtie-build Trinity.fasta Trinity_bowtie\n\n#Run bowtie to align fastq reads to the assembly\nbowtie -q --phred33-quals -n 2 -e 99999999 -l 25 -I 1 -X 1000 -p 20 -a -m 200 --chunkmbs 128 -S Trinity_bowtie -1 R1_pairedout.fastq -2 R2_pairedout.fastq trinity_backmap_paired.sam 1>bowtie_trinity_backmapping.log 2>bowtie_trinity_backmapping.err\n\n#Convert alignment file in SAM format (human readable) to BAM format (binary)\nsamtools view -bS trinity_backmap_paired.sam > trinity_backmap_paired.bam && rm trinity_backmap_paired.sam\n\n#Classify alignments as properly paired (i.e. on the same contig with a reasonable insert length), aligned, or not aligned using the samtools flagstat tool\nsamtools flagstat trinity_backmap_paired.bam > trinity_backmap_paired_flagstat.txt\n\n#Calculate the average insert size\njava -jar picard.jar CollectInsertSizeMetrics I=Trinity_backmap_paired.bam O=insert_size_output.txt H=insert_size_output.pdf M=0.5","description":"","os_name":"Unix","os_version":"bash","can_edit":"1"},"is_project":0}]},{"id":"309366","is_changed":"0","original_id":"0","is_skipped":"0","is_checked":"0","guid":"A536DCD8F04643B6B4FB9D1CE5647FB7","previous_guid":"7E5BE0EF826D4FBDAA570C4122588A7D","previous_id":"296089","last_modified":"1488583069","components":[{"component_id":"454799","previous_id":0,"original_id":"0","guid":"F538980B86884DE0AF0A5431793EF64F","previous_guid":null,"component_type_id":"1","data_id":"0","data":"<p>Reduce transcript redundancy\u00a0using the CD-HIT algorithm.\u00a0CD-HIT is used to cluster similar biological sequences together, reducing sequence redundancy and improving the performance and accuracy of specific downstream sequence analyses.<\/p>\n<p>\u00a0<\/p>\n<p>De novo assembly often produces highly similar sequences. These can be biological, for example transcript isoforms and transcripts from the same family, or artifacts of the assembly process, such as chimeric transcripts, unsupported insertions, incomplete\/fragmented\/misassembled or duplicate transcripts. The threshold for clustering\u00a0depends on the specific analysis being performed: to cluster\u00a0exact\u00a0duplicates a threshold of '1.0' is used, to cluster transcripts that are share 99% similarity a threshold of '0.99' is used, and so on.<\/p>\n<p>\u00a0<\/p>\n<p>CD-HIT-EST:<br \/>Download - <a href=\"https:\/\/github.com\/weizhongli\/cdhit\" target=\"_blank\">https:\/\/github.com\/weizhongli\/cdhit<\/a>\u00a0(ver4.6.4)<br \/>Documentation -\u00a0<a href=\"http:\/\/weizhongli-lab.org\/lab-wiki\/doku.php?\" target=\"_blank\">http:\/\/weizhongli-lab.org\/lab-wiki\/doku.php?<\/a><\/p>\n<p>Reference - 'Cd-hit: a fast program for clustering and comparing large sets of protein or nucleotide sequences', Weizhong Li &amp; Adam Godzik Bioinformatics, (2006) 22:1658-9. \/ Limin Fu, Beifang Niu, Zhengwei Zhu, Sitao Wu and Weizhong Li, CD-HIT: accelerated for clustering the next generation sequencing data. Bioinformatics, (2012), 28 (23): 3150-3152. doi: 10.1093\/bioinformatics\/bts565.<\/p>\n<p>\u00a0<\/p>\n<p>*All analyses and validation steps described in\u00a0this protocol use 'un-clustered' assembly .fasta files.<\/p>\n<p>\u00a0 \u00a0<\/p>","order_id":"0","name":"Description","data_by_id":"0","type_id":"1","source_data":{"description":"<p>Reduce transcript redundancy\u00a0using the CD-HIT algorithm.\u00a0CD-HIT is used to cluster similar biological sequences together, reducing sequence redundancy and improving the performance and accuracy of specific downstream sequence analyses.<\/p>\n<p>\u00a0<\/p>\n<p>De novo assembly often produces highly similar sequences. These can be biological, for example transcript isoforms and transcripts from the same family, or artifacts of the assembly process, such as chimeric transcripts, unsupported insertions, incomplete\/fragmented\/misassembled or duplicate transcripts. The threshold for clustering\u00a0depends on the specific analysis being performed: to cluster\u00a0exact\u00a0duplicates a threshold of '1.0' is used, to cluster transcripts that are share 99% similarity a threshold of '0.99' is used, and so on.<\/p>\n<p>\u00a0<\/p>\n<p>CD-HIT-EST:<br \/>Download - <a href=\"https:\/\/github.com\/weizhongli\/cdhit\" target=\"_blank\">https:\/\/github.com\/weizhongli\/cdhit<\/a>\u00a0(ver4.6.4)<br \/>Documentation -\u00a0<a href=\"http:\/\/weizhongli-lab.org\/lab-wiki\/doku.php?\" target=\"_blank\">http:\/\/weizhongli-lab.org\/lab-wiki\/doku.php?<\/a><\/p>\n<p>Reference - 'Cd-hit: a fast program for clustering and comparing large sets of protein or nucleotide sequences', Weizhong Li &amp; Adam Godzik Bioinformatics, (2006) 22:1658-9. \/ Limin Fu, Beifang Niu, Zhengwei Zhu, Sitao Wu and Weizhong Li, CD-HIT: accelerated for clustering the next generation sequencing data. Bioinformatics, (2012), 28 (23): 3150-3152. doi: 10.1093\/bioinformatics\/bts565.<\/p>\n<p>\u00a0<\/p>\n<p>*All analyses and validation steps described in\u00a0this protocol use 'un-clustered' assembly .fasta files.<\/p>\n<p>\u00a0 \u00a0<\/p>"},"is_project":0},{"component_id":"454744","previous_id":"454799","original_id":"0","guid":"74DE43EDF5AA4856B05B72AA5B77584B","previous_guid":"F538980B86884DE0AF0A5431793EF64F","component_type_id":"6","data_id":"0","data":"Remove redundant transcripts","order_id":"1","name":"Section","data_by_id":"0","type_id":"6","source_data":{"section":"Remove redundant transcripts"},"is_project":0},{"component_id":"455193","previous_id":"454744","original_id":"0","guid":"9A9F1DE7CF5147F9B06A9DD12CD32E96","previous_guid":"74DE43EDF5AA4856B05B72AA5B77584B","component_type_id":"15","data_id":"1614","data":"","order_id":"2","name":"Command","data_by_id":"1","type_id":"15","source_data":{"name":"#Install CD-HIT-EST\ncd $PROGRAMDIR\ngit clone --recursive https:\/\/github.com\/weizhongli\/cdhit.git\ncd cdhit\nmake\n#add binaries to a directory contained in PATH, or add current directory to PATH\necho export PATH=\\$PATH:`pwd`\\ >> ~\/.bashrc && source ~\/.bashrc\n\n#for SOAPdenovo-Trans\ncd $WORKDIR\/cleaned_trimmed_reads\/SOAPdenovo-Trans_output\/ && mkdir SOAP_cdhit\nfor f in SOAP*\/*.contig; do cd-hit-est -i $f -o SOAP_cdhit\/clustered_95_$f -c 0.95 -n 8 -p 1 -g 1 -M 200000 -T 12 -d 40 1>SOAP_cdhit\/$f.log 2>SOAP_cdhit\/$f.err; done\n\n#for Trinity\ncd $WORKDIR\/cleaned_trimmed_reads\/Trinity-DN\/ && mkdir trinity_cdhit\ncd-hit-est -i Trinity.fasta -o trinity_cdhit\/Trinity_clustered_0.95 -c 0.95 -n 8 -p 1 -g 1 -M 200000 -T 12 -d 40 1>trinity_cdhit\/Trinity_cd-hit-est_0.95.log 2>trinity_cdhit\/Trinity_cd-hit-est_0.95.err\n\n#for Velvet\/Oases\ncd $WORKDIR\/cleaned_trimmed_reads\/velvet-oases_output\/ && mkdir velvet-oases_cdhit\nfor f in dir_*; do cd-hit-est -i $f\/transcripts.fa -o velvet-oases_cdhit\/clustered_95_$f -c 0.95 -n 8 -p 1 -g 1 -M 200000 -T 12 -d 40 1>velvet-oases_cdhit\/$f.log 2>velvet-oases_cdhit\/$f.err; done","description":"","os_name":"Unix","os_version":"bash","can_edit":"1"},"is_project":0}]},{"id":"309748","is_changed":"0","original_id":"0","is_skipped":"0","is_checked":"0","guid":"4A42582C7D4F4AB387CD6625F816C8E7","previous_guid":"A536DCD8F04643B6B4FB9D1CE5647FB7","previous_id":"309366","last_modified":"1488274206","components":[{"component_id":"455549","previous_id":0,"original_id":"0","guid":"747BAB56D41E48578173AC61DAC39ADA","previous_guid":null,"component_type_id":"1","data_id":"0","data":"<p>Run\u00a0GapCloser on the SOAPdenovo-Trans assemblies. GapCloser is bundled with SOAPdenovo2, and removes\u00a0strings of 'N' introduced in\u00a0transcripts during scaffolding by SOAPdenovo-Trans. Removal of these gaps\u00a0can improve accuracy and performance in specific downstream analysis. GapCloser is designed to\u00a0remove assembly artifacts (N's) using the abundant pair relationships of short reads.<\/p>\n<p>\u00a0<\/p>\n<p>GapCloser:<\/p>\n<p>Download - <a href=\"https:\/\/sourceforge.net\/projects\/soapdenovo2\/files\/GapCloser\/\" target=\"_blank\">https:\/\/sourceforge.net\/projects\/soapdenovo2\/files\/GapCloser\/<\/a>\u00a0(ver1.12-r6)<br \/>Documentation - Read the GapCloser_Manual.pdf in GapCloser-bin-v1.12-r6.tgz<br \/>Reference - Luo, R., Liu, B., Xie, Y., Li, Z., Huang, W., Yuan, J., He, G., Chen, Y., Pan, Q., Liu, Y. and Tang, J., 2012. SOAPdenovo2: an empirically improved memory-efficient short-read de novo assembler. Gigascience, 1(1), p.18.<\/p>\n<p>\u00a0<\/p>\n<p>*Use of 'non-GapClosed' or 'post-GapClosed' SOAPdenovo-Trans assemblies\u00a0depends\u00a0on the analyses applied. In many cases the inclusion\u00a0of long strings of 'N' will cause errors or poor performance: if this occurs, use the GapClosed assemblies.<\/p>\n<p>\u00a0<\/p>","order_id":"0","name":"Description","data_by_id":"0","type_id":"1","source_data":{"description":"<p>Run\u00a0GapCloser on the SOAPdenovo-Trans assemblies. GapCloser is bundled with SOAPdenovo2, and removes\u00a0strings of 'N' introduced in\u00a0transcripts during scaffolding by SOAPdenovo-Trans. Removal of these gaps\u00a0can improve accuracy and performance in specific downstream analysis. GapCloser is designed to\u00a0remove assembly artifacts (N's) using the abundant pair relationships of short reads.<\/p>\n<p>\u00a0<\/p>\n<p>GapCloser:<\/p>\n<p>Download - <a href=\"https:\/\/sourceforge.net\/projects\/soapdenovo2\/files\/GapCloser\/\" target=\"_blank\">https:\/\/sourceforge.net\/projects\/soapdenovo2\/files\/GapCloser\/<\/a>\u00a0(ver1.12-r6)<br \/>Documentation - Read the GapCloser_Manual.pdf in GapCloser-bin-v1.12-r6.tgz<br \/>Reference - Luo, R., Liu, B., Xie, Y., Li, Z., Huang, W., Yuan, J., He, G., Chen, Y., Pan, Q., Liu, Y. and Tang, J., 2012. SOAPdenovo2: an empirically improved memory-efficient short-read de novo assembler. Gigascience, 1(1), p.18.<\/p>\n<p>\u00a0<\/p>\n<p>*Use of 'non-GapClosed' or 'post-GapClosed' SOAPdenovo-Trans assemblies\u00a0depends\u00a0on the analyses applied. In many cases the inclusion\u00a0of long strings of 'N' will cause errors or poor performance: if this occurs, use the GapClosed assemblies.<\/p>\n<p>\u00a0<\/p>"},"is_project":0},{"component_id":"455544","previous_id":"455549","original_id":"0","guid":"35CD81F47A1843489C6BBC7E1AF11377","previous_guid":"747BAB56D41E48578173AC61DAC39ADA","component_type_id":"6","data_id":"0","data":"Remove SOAPdenovo-Trans 'gaps'","order_id":"1","name":"Section","data_by_id":"0","type_id":"6","source_data":{"section":"Remove SOAPdenovo-Trans 'gaps'"},"is_project":0},{"component_id":"455703","previous_id":"455544","original_id":"0","guid":"DBC428128BEA4721859F6BEDBD8C8BE5","previous_guid":"35CD81F47A1843489C6BBC7E1AF11377","component_type_id":"15","data_id":"1615","data":"","order_id":"2","name":"Command","data_by_id":"1","type_id":"15","source_data":{"name":"#Download and install GapCloser\ncd $PROGRAMDIR\nwget https:\/\/sourceforge.net\/projects\/soapdenovo2\/files\/GapCloser\/src\/r6\/GapCloser-src-v1.12-r6.tgz\/download --no-check-certificate -O GapCloser.tar.gz\ntar zxvf GapCloser.tar.gz\ncd v1.12-r6 && make\n#add binaries to a directory contained in PATH, or add current directory to PATH\ncd bin && echo export PATH=\\$PATH:`pwd`\\ >> ~\/.bashrc && source ~\/.bashrc\n\n#Copy assemblies to a single directory and rename to *.fasta\ncd $WORKDIR\/cleaned_trimmed_reads\/SOAPdenovo-Trans_output\/\nmkdir SOAP_assembly_fasta_files\nfor f in SOAP*; do cp $f\/*.scafSeq SOAP_assembly_fasta_files; done\ncd SOAP_assembly_fasta_files\nfor f in *.scafSeq; do mv $f $(echo $f | sed 's\/.scafSeq\/.fasta\/g'); done\n\n#Create a config file (similar to Step 5)\ncd $WORKDIR\/cleaned_trimmed_reads\/SOAPdenovo-Trans_output\/SOAP_assembly_fasta_files\ncat > GapCloser.config <<END_TEXT\nmax_rd_len=150\n[LIB]\navg_ins=192\nreverse_seq=0\nasm_flags=3\nq1=$WORKDIR\/cleaned_trimmed_reads\/R1_pairedout.fastq\nq2=$WORKDIR\/cleaned_trimmed_reads\/R2_pairedout.fastq\nEND_TEXT\n\n#Run GapCloser\ncd $WORKDIR\/cleaned_trimmed_reads\/SOAPdenovo-Trans_output\/SOAP_assembly_fasta_file\nfor f in *.fasta; do GapCloser -b GapCloser.config -a $f -o GapClosed_$f -l 150 -t 24 1>GapCloser_{$f}.log 2>GapCloser_{$f}.err; done","description":"","os_name":"Unix","os_version":"bash","can_edit":"1"},"is_project":0}]},{"id":"309941","is_changed":"0","original_id":"0","is_skipped":"0","is_checked":"0","guid":"1B59524BDC484125A99E994DB7E9D953","previous_guid":"C1E50585FE2F4B06853093656CF09D74","previous_id":"313973","last_modified":"1488164912","components":[{"component_id":"456042","previous_id":0,"original_id":"0","guid":"440B0E82BAD9429AA8C0FE4AD153356B","previous_guid":null,"component_type_id":"1","data_id":"0","data":"<p>Search all assemblies for the presence\/absence of\u00a0Benchmarking Universal Single-Copy Orthologs (BUSCOs). BUSCO provides a quantitative measure of transcriptome quality and completeness, based on evolutionarily-informed expectations of gene content from near-universal single-copy orthologs selected from OrthoDB v9.<\/p>\n<p>\u00a0<\/p>\n<p>Aligned BUSCOs are classified\u00a0as\u00a0'complete', 'fragmented', or 'missing'. 'Complete' genes are further categorised as 'single' or 'duplicate', with genomes ideally\u00a0containing a single copy of each gene (transcriptomes often have multiple copies of transcripts). This tool provides a genome-free\/reference-free validation of transcriptome assembly quality, and allows comparison between\u00a0multiple assemblies.<\/p>\n<p>\u00a0<\/p>\n<p>\u00a0<\/p>\n<p>BUSCO:<br \/>Download - <a href=\"https:\/\/gitlab.com\/ezlab\/busco\" target=\"_blank\">https:\/\/gitlab.com\/ezlab\/busco<\/a>\u00a0(ver1.22)<br \/>Documentation - <a href=\"http:\/\/busco.ezlab.org\/\" target=\"_blank\">http:\/\/busco.ezlab.org\/<\/a><\/p>\n<p>Requirements - species-specific genesets\u00a0(from\u00a0<a href=\"http:\/\/busco.ezlab.org\/\" target=\"_blank\">http:\/\/busco.ezlab.org\/<\/a>)<br \/>Reference - Sim\u00e3o, F.A., Waterhouse, R.M., Ioannidis, P., Kriventseva, E.V. and Zdobnov, E.M., 2015. BUSCO: assessing genome assembly and annotation completeness with single-copy orthologs. Bioinformatics, p.btv351.<\/p>\n<p>\u00a0<\/p>","order_id":"0","name":"Description","data_by_id":"0","type_id":"1","source_data":{"description":"<p>Search all assemblies for the presence\/absence of\u00a0Benchmarking Universal Single-Copy Orthologs (BUSCOs). BUSCO provides a quantitative measure of transcriptome quality and completeness, based on evolutionarily-informed expectations of gene content from near-universal single-copy orthologs selected from OrthoDB v9.<\/p>\n<p>\u00a0<\/p>\n<p>Aligned BUSCOs are classified\u00a0as\u00a0'complete', 'fragmented', or 'missing'. 'Complete' genes are further categorised as 'single' or 'duplicate', with genomes ideally\u00a0containing a single copy of each gene (transcriptomes often have multiple copies of transcripts). This tool provides a genome-free\/reference-free validation of transcriptome assembly quality, and allows comparison between\u00a0multiple assemblies.<\/p>\n<p>\u00a0<\/p>\n<p>\u00a0<\/p>\n<p>BUSCO:<br \/>Download - <a href=\"https:\/\/gitlab.com\/ezlab\/busco\" target=\"_blank\">https:\/\/gitlab.com\/ezlab\/busco<\/a>\u00a0(ver1.22)<br \/>Documentation - <a href=\"http:\/\/busco.ezlab.org\/\" target=\"_blank\">http:\/\/busco.ezlab.org\/<\/a><\/p>\n<p>Requirements - species-specific genesets\u00a0(from\u00a0<a href=\"http:\/\/busco.ezlab.org\/\" target=\"_blank\">http:\/\/busco.ezlab.org\/<\/a>)<br \/>Reference - Sim\u00e3o, F.A., Waterhouse, R.M., Ioannidis, P., Kriventseva, E.V. and Zdobnov, E.M., 2015. BUSCO: assessing genome assembly and annotation completeness with single-copy orthologs. Bioinformatics, p.btv351.<\/p>\n<p>\u00a0<\/p>"},"is_project":0},{"component_id":"456033","previous_id":"456042","original_id":"0","guid":"FE9811DD6D4D4151B023D84DA26CCD0E","previous_guid":"440B0E82BAD9429AA8C0FE4AD153356B","component_type_id":"6","data_id":"0","data":"Search for BUSCOs","order_id":"1","name":"Section","data_by_id":"0","type_id":"6","source_data":{"section":"Search for BUSCOs"},"is_project":0},{"component_id":"456046","previous_id":"456033","original_id":"0","guid":"52AA4E69F14346AFA7F6E9000766B1F0","previous_guid":"FE9811DD6D4D4151B023D84DA26CCD0E","component_type_id":"15","data_id":"1616","data":"","order_id":"2","name":"Command","data_by_id":"1","type_id":"15","source_data":{"name":"#For easy install use homebrew \/ linuxbrew (http:\/\/linuxbrew.sh\/)\ncd $PROGRAMDIR\nbrew install busco\n#to download and install from source\ncd $PROGRAMDIR\nwget https:\/\/gitlab.com\/ezlab\/busco\/repository\/archive.tar.gz?ref=master -O BUSCO.tar.gz\ntar -zxvf BUSCO.tar.gz && rm BUSCO.tar.gz && mv busco* BUSCO_v1.22\ncd BUSCO_v1.22\necho export PATH=\\$PATH:`pwd`\\ >> ~\/.bashrc && source ~\/.bashrc\n\n#Download the required BUSCO catalogue (eg vertebrata and\/or eukaryota) and unpack\ncd $PROGRAMDIR\/BUSCO_v1.22\/\nwget http:\/\/busco.ezlab.org\/v1\/files\/eukaryota_buscos.tar.gz -O eukaryota.tar.gz\nwget http:\/\/busco.ezlab.org\/v1\/files\/vertebrata_buscos.tar.gz -O vertebrata.tar.gz\ntar -zxvf *.tar.gz\n\n#Run busco\ncd $WORKDIR\/cleaned_trimmed_reads\/all_assemblies\nfor f in *.fasta; do python BUSCO_v1.22.py -o busco_vert_$f -i $f -l $PROGRAMDIR\/BUSCO_v1.22\/vertebrata -m tran -c 32 -f 1>{$f}_busco_vert.log 2>{$f}_busco_vert.err; done\n\nfor f in *.fasta; do python BUSCO_v1.22.py -o busco_euk_$f -i $f -l $PROGRAMDIR\/BUSCO_v1.22\/eukaryota -m tran -c 32 -f 1>{$f}_busco_euk.log 2>{$f}_busco_euk.err; done","description":"","os_name":"Unix","os_version":"bash","can_edit":"1"},"is_project":0}]},{"id":"313726","is_changed":"0","original_id":"0","is_skipped":"0","is_checked":"0","guid":"F16C6F884DAA4084947E09A1FA60B5B1","previous_guid":"1B59524BDC484125A99E994DB7E9D953","previous_id":"309941","last_modified":"1488587130","components":[{"component_id":"463448","previous_id":0,"original_id":"0","guid":"2577A8E171FB4093B26720F54E92A19C","previous_guid":null,"component_type_id":"1","data_id":"0","data":"<p>Run CEGMA on assemblies to identify the presence\/absence of core eukaryotic genes. The most\u00a0accurate and complete transcriptome assemblies are expected to contain a greater number of\u00a0CEGMA core genes. CEGMA is considered deprecated software: it is no longer supported, and has effectively been\u00a0superseded by BUSCO, however CEGMA scores may still be useful for comparing new transcriptome assemblies to previously established assemblies.<\/p>\n<p>\u00a0<\/p>\n<p>CEGMA is difficult to install; a guide can be found at http:\/\/korflab.ucdavis.edu\/datasets\/cegma\/ubuntu_instructions_1.txt<\/p>\n<p>Additional information on compiling genewise is available at http:\/\/seqanswers.com\/forums\/archive\/index.php\/t-24027.html<\/p>\n<p>\u00a0<\/p>\n<p>CEGMA:<br \/>Download - <a href=\"http:\/\/korflab.ucdavis.edu\/datasets\/cegma\/#SCT3\" target=\"_blank\">http:\/\/korflab.ucdavis.edu\/datasets\/cegma\/#SCT3<\/a>\u00a0(ver2.5)<br \/>Documentation - <a href=\"http:\/\/korflab.ucdavis.edu\/datasets\/cegma\/README\" target=\"_blank\">http:\/\/korflab.ucdavis.edu\/datasets\/cegma\/README<\/a> \/ <a href=\"http:\/\/korflab.ucdavis.edu\/Datasets\/cegma\/faq.html\" target=\"_blank\">http:\/\/korflab.ucdavis.edu\/Datasets\/cegma\/faq.html<\/a><\/p>\n<p>Requirements - there are a number of dependancies, as detailed in the install guide.<br \/>Reference - G. Parra, K. Bradnam and I. Korf. 'CEGMA: a pipeline to accurately annotate core genes in eukaryotic genomes.'<br \/>Bioinformatics, 23: 1061-1067 (2007) \/\u00a0Genis Parra, Keith Bradnam, Zemin Ning, Thomas Keane, and Ian Korf. Assessing the gene space in draft genomes' Nucleic Acids Research, 37(1): 298-297 (2009)<\/p>\n<p>\u00a0<\/p>","order_id":"0","name":"Description","data_by_id":"0","type_id":"1","source_data":{"description":"<p>Run CEGMA on assemblies to identify the presence\/absence of core eukaryotic genes. The most\u00a0accurate and complete transcriptome assemblies are expected to contain a greater number of\u00a0CEGMA core genes. CEGMA is considered deprecated software: it is no longer supported, and has effectively been\u00a0superseded by BUSCO, however CEGMA scores may still be useful for comparing new transcriptome assemblies to previously established assemblies.<\/p>\n<p>\u00a0<\/p>\n<p>CEGMA is difficult to install; a guide can be found at http:\/\/korflab.ucdavis.edu\/datasets\/cegma\/ubuntu_instructions_1.txt<\/p>\n<p>Additional information on compiling genewise is available at http:\/\/seqanswers.com\/forums\/archive\/index.php\/t-24027.html<\/p>\n<p>\u00a0<\/p>\n<p>CEGMA:<br \/>Download - <a href=\"http:\/\/korflab.ucdavis.edu\/datasets\/cegma\/#SCT3\" target=\"_blank\">http:\/\/korflab.ucdavis.edu\/datasets\/cegma\/#SCT3<\/a>\u00a0(ver2.5)<br \/>Documentation - <a href=\"http:\/\/korflab.ucdavis.edu\/datasets\/cegma\/README\" target=\"_blank\">http:\/\/korflab.ucdavis.edu\/datasets\/cegma\/README<\/a> \/ <a href=\"http:\/\/korflab.ucdavis.edu\/Datasets\/cegma\/faq.html\" target=\"_blank\">http:\/\/korflab.ucdavis.edu\/Datasets\/cegma\/faq.html<\/a><\/p>\n<p>Requirements - there are a number of dependancies, as detailed in the install guide.<br \/>Reference - G. Parra, K. Bradnam and I. Korf. 'CEGMA: a pipeline to accurately annotate core genes in eukaryotic genomes.'<br \/>Bioinformatics, 23: 1061-1067 (2007) \/\u00a0Genis Parra, Keith Bradnam, Zemin Ning, Thomas Keane, and Ian Korf. Assessing the gene space in draft genomes' Nucleic Acids Research, 37(1): 298-297 (2009)<\/p>\n<p>\u00a0<\/p>"},"is_project":0},{"component_id":"463440","previous_id":"463448","original_id":"0","guid":"9EC318EF6D664BF0BD48FE41D8643CD8","previous_guid":"2577A8E171FB4093B26720F54E92A19C","component_type_id":"6","data_id":"0","data":"Search for CEGMAs","order_id":"1","name":"Section","data_by_id":"0","type_id":"6","source_data":{"section":"Search for CEGMAs"},"is_project":0},{"component_id":"463616","previous_id":"463440","original_id":"0","guid":"0FECA1FF27F04CC28468ADC024B4FD08","previous_guid":"9EC318EF6D664BF0BD48FE41D8643CD8","component_type_id":"15","data_id":"1617","data":"","order_id":"2","name":"Command","data_by_id":"1","type_id":"15","source_data":{"name":"#Download and install CEGMA\ncd $PROGRAMDIR\nwget http:\/\/korflab.ucdavis.edu\/datasets\/cegma\/CEGMA_v2.5.tar.gz\ntar zxvf CEGMA_v2.5.tar.gz\nrm CEGMA_v2.5.tar.gz && CEGMA_v2.5\nmake\n#add executables to a directory contained in PATH, or add current directory to PATH \ncd bin && echo export PATH=\\$PATH:`pwd`\\ >> ~\/.bashrc && source ~\/.bashrc\n\n###Ensure all required dependencies are installed as detailed in the installation guide\n\n#Run CEGMA on each assembly\ncd $WORKDIR\/cleaned_trimmed_reads\/all_assemblies\nmkdir cegma_output\nfor f in *.fasta; do mkdir cegma_output\/dir_$f && cp $f cegma_output\/dir_$f; done\ncd $WORKDIR\/cleaned_trimmed_reads\/all_assemblies\/cegma_output\nexport CEGMA=$PROGRAMDIR\/cegma\nfor f in $WORKDIR\/cleaned_trimmed_reads\/all_assemblies\/cegma_output\/dir_*\/*.fasta; do ~\/cegma\/bin\/cegma --genome $f -o $WORKDIR\/cleaned_trimmed_reads\/all_assemblies\/cegma_output\/dir_*\/cegma_$f -T 32; done\n#If the 'for loop' fails, run CEGMA on assemblies individually","description":"","os_name":"Unix","os_version":"bash","can_edit":"1"},"is_project":0}]},{"id":"313973","is_changed":"0","original_id":"0","is_skipped":"0","is_checked":"0","guid":"C1E50585FE2F4B06853093656CF09D74","previous_guid":"4A42582C7D4F4AB387CD6625F816C8E7","previous_id":"309748","last_modified":"1527161921","components":[{"component_id":"499621","previous_id":0,"original_id":"0","guid":"AFDDE9063E6242C4A3BF3877487D662F","previous_guid":null,"component_type_id":"1","data_id":"0","data":"<p>Move all transcriptome assemblies to a single directory. Use the EvidentialGene tr2aacds pipeline and\/or Transfuse to identify high-quality, non-redundant transcripts from all single-kmer assemblies, and combine these to form a 'merged' or 'clustered' assembly.\u00a0EvidentialGene tr2aacds.pl processes de novo\u00a0assemblies with different kmer sizes (and from different assemblers), into the most biologically useful 'best' set of mRNA, classified into primary and alternate transcripts. Similarly,\u00a0Transfuse intelligently merges multiple de novo transcriptome assemblies, combining 'high-grade' transcripts\u00a0into a single high quality transcriptome.<\/p>\n<p>\u00a0<\/p>\n<p>EvidentialGene tr2aacds<\/p>\n<p>Download - <a href=\"http:\/\/arthropods.eugenes.org\/genes2\/about\/EvidentialGene_trassembly_pipe.html\" target=\"_blank\">http:\/\/arthropods.eugenes.org\/genes2\/about\/EvidentialGene_trassembly_pipe.html<\/a><\/p>\n<p>Documentation - <a href=\"http:\/\/arthropods.eugenes.org\/genes2\/about\/EvidentialGene_trassembly_pipe.html\" target=\"_blank\">http:\/\/arthropods.eugenes.org\/EvidentialGene\/evigene\/<\/a><\/p>\n<p>Reference -\u00a0Gilbert, Donald (2013) Gene-omes built from mRNA seq not genome DNA. 7th annual arthropod genomics symposium. Notre Dame. http:\/\/arthropods.eugenes.org\/EvidentialGene\/about\/EvigeneRNA2013poster.pdf and http:\/\/globalhealth.nd.edu\/7th-annual-arthropod-genomics-symposium\/ and doi:10.7490\/f1000research.1112594.1 \/ Gilbert D. (2016) Accurate &amp; complete gene construction with EvidentialGene. <br \/> Talk at Galaxy Community Conference 2016, Bloomington IN. F1000Research, 5:1567 (slide set). doi:10.7490\/f1000research.1112467.1 http:\/\/eugenes.org\/EvidentialGene\/about\/evigene_bothgalmod1606iu.pdf (Galaxy+GMOD full slide set)<\/p>\n<p>\u00a0<\/p>\n<p>Transfuse<\/p>\n<p>Download - <a href=\"https:\/\/github.com\/cboursnell\/transfuse\/releases\/\" target=\"_blank\">https:\/\/github.com\/cboursnell\/transfuse\/releases\/<\/a>\u00a0(ver0.5.0)<\/p>\n<p>Documentation - <a href=\"https:\/\/github.com\/cboursnell\/transfuse\" target=\"_blank\">https:\/\/github.com\/cboursnell\/transfuse<\/a><\/p>\n<p>Requirements - dependencies are bundled with the transfuse tarball<\/p>\n<p>Reference -\u00a0https:\/\/github.com\/cboursnell\/transfuse<\/p>\n<p>\u00a0<\/p>","order_id":"0","name":"Description","data_by_id":"0","type_id":"1","source_data":{"description":"<p>Move all transcriptome assemblies to a single directory. Use the EvidentialGene tr2aacds pipeline and\/or Transfuse to identify high-quality, non-redundant transcripts from all single-kmer assemblies, and combine these to form a 'merged' or 'clustered' assembly.\u00a0EvidentialGene tr2aacds.pl processes de novo\u00a0assemblies with different kmer sizes (and from different assemblers), into the most biologically useful 'best' set of mRNA, classified into primary and alternate transcripts. Similarly,\u00a0Transfuse intelligently merges multiple de novo transcriptome assemblies, combining 'high-grade' transcripts\u00a0into a single high quality transcriptome.<\/p>\n<p>\u00a0<\/p>\n<p>EvidentialGene tr2aacds<\/p>\n<p>Download - <a href=\"http:\/\/arthropods.eugenes.org\/genes2\/about\/EvidentialGene_trassembly_pipe.html\" target=\"_blank\">http:\/\/arthropods.eugenes.org\/genes2\/about\/EvidentialGene_trassembly_pipe.html<\/a><\/p>\n<p>Documentation - <a href=\"http:\/\/arthropods.eugenes.org\/genes2\/about\/EvidentialGene_trassembly_pipe.html\" target=\"_blank\">http:\/\/arthropods.eugenes.org\/EvidentialGene\/evigene\/<\/a><\/p>\n<p>Reference -\u00a0Gilbert, Donald (2013) Gene-omes built from mRNA seq not genome DNA. 7th annual arthropod genomics symposium. Notre Dame. http:\/\/arthropods.eugenes.org\/EvidentialGene\/about\/EvigeneRNA2013poster.pdf and http:\/\/globalhealth.nd.edu\/7th-annual-arthropod-genomics-symposium\/ and doi:10.7490\/f1000research.1112594.1 \/ Gilbert D. (2016) Accurate &amp; complete gene construction with EvidentialGene. <br \/> Talk at Galaxy Community Conference 2016, Bloomington IN. F1000Research, 5:1567 (slide set). doi:10.7490\/f1000research.1112467.1 http:\/\/eugenes.org\/EvidentialGene\/about\/evigene_bothgalmod1606iu.pdf (Galaxy+GMOD full slide set)<\/p>\n<p>\u00a0<\/p>\n<p>Transfuse<\/p>\n<p>Download - <a href=\"https:\/\/github.com\/cboursnell\/transfuse\/releases\/\" target=\"_blank\">https:\/\/github.com\/cboursnell\/transfuse\/releases\/<\/a>\u00a0(ver0.5.0)<\/p>\n<p>Documentation - <a href=\"https:\/\/github.com\/cboursnell\/transfuse\" target=\"_blank\">https:\/\/github.com\/cboursnell\/transfuse<\/a><\/p>\n<p>Requirements - dependencies are bundled with the transfuse tarball<\/p>\n<p>Reference -\u00a0https:\/\/github.com\/cboursnell\/transfuse<\/p>\n<p>\u00a0<\/p>"},"is_project":0},{"component_id":"464087","previous_id":"499621","original_id":"0","guid":"F3035C0657184C1192BF3ACE54BA3FA7","previous_guid":"AFDDE9063E6242C4A3BF3877487D662F","component_type_id":"6","data_id":"0","data":"Merge single k-mer assemblies","order_id":"1","name":"Section","data_by_id":"0","type_id":"6","source_data":{"section":"Merge single k-mer assemblies"},"is_project":0},{"component_id":"500117","previous_id":"464087","original_id":"0","guid":"2B0C88BE60AE40059C077867EFFD7832","previous_guid":"F3035C0657184C1192BF3ACE54BA3FA7","component_type_id":"15","data_id":"1628","data":"","order_id":"2","name":"Command","data_by_id":"1","type_id":"15","source_data":{"name":"#Download and install EvidentialGene tr2aacds\nwget ftp:\/\/arthropods.eugenes.org\/evigene.tar\ntar xvf evigene.tar\ncd evigene\/\n#add executables from scripts directory and subdirectories to PATH\necho export PATH=$PATH$( find $PROGRAMDIR\/evigene\/scripts\/ -type d -printf \":%p\" ) >> ~\/.bashrc\n\n#Concatenate all fasta assembly files\ncd $WORKDIR\/cleaned_trimmed_reads\nmkdir all_assemblies\ncd SOAPdenovo-Trans_output\/SOAP_assembly_fasta_files\ncp SOAP_* ..\/..\/all_assemblies; done\ncd ..\/..\/velvet-oases_output\nmkdir velvet-oases_fasta_files\nfor f in dir_*; do mv $f\/transcripts.fa $f\/velvet-oases_{$f}.fasta; done\nfor f in dir_*; do cp $f\/velvet-oases* velvet-oases_fasta_files; done\ncd velvet-oases_fasta_files && cp *.fasta ..\/..\/all_assemblies\ncd ..\/Trinity-DN\ncp Trinity.fasta ..\/all_assemblies\ncd ..\/all_assemblies\ncat *.fasta > All_assemblies.fasta\nmkdir tr2aacds_merge && mv All_assemblies.fasta tr2aacds_merge\/\n\n#Rename fasta headers\ncd $WORKDIR\/cleaned_trimmed_reads\/all_assemblies\/tr2aacds_merge\/\nperl -ane 'if(\/\\>\/){$a++;print \">Locus_$a\\n\"}else{print;}' All_assemblies.fasta > All_renamed.fasta\n\n#Reformat fasta headers, then run the tr2aacds pipeline\ntrformat.pl -output All_assemblies.tr -input All_renamed.fasta\nrm All_assemblies.fasta All_renamed.fasta\ntr2aacds.pl -mrnaseq All_assemblies.tr -NCPU=40 1>tr2aacds.log 2>tr2aacds.err\n\n#Download and install transfuse using Ruby\ngem install transfuse\n#or, alternatively, from source\nwget https:\/\/github.com\/cboursnell\/transfuse\/releases\/download\/v0.5.0\/transfuse-0.5.0-linux-x86_64.tar.gz -O transfuse.tar.gz\ntar -zxvf transfuse.tar.gz\n#add binary to a directory contained in PATH, or add current directory to PATH\necho export PATH=\\$PATH:`pwd`\\ >> ~\/.bashrc && source ~\/.bashrc\n\n#Run transfuse on the fasta assemblies to merge non-redundant and read-supported contigs together\ncd $WORKDIR\/cleaned_trimmed_reads\/all_assemblies\nmkdir transfuse\nLIST=`ls -m *.fasta | tr -d \" \\t\\n\\r\"`\ntransfuse -a $LIST -l R1_pairedout.fastq -r R2_pairedout.fastq -o transfuse\/transfused_assembly -t 40 1>tfuse.log 2>tfuse.err\n\n#If transfuse fails due to insufficient MCP, symlink snap-aligner from TransRate into the transfuse \/bin\/ directory (or \/ruby*\/gems\/transrate\/ directory if install using Ruby) after editing the snap.rb file to increase MCP as described in Step 15.","description":"","os_name":"Unix","os_version":"bash","can_edit":"1"},"is_project":0},{"component_id":"1038942","previous_id":"500117","original_id":"0","guid":"8F91769422CC4581A9D87B87F838D160","previous_guid":"2B0C88BE60AE40059C077867EFFD7832","component_type_id":"13","data_id":"17103","data":"","order_id":"3","name":"Comment","data_by_id":"1","type_id":"13","source_data":{"annotation_id":"17103","thread_id":"17103","id":"17103","thread_title":"Comment on step 12 of De novo transcriptome assembly workflow","uri":"comment-on-step-12-of-de-novo-transcriptome-assembly","thread_uri":"comment-on-step-12-of-de-novo-transcriptome-assembly","step_id":"313973","protocol_uri":"de-novo-transcriptome-assembly-workflow-ghebt3e","protocol_name":"De novo transcriptome assembly workflow","protocol_name_html":"De novo transcriptome assembly workflow","annotation":"<p>Hello, first of all, great work here thank you for that detailed protocol.<\/p>\n<p>\u00a0<\/p>\n<p>My question is, why we have did cdhit step and then we didn't take its ouput to do this step?<\/p>\n<p>\u00a0<\/p>\n<p>Thank you<\/p>","thread_text":"<p>Hello, first of all, great work here thank you for that detailed protocol.<\/p>\n<p>\u00a0<\/p>\n<p>My question is, why we have did cdhit step and then we didn't take its ouput to do this step?<\/p>\n<p>\u00a0<\/p>\n<p>Thank you<\/p>","body":"<p>Hello, first of all, great work here thank you for that detailed protocol.<\/p>\n<p>\u00a0<\/p>\n<p>My question is, why we have did cdhit step and then we didn't take its ouput to do this step?<\/p>\n<p>\u00a0<\/p>\n<p>Thank you<\/p>","is_private":"0","public_protocol":"1","can_edit":0,"can_delete":"0","show_name":"1","created_date":"1515161187","created_on":"1515161187","modified_on":null,"last_updated":null,"profile_image":"\/img\/avatars\/012.png","full_name":"Pablo Garc\u00eda","affiliation":null,"username":"pablo-garca","email":"jaredmamrot@gmail.com","pa_useranme":"jared-mamrot","comments":[{"comment_type":"1","profile_image":"https:\/\/s3.amazonaws.com\/pr-journal\/d4bef86.jpg","affiliation":"Hudson Institute of Medical Research","full_name":"Jared Mamrot","name":"Jared Mamrot","username":"jared-mamrot","comment_text":"<p>Hi Pablo,<\/p>\n<p>\u00a0<\/p>\n<p>I'm really glad you've found the protocol useful (most of it anyway) and I'm sorry the purpose for CD-HIT isn't clear. Another user has commented on this part of the protocol too so it looks like I need to flag to users somehow.<\/p>\n<p>\u00a0<\/p>\n<p>I used the\u00a0output from CD-HIT-EST\u00a0as a measure of redundancy: I clustered at\u00a0multiple siilarity thresholds\u00a0looking for a reduction in the number of contigs.\u00a0A large reduction in the number of contigs after clustering would indicate the presence of transcript duplicates\/triplicates\/etc in my\u00a0assembly, which would require further efforts to address. This wasn't the case in my project (transcriptome assembly for the spiny mouse) so the post-clustered\u00a0contigs were not used further down the pipeline. I've included this step in case\u00a0the\u00a0protocol is applied to\u00a0other datasets, as the results may be more relevant and indicate further work is required to improve assembly quality by\u00a0reducing transcript redundancy.<\/p>\n<p>\u00a0<\/p>\n<p>For further explanation\u00a0of what the program does and whether it's worth applying in this manner for your specific dataset, please refer to: 'Cd-hit: a fast program for clustering and comparing large sets of protein or nucleotide sequences', Weizhong Li &amp; Adam Godzik Bioinformatics, (2006) 22:1658-9. \/ Limin Fu, Beifang Niu, Zhengwei Zhu, Sitao Wu and Weizhong Li, CD-HIT: accelerated for clustering the next generation sequencing data. Bioinformatics, (2012), 28 (23): 3150-3152. doi: 10.1093\/bioinformatics\/bts565.<\/p>","body":"<p>Hi Pablo,<\/p>\n<p>\u00a0<\/p>\n<p>I'm really glad you've found the protocol useful (most of it anyway) and I'm sorry the purpose for CD-HIT isn't clear. Another user has commented on this part of the protocol too so it looks like I need to flag to users somehow.<\/p>\n<p>\u00a0<\/p>\n<p>I used the\u00a0output from CD-HIT-EST\u00a0as a measure of redundancy: I clustered at\u00a0multiple siilarity thresholds\u00a0looking for a reduction in the number of contigs.\u00a0A large reduction in the number of contigs after clustering would indicate the presence of transcript duplicates\/triplicates\/etc in my\u00a0assembly, which would require further efforts to address. This wasn't the case in my project (transcriptome assembly for the spiny mouse) so the post-clustered\u00a0contigs were not used further down the pipeline. I've included this step in case\u00a0the\u00a0protocol is applied to\u00a0other datasets, as the results may be more relevant and indicate further work is required to improve assembly quality by\u00a0reducing transcript redundancy.<\/p>\n<p>\u00a0<\/p>\n<p>For further explanation\u00a0of what the program does and whether it's worth applying in this manner for your specific dataset, please refer to: 'Cd-hit: a fast program for clustering and comparing large sets of protein or nucleotide sequences', Weizhong Li &amp; Adam Godzik Bioinformatics, (2006) 22:1658-9. \/ Limin Fu, Beifang Niu, Zhengwei Zhu, Sitao Wu and Weizhong Li, CD-HIT: accelerated for clustering the next generation sequencing data. Bioinformatics, (2012), 28 (23): 3150-3152. doi: 10.1093\/bioinformatics\/bts565.<\/p>","anonymously":"0","parent_comment_id":"0","parent_id":"0","comment_id":"2971","id":"2971","created_on":"1516750875","modified_on":null,"comment_rating":null,"can_edit":0,"can_remove":0,"is_private":"0","can_delete":0},{"comment_type":"1","profile_image":"\/img\/avatars\/012.png","affiliation":null,"full_name":"Pablo Garc\u00eda","name":"Pablo Garc\u00eda","username":"pablo-garca","comment_text":"<p>Thank you for your awnser. Yes, I have seen the question of the other user who ask about cdhit when I reach this step. Sorry about that (also) redundant question.<\/p>\n<p>\u00a0<\/p>\n<p>If science were always shared like this protocol, well it could work better.<\/p>","body":"<p>Thank you for your awnser. Yes, I have seen the question of the other user who ask about cdhit when I reach this step. Sorry about that (also) redundant question.<\/p>\n<p>\u00a0<\/p>\n<p>If science were always shared like this protocol, well it could work better.<\/p>","anonymously":"0","parent_comment_id":"2971","parent_id":"2971","comment_id":"2973","id":"2973","created_on":"1516787494","modified_on":null,"comment_rating":null,"can_edit":0,"can_remove":0,"is_private":"0","can_delete":0}]},"is_project":0},{"component_id":"1115206","previous_id":"1038942","original_id":"0","guid":"EF7481E306524730BFB702EDE4357A51","previous_guid":"8F91769422CC4581A9D87B87F838D160","component_type_id":"13","data_id":"18884","data":"","order_id":"4","name":"Comment","data_by_id":"1","type_id":"13","source_data":{"annotation_id":"18884","thread_id":"18884","id":"18884","thread_title":"Comment on step 12 of De novo transcriptome assembly workflow","uri":"comment-on-step-12-of-de-novo-transcriptome-assembly1","thread_uri":"comment-on-step-12-of-de-novo-transcriptome-assembly1","step_id":"313973","protocol_uri":"de-novo-transcriptome-assembly-workflow-ghebt3e","protocol_name":"De novo transcriptome assembly workflow","protocol_name_html":"De novo transcriptome assembly workflow","annotation":"<p>Hi,<br \/> Thank you so much for your detailed protocol. I am having issues with Evigenes that I hope you or someone else here can clarify. First of all, FYI, the ftp site doesn't work and the downloaded file is \"evigenes18may07\" not \"evigene\" (I mention this because this may be helpful to a newbie like me who gets easily derailed if the instructions aren't exact).<br \/> I have 4 assemblies, 2 done with Trinity and 2 with rnaSPAdes. I've concatenated them into one file.<br \/> I made it through the <br \/> #add executables from scripts directory and subdirectories to PATH<br \/> #Concatenate all files (didn't follow your protocol - just concatenated and put it in evigenes18may07 folder)<br \/> #Rename fasta headers (This file is in evigenes10may07 as well)<br \/> <br \/> Now here is where I have a problem<br \/> #Reformat fasta headers<br \/> trformat.pl -output Lpe10_05ALLrenamed.tr -input Lpe10_05RenamedALL.fasta<br \/> <br \/> I get an error: <br \/> \"Can't use an undefined value as a symbol reference at \/home\/me\/evigenes18may07\/scripts\/rnaseq\/trformat.pl line 296\"<br \/> <br \/> <br \/> Incidentally, line 296 of that script is:<br \/> print $outh $_ if($ok); # testformat got here .. bad<\/p>\n<p>Unfortunately, the documentation for evigenes is challenging to follow for me. Any help would be appreciated.<\/p>","thread_text":"<p>Hi,<br \/> Thank you so much for your detailed protocol. I am having issues with Evigenes that I hope you or someone else here can clarify. First of all, FYI, the ftp site doesn't work and the downloaded file is \"evigenes18may07\" not \"evigene\" (I mention this because this may be helpful to a newbie like me who gets easily derailed if the instructions aren't exact).<br \/> I have 4 assemblies, 2 done with Trinity and 2 with rnaSPAdes. I've concatenated them into one file.<br \/> I made it through the <br \/> #add executables from scripts directory and subdirectories to PATH<br \/> #Concatenate all files (didn't follow your protocol - just concatenated and put it in evigenes18may07 folder)<br \/> #Rename fasta headers (This file is in evigenes10may07 as well)<br \/> <br \/> Now here is where I have a problem<br \/> #Reformat fasta headers<br \/> trformat.pl -output Lpe10_05ALLrenamed.tr -input Lpe10_05RenamedALL.fasta<br \/> <br \/> I get an error: <br \/> \"Can't use an undefined value as a symbol reference at \/home\/me\/evigenes18may07\/scripts\/rnaseq\/trformat.pl line 296\"<br \/> <br \/> <br \/> Incidentally, line 296 of that script is:<br \/> print $outh $_ if($ok); # testformat got here .. bad<\/p>\n<p>Unfortunately, the documentation for evigenes is challenging to follow for me. Any help would be appreciated.<\/p>","body":"<p>Hi,<br \/> Thank you so much for your detailed protocol. I am having issues with Evigenes that I hope you or someone else here can clarify. First of all, FYI, the ftp site doesn't work and the downloaded file is \"evigenes18may07\" not \"evigene\" (I mention this because this may be helpful to a newbie like me who gets easily derailed if the instructions aren't exact).<br \/> I have 4 assemblies, 2 done with Trinity and 2 with rnaSPAdes. I've concatenated them into one file.<br \/> I made it through the <br \/> #add executables from scripts directory and subdirectories to PATH<br \/> #Concatenate all files (didn't follow your protocol - just concatenated and put it in evigenes18may07 folder)<br \/> #Rename fasta headers (This file is in evigenes10may07 as well)<br \/> <br \/> Now here is where I have a problem<br \/> #Reformat fasta headers<br \/> trformat.pl -output Lpe10_05ALLrenamed.tr -input Lpe10_05RenamedALL.fasta<br \/> <br \/> I get an error: <br \/> \"Can't use an undefined value as a symbol reference at \/home\/me\/evigenes18may07\/scripts\/rnaseq\/trformat.pl line 296\"<br \/> <br \/> <br \/> Incidentally, line 296 of that script is:<br \/> print $outh $_ if($ok); # testformat got here .. bad<\/p>\n<p>Unfortunately, the documentation for evigenes is challenging to follow for me. Any help would be appreciated.<\/p>","is_private":"0","public_protocol":"1","can_edit":0,"can_delete":"0","show_name":"1","created_date":"1527161919","created_on":"1527161919","modified_on":null,"last_updated":null,"profile_image":"\/img\/avatars\/017.png","full_name":"kat coyk","affiliation":null,"username":"kat-coyk","email":"jaredmamrot@gmail.com","pa_useranme":"jared-mamrot","comments":[{"comment_type":"1","profile_image":"https:\/\/s3.amazonaws.com\/pr-journal\/d4bef86.jpg","affiliation":"Hudson Institute of Medical Research","full_name":"Jared Mamrot","name":"Jared Mamrot","username":"jared-mamrot","comment_text":"<p>Hi Kat,<\/p>\n<p>\u00a0<\/p>\n<p>Thank you for your comments and for your patience waiting for my reply. I have tried a few times to replicate your problems, but the protocol is working normally for me. If you are able to provide some \u2018test data\u2019 I may be more successful in working out a solution (if you haven\u2019t figured it out yourself already).<\/p>\n<p>\u00a0<\/p>\n<p>Regarding your first comment, the FTP site appears to be working normally. When I tried the command \u201cwget <a href=\"ftp:\/\/arthropods.eugenes.org\/evigene.tar\" target=\"_blank\" rel=\"noopener noreferrer\">ftp:\/\/arthropods.eugenes.org\/evigene.tar<\/a>\u201d it downloaded the most up-to-date version of the EviGene software (at the moment, version May 2018), so I\u2019m not sure why it didn\u2019t work for you. What error did you get when you tried this?<\/p>\n<p>\u00a0<\/p>\n<p>Were you able to successfully rename the fasta headers using the perl script? This is important, as trformat.pl expects each contig to have a unique name in a known format (Locus_XX follows Velvet's naming convention - this may explain the error you\u2019re getting, as line 296 is part of a Velvet subroutine). If you\u2019ve renamed the contigs successfully you could try adding \u201c--prefix=velvet\u201d in your command or try skipping the concatenation step, instead using your pre-concatenated assemblies as input e.g. trformat.pl -output all.tr -input Trinity_assembly_1.fasta Trinity_assembly_2.fasta RNAspades_assembly_1.fasta \u2026<\/p>\n<p>\u00a0<\/p>\n<p>Please contact me via email (<a href=\"mailto:jared.mamrot@hudson.org.au\" target=\"_blank\" rel=\"noopener noreferrer\">jared.mamrot@hudson.org.au<\/a>) if you are still getting this problem and we will figure out a solution. Alternatively, you could try the author of the software, Don Gilbert (<a href=\"mailto:gilbertd@bio.indiana.edu\" target=\"_blank\" rel=\"noopener noreferrer\">gilbertd@bio.indiana.edu<\/a>). Otherwise, if you\u2019ve solved it yourself, please post your solution here for others to see.<\/p>\n<p>\u00a0<\/p>\n<p>Thanks,<\/p>\n<p>Jared<\/p>","body":"<p>Hi Kat,<\/p>\n<p>\u00a0<\/p>\n<p>Thank you for your comments and for your patience waiting for my reply. I have tried a few times to replicate your problems, but the protocol is working normally for me. If you are able to provide some \u2018test data\u2019 I may be more successful in working out a solution (if you haven\u2019t figured it out yourself already).<\/p>\n<p>\u00a0<\/p>\n<p>Regarding your first comment, the FTP site appears to be working normally. When I tried the command \u201cwget <a href=\"ftp:\/\/arthropods.eugenes.org\/evigene.tar\" target=\"_blank\" rel=\"noopener noreferrer\">ftp:\/\/arthropods.eugenes.org\/evigene.tar<\/a>\u201d it downloaded the most up-to-date version of the EviGene software (at the moment, version May 2018), so I\u2019m not sure why it didn\u2019t work for you. What error did you get when you tried this?<\/p>\n<p>\u00a0<\/p>\n<p>Were you able to successfully rename the fasta headers using the perl script? This is important, as trformat.pl expects each contig to have a unique name in a known format (Locus_XX follows Velvet's naming convention - this may explain the error you\u2019re getting, as line 296 is part of a Velvet subroutine). If you\u2019ve renamed the contigs successfully you could try adding \u201c--prefix=velvet\u201d in your command or try skipping the concatenation step, instead using your pre-concatenated assemblies as input e.g. trformat.pl -output all.tr -input Trinity_assembly_1.fasta Trinity_assembly_2.fasta RNAspades_assembly_1.fasta \u2026<\/p>\n<p>\u00a0<\/p>\n<p>Please contact me via email (<a href=\"mailto:jared.mamrot@hudson.org.au\" target=\"_blank\" rel=\"noopener noreferrer\">jared.mamrot@hudson.org.au<\/a>) if you are still getting this problem and we will figure out a solution. Alternatively, you could try the author of the software, Don Gilbert (<a href=\"mailto:gilbertd@bio.indiana.edu\" target=\"_blank\" rel=\"noopener noreferrer\">gilbertd@bio.indiana.edu<\/a>). Otherwise, if you\u2019ve solved it yourself, please post your solution here for others to see.<\/p>\n<p>\u00a0<\/p>\n<p>Thanks,<\/p>\n<p>Jared<\/p>","anonymously":"0","parent_comment_id":"0","parent_id":"0","comment_id":"3554","id":"3554","created_on":"1528164961","modified_on":null,"comment_rating":null,"can_edit":0,"can_remove":0,"is_private":"0","can_delete":0}]},"is_project":0}]},{"id":"332474","is_changed":"0","original_id":"0","is_skipped":"0","is_checked":"0","guid":"A54BEA65059941819B21421FEDD0B606","previous_guid":"F16C6F884DAA4084947E09A1FA60B5B1","previous_id":"313726","last_modified":"1488676302","components":[{"component_id":"499744","previous_id":0,"original_id":"0","guid":"EAB1A79C196A4D78BA12810EAC865A0C","previous_guid":null,"component_type_id":"1","data_id":"0","data":"<p>TransRate is software for de-novo transcriptome quality analysis. It examines each\u00a0assembly in detail and reports quality scores for contigs and assemblies, allowing you to identify the optimal assembly, filter out contigs from an assembly that are not supported by the reads, and help decide when to stop trying to improve the assembly.<\/p>\n<p>\u00a0<\/p>\n<p>TransRate:<\/p>\n<p>Download - <a href=\"https:\/\/github.com\/blahah\/transrate\/releases\" target=\"_blank\">https:\/\/github.com\/blahah\/transrate\/releases<\/a>\u00a0(ver1.2)<\/p>\n<p>Documentation - <a href=\"http:\/\/hibberdlab.com\/transrate\/index.html\" target=\"_blank\">http:\/\/hibberdlab.com\/transrate\/index.html<\/a><\/p>\n<p>Requirements - snap-aligner (v1.0beta18), bam-read (v1.0), salmon (v0.6.0), \u00a0vsearch (ver1.8.0): bundled with transrate tarball<\/p>\n<p>Reference -\u00a0TransRate: reference free quality assessment of de-novo transcriptome assemblies (2016). Richard D Smith-Unna, Chris Boursnell, Rob Patro, Julian M Hibberd, Steven Kelly. Genome Research doi: http:\/\/dx.doi.org\/10.1101\/gr.196469.115<\/p>\n<p>\u00a0<\/p>","order_id":"0","name":"Description","data_by_id":"0","type_id":"1","source_data":{"description":"<p>TransRate is software for de-novo transcriptome quality analysis. It examines each\u00a0assembly in detail and reports quality scores for contigs and assemblies, allowing you to identify the optimal assembly, filter out contigs from an assembly that are not supported by the reads, and help decide when to stop trying to improve the assembly.<\/p>\n<p>\u00a0<\/p>\n<p>TransRate:<\/p>\n<p>Download - <a href=\"https:\/\/github.com\/blahah\/transrate\/releases\" target=\"_blank\">https:\/\/github.com\/blahah\/transrate\/releases<\/a>\u00a0(ver1.2)<\/p>\n<p>Documentation - <a href=\"http:\/\/hibberdlab.com\/transrate\/index.html\" target=\"_blank\">http:\/\/hibberdlab.com\/transrate\/index.html<\/a><\/p>\n<p>Requirements - snap-aligner (v1.0beta18), bam-read (v1.0), salmon (v0.6.0), \u00a0vsearch (ver1.8.0): bundled with transrate tarball<\/p>\n<p>Reference -\u00a0TransRate: reference free quality assessment of de-novo transcriptome assemblies (2016). Richard D Smith-Unna, Chris Boursnell, Rob Patro, Julian M Hibberd, Steven Kelly. Genome Research doi: http:\/\/dx.doi.org\/10.1101\/gr.196469.115<\/p>\n<p>\u00a0<\/p>"},"is_project":0},{"component_id":"499733","previous_id":"499744","original_id":"0","guid":"A4217BD7319B4FC18CBED0062E187123","previous_guid":"EAB1A79C196A4D78BA12810EAC865A0C","component_type_id":"6","data_id":"0","data":"Run TransRate","order_id":"1","name":"Section","data_by_id":"0","type_id":"6","source_data":{"section":"Run TransRate"},"is_project":0},{"component_id":"499884","previous_id":"499733","original_id":"0","guid":"8266A8C0C90A4AC78D1C2145F4A7A4AD","previous_guid":"A4217BD7319B4FC18CBED0062E187123","component_type_id":"15","data_id":"1626","data":"","order_id":"2","name":"Command","data_by_id":"1","type_id":"15","source_data":{"name":"#To install using ruby\ncd $PROGRAMDIR\ngem install transrate\ntransrate --install-deps all\n#to install from source\ncd $PROGRAMDIR\nwget https:\/\/bintray.com\/artifact\/download\/blahah\/generic\/transrate-1.0.2-linux-x86_64.tar.gz -O transrate.tar.gz\ntar -zxvf transrate.tar.gz\ncd transrate-1.0.2-linux-x86_64\/bin\n#add executables to a directory contained in PATH, or add current directory to PATH \necho export PATH=\\$PATH:`pwd`\\ >> ~\/.bashrc && source ~\/.bashrc\n\n#Prior to run, edit \/transrate\/lib\/app\/lib\/transrate\/snap.rb to increase MCP \n#edit the function \u201cbuild_paired_cmd\u201d, by finding the line \u201c> cmd << \" -omax 10\" # max alignments per pair\/read\u201d and inserting \u201c> cmd << \" -mcp 10000000\" # maximum candidate pool size\u201d after it.\n\n#Run TransRate\ncd $WORKDIR\/cleaned_trimmed_reads\/all_assemblies\/\nfor f in *.fasta; do transrate --assembly $f --left R1_pairedout.fastq --right R2_pairedout.fastq --output .\/transrate_$f --threads 32 1>trate_$f.log 2>trate_$f.err; done","description":"","os_name":"Unix","os_version":"bash","can_edit":"1"},"is_project":0}]},{"id":"332556","is_changed":"0","original_id":"0","is_skipped":"0","is_checked":"0","guid":"DE376DCEFB684AE8946DD223B44F1D3B","previous_guid":"A54BEA65059941819B21421FEDD0B606","previous_id":"332474","last_modified":"1517316543","components":[{"component_id":"499898","previous_id":0,"original_id":"0","guid":"F2D456A242B644F8BE30233BFFD30B10","previous_guid":null,"component_type_id":"1","data_id":"0","data":"<p>Use Bowtie to align reads to each assembly. The proportion of properly aligned reads is\u00a0stored in the\u00a0*_flagstat.txt files. This provides a general assessment\u00a0of assembly completeness: if many reads align properly (i.e. on the same contig), it suggests the assembly quality is high.<\/p>\n<p>\u00a0<\/p>\n<p>Bowtie:<br \/>Download - <a href=\"https:\/\/sourceforge.net\/projects\/bowtie-bio\/files\/bowtie\/1.2.0\/\" target=\"_blank\">https:\/\/sourceforge.net\/projects\/bowtie-bio\/files\/bowtie\/1.2.0\/<\/a>\u00a0(ver1.2)<br \/>Documentation - <a href=\"http:\/\/bowtie-bio.sourceforge.net\/index.shtml\" target=\"_blank\">http:\/\/bowtie-bio.sourceforge.net\/index.shtml<\/a><br \/>Reference - Langmead B, Trapnell C, Pop M, Salzberg SL. Ultrafast and memory-efficient alignment of short DNA sequences to the human genome. Genome Biol 10:R25.<\/p>\n<p>\u00a0<\/p>","order_id":"0","name":"Description","data_by_id":"0","type_id":"1","source_data":{"description":"<p>Use Bowtie to align reads to each assembly. The proportion of properly aligned reads is\u00a0stored in the\u00a0*_flagstat.txt files. This provides a general assessment\u00a0of assembly completeness: if many reads align properly (i.e. on the same contig), it suggests the assembly quality is high.<\/p>\n<p>\u00a0<\/p>\n<p>Bowtie:<br \/>Download - <a href=\"https:\/\/sourceforge.net\/projects\/bowtie-bio\/files\/bowtie\/1.2.0\/\" target=\"_blank\">https:\/\/sourceforge.net\/projects\/bowtie-bio\/files\/bowtie\/1.2.0\/<\/a>\u00a0(ver1.2)<br \/>Documentation - <a href=\"http:\/\/bowtie-bio.sourceforge.net\/index.shtml\" target=\"_blank\">http:\/\/bowtie-bio.sourceforge.net\/index.shtml<\/a><br \/>Reference - Langmead B, Trapnell C, Pop M, Salzberg SL. Ultrafast and memory-efficient alignment of short DNA sequences to the human genome. Genome Biol 10:R25.<\/p>\n<p>\u00a0<\/p>"},"is_project":0},{"component_id":"499890","previous_id":"499898","original_id":"0","guid":"F817C7933B1D41BAA80E7E076B07B843","previous_guid":"F2D456A242B644F8BE30233BFFD30B10","component_type_id":"6","data_id":"0","data":"Align reads to each assembly","order_id":"1","name":"Section","data_by_id":"0","type_id":"6","source_data":{"section":"Align reads to each assembly"},"is_project":0},{"component_id":"499929","previous_id":"499890","original_id":"0","guid":"82CB1D483F3A45F8BAC684A2E543426E","previous_guid":"F817C7933B1D41BAA80E7E076B07B843","component_type_id":"15","data_id":"1627","data":"","order_id":"2","name":"Command","data_by_id":"1","type_id":"15","source_data":{"name":"#Bowtie download and install detailed at Step 8\n\n#Build an alignment database for each assembly\ncd $WORKDIR\/cleaned_trimmed_reads\/all_assemblies\nfor f in *.fasta; do bowtie-build $f $f_bowtie; done\n\n#Run bowtie and convert output from SAM format (human readable) to BAM format (binary)\nfor f in *.fasta; do bowtie -q --phred33-quals -n 2 -e 99999999 -l 25 -I 1 -X 1000 -p 20 -a -m 200 --chunkmbs 128 -S $f_bowtie -1 $WORKDIR\/cleaned_trimmed_reads\/R1_pairedout.fq -2 $WORKDIR\/cleaned_trimmed_reads\/R2_pairedout.fq $f.sam 1>bowtie_$f_backmapped.log 2>bowtie_$f_backmapping.err && samtools view -bS $f.sam > $f.bam && rm $f.sam; done\n\n#Classify alignments as properly paired (i.e. on the same contig with a reasonable insert length), aligned, or not aligned using the samtools flagstat tool\nfor f in *.bam; do samtools flagstat $f > $f_flagstat.txt; done","description":"","os_name":"Unix","os_version":"bash","can_edit":"1"},"is_project":0},{"component_id":"1049238","previous_id":"499929","original_id":"0","guid":"2BAFFCF0CC64479889CE7FE538651592","previous_guid":"82CB1D483F3A45F8BAC684A2E543426E","component_type_id":"13","data_id":"17356","data":"","order_id":"3","name":"Comment","data_by_id":"1","type_id":"13","source_data":{"annotation_id":"17356","thread_id":"17356","id":"17356","thread_title":"Comment on step 16 of De novo transcriptome assembly workflow","uri":"comment-on-step-16-of-de-novo-transcriptome-assembly","thread_uri":"comment-on-step-16-of-de-novo-transcriptome-assembly","step_id":"332556","protocol_uri":"de-novo-transcriptome-assembly-workflow-ghebt3e","protocol_name":"De novo transcriptome assembly workflow","protocol_name_html":"De novo transcriptome assembly workflow","annotation":"<p>Hello, I have a question related with the pipeline in terms of redundancy reduction.<\/p>\n<p>\u00a0<\/p>\n<p>I have performed these steps:<\/p>\n<p>* Trinity &gt; cdhit &gt; output to merge in my \"final redundant transcriptome\"<\/p>\n<p>* SOAP &gt; gapcloser &gt; cdhit &gt; output to merge in my \"final redundant transcriptome\"<\/p>\n<p>* Velvet-Oases &gt; cdhit &gt; output to merge in my \"final redundant transcriptome\"<\/p>\n<p>* \"final redundant transcriptome\" &gt; EvidentialGene &gt; Transcriptome.okay.tr\/cds\/aa<\/p>\n<p>\u00a0<\/p>\n<p>Since I'm reducing the size of my transcriptome, and also deleting these transcripts which were considered \"not good\", it's normal to found worst mapping % at the end of the pipeline? In my specific case, I came from &gt; 90% in my Trinity.fasta to 70-75% in my Transcriptome.okay.tr<\/p>\n<p>\u00a0<\/p>\n<p>What de you think about apply cd-hit after gapcloser? could be a problem?<\/p>\n<p>\u00a0<\/p>\n<p>Thank you!<\/p>","thread_text":"<p>Hello, I have a question related with the pipeline in terms of redundancy reduction.<\/p>\n<p>\u00a0<\/p>\n<p>I have performed these steps:<\/p>\n<p>* Trinity &gt; cdhit &gt; output to merge in my \"final redundant transcriptome\"<\/p>\n<p>* SOAP &gt; gapcloser &gt; cdhit &gt; output to merge in my \"final redundant transcriptome\"<\/p>\n<p>* Velvet-Oases &gt; cdhit &gt; output to merge in my \"final redundant transcriptome\"<\/p>\n<p>* \"final redundant transcriptome\" &gt; EvidentialGene &gt; Transcriptome.okay.tr\/cds\/aa<\/p>\n<p>\u00a0<\/p>\n<p>Since I'm reducing the size of my transcriptome, and also deleting these transcripts which were considered \"not good\", it's normal to found worst mapping % at the end of the pipeline? In my specific case, I came from &gt; 90% in my Trinity.fasta to 70-75% in my Transcriptome.okay.tr<\/p>\n<p>\u00a0<\/p>\n<p>What de you think about apply cd-hit after gapcloser? could be a problem?<\/p>\n<p>\u00a0<\/p>\n<p>Thank you!<\/p>","body":"<p>Hello, I have a question related with the pipeline in terms of redundancy reduction.<\/p>\n<p>\u00a0<\/p>\n<p>I have performed these steps:<\/p>\n<p>* Trinity &gt; cdhit &gt; output to merge in my \"final redundant transcriptome\"<\/p>\n<p>* SOAP &gt; gapcloser &gt; cdhit &gt; output to merge in my \"final redundant transcriptome\"<\/p>\n<p>* Velvet-Oases &gt; cdhit &gt; output to merge in my \"final redundant transcriptome\"<\/p>\n<p>* \"final redundant transcriptome\" &gt; EvidentialGene &gt; Transcriptome.okay.tr\/cds\/aa<\/p>\n<p>\u00a0<\/p>\n<p>Since I'm reducing the size of my transcriptome, and also deleting these transcripts which were considered \"not good\", it's normal to found worst mapping % at the end of the pipeline? In my specific case, I came from &gt; 90% in my Trinity.fasta to 70-75% in my Transcriptome.okay.tr<\/p>\n<p>\u00a0<\/p>\n<p>What de you think about apply cd-hit after gapcloser? could be a problem?<\/p>\n<p>\u00a0<\/p>\n<p>Thank you!<\/p>","is_private":"0","public_protocol":"1","can_edit":0,"can_delete":"0","show_name":"1","created_date":"1517316542","created_on":"1517316542","modified_on":null,"last_updated":null,"profile_image":"\/img\/avatars\/012.png","full_name":"Pablo Garc\u00eda","affiliation":null,"username":"pablo-garca","email":"jaredmamrot@gmail.com","pa_useranme":"jared-mamrot","comments":[{"comment_type":"1","profile_image":"https:\/\/s3.amazonaws.com\/pr-journal\/d4bef86.jpg","affiliation":"Hudson Institute of Medical Research","full_name":"Jared Mamrot","name":"Jared Mamrot","username":"jared-mamrot","comment_text":"<p>Hi Pablo,<\/p>\n<p>\u00a0<\/p>\n<p>Your reported 70-75% mapping against Transcriptome.okay.tr does sound low, but there are a number of possible explanations for this. Try\u00a0combining Transcriptome.okay.tr with\u00a0Transcriptome.okalt.tr to see if\u00a0this improves\u00a0the mapping rate\u00a0(and other metrics such as the proportion of BUSCOs found \/ TransRate score). If you still don't get &gt;85% I suggest\u00a0running tr2aacds again on your pre-CD-HIT-EST samples (i.e. exclude the CD-HIT-EST output from the tr2aacds step and just use the 'raw' assemblies) and also explore other measures of transcriptome quality such as BUSCO and TransRate scores.<\/p>\n<p>\u00a0<\/p>\n<p>Provided this improves the mapping rate, an additional step to reduce redundancy in the assembly is to remove contigs that are not supported by\u00a0your reads. TransRate is the best method for this (the good.contigs.fa file), or\u00a0you can examine\u00a0your sorted, indexed bam file using 'samtools idxstats' and retain contigs that have a read count &gt;0.<\/p>\n<p>\u00a0<\/p>\n<p>Let me know how you get on.<\/p>\n<p>\u00a0\u00a0<\/p>\n<p>Thanks,<\/p>\n<p>Jared<\/p>\n<p>\u00a0<\/p>","body":"<p>Hi Pablo,<\/p>\n<p>\u00a0<\/p>\n<p>Your reported 70-75% mapping against Transcriptome.okay.tr does sound low, but there are a number of possible explanations for this. Try\u00a0combining Transcriptome.okay.tr with\u00a0Transcriptome.okalt.tr to see if\u00a0this improves\u00a0the mapping rate\u00a0(and other metrics such as the proportion of BUSCOs found \/ TransRate score). If you still don't get &gt;85% I suggest\u00a0running tr2aacds again on your pre-CD-HIT-EST samples (i.e. exclude the CD-HIT-EST output from the tr2aacds step and just use the 'raw' assemblies) and also explore other measures of transcriptome quality such as BUSCO and TransRate scores.<\/p>\n<p>\u00a0<\/p>\n<p>Provided this improves the mapping rate, an additional step to reduce redundancy in the assembly is to remove contigs that are not supported by\u00a0your reads. TransRate is the best method for this (the good.contigs.fa file), or\u00a0you can examine\u00a0your sorted, indexed bam file using 'samtools idxstats' and retain contigs that have a read count &gt;0.<\/p>\n<p>\u00a0<\/p>\n<p>Let me know how you get on.<\/p>\n<p>\u00a0\u00a0<\/p>\n<p>Thanks,<\/p>\n<p>Jared<\/p>\n<p>\u00a0<\/p>","anonymously":"0","parent_comment_id":"0","parent_id":"0","comment_id":"3000","id":"3000","created_on":"1517549615","modified_on":"1517551627","comment_rating":null,"can_edit":0,"can_remove":0,"is_private":"0","can_delete":0},{"comment_type":"1","profile_image":"\/img\/avatars\/012.png","affiliation":null,"full_name":"Pablo Garc\u00eda","name":"Pablo Garc\u00eda","username":"pablo-garca","comment_text":"<p>Hi Jared, thank you for your support to your protocol.<\/p>\n<p>\u00a0<\/p>\n<p>I have tried to mapped combining the okay and alt files. My % of mapped reads grows up to 87% so its okay, thank you.<\/p>\n<p>\u00a0<\/p>\n<p>My next doubt come from Transrate score and good contig subset usage. When I ran Transrate in my original assembly I obtained a low Transrate score and the subset which you have mentiones (good contgis). I took this subset and I ran again Transrate. Efectively, the Transrate score grows a lot so I decide to continue with this subset of good contigs. However, first I wanted to check the % of mapped reads using this good contig subset and what I found was a strong decreasse in my mapping ratio (from 87% to 60%). This make me comeback again to the begining point, which dataset stablish as my \"working transcriptome\".<\/p>\n<p>\u00a0<\/p>\n<p>Should I care a lot of this % mapping reduction when I have a good Transrate score (much better than the previous)?<\/p>\n<p>\u00a0<\/p>\n<p>Apologize me if you find this explanation a little bit confusing, I can repeat it with more details.<\/p>\n<p>\u00a0<\/p>\n<p>Thanks,<\/p>\n<p>Pablo<\/p>","body":"<p>Hi Jared, thank you for your support to your protocol.<\/p>\n<p>\u00a0<\/p>\n<p>I have tried to mapped combining the okay and alt files. My % of mapped reads grows up to 87% so its okay, thank you.<\/p>\n<p>\u00a0<\/p>\n<p>My next doubt come from Transrate score and good contig subset usage. When I ran Transrate in my original assembly I obtained a low Transrate score and the subset which you have mentiones (good contgis). I took this subset and I ran again Transrate. Efectively, the Transrate score grows a lot so I decide to continue with this subset of good contigs. However, first I wanted to check the % of mapped reads using this good contig subset and what I found was a strong decreasse in my mapping ratio (from 87% to 60%). This make me comeback again to the begining point, which dataset stablish as my \"working transcriptome\".<\/p>\n<p>\u00a0<\/p>\n<p>Should I care a lot of this % mapping reduction when I have a good Transrate score (much better than the previous)?<\/p>\n<p>\u00a0<\/p>\n<p>Apologize me if you find this explanation a little bit confusing, I can repeat it with more details.<\/p>\n<p>\u00a0<\/p>\n<p>Thanks,<\/p>\n<p>Pablo<\/p>","anonymously":"0","parent_comment_id":"3000","parent_id":"3000","comment_id":"3022","id":"3022","created_on":"1518438062","modified_on":null,"comment_rating":null,"can_edit":0,"can_remove":0,"is_private":"0","can_delete":0},{"comment_type":"1","profile_image":"https:\/\/s3.amazonaws.com\/pr-journal\/d4bef86.jpg","affiliation":"Hudson Institute of Medical Research","full_name":"Jared Mamrot","name":"Jared Mamrot","username":"jared-mamrot","comment_text":"<p>Hi Pablo,<\/p>\n<p>\u00a0<\/p>\n<p>I can understand your frustration with this problem. In my opinion the decision to use the 'more complete' assembly (i.e. less transrate score, but better mapping) or the 'more accurate' assembly (better transrate score, less assembly artefacts) depends on\u00a0your desired applications.<\/p>\n<p>\u00a0<\/p>\n<p>If you plan to use the assembly as a reference to calculate differential gene expression then I personally have used the 'more complete' assembly then clustered similar transcripts at a later stage using the program Corset (https:\/\/github.com\/Oshlack\/Corset\/wiki). This approach is very effective at reducing the number of contigs you are working with and the Corset program itself is an incredibly elegant solution to this problem, producing gene-level counts that feed into edgeR giving accurate\/meaningful gene expression results.<\/p>\n<p>\u00a0<\/p>\n<p>If you are looking to produce a gene catalogue for your species of interest you will want to use the \"more accurate\" set of contigs. Some of the issues you are concerned about might be explained by other factors (for instance, one of my good.contigs.fa assemblies did not have 18\/28S rRNA sequence, and in my samples I had a relatively large\u00a0number of rRNA as my rRNA depletion was not very effective; this affected mapping, but when I removed the rRNA-specific reads my mapping rate improved to 90%).<\/p>\n<p>\u00a0<\/p>\n<p>You can also do both. In my spiny mouse transcriptome project (the one where this protocol came from) I assembled a large number of transcriptomes and have used different transcriptomes for different purposes. I set up a BLAST website giving users the option to choose the more complete assembly or the more accurate one (https:\/\/spinymouse.erc.monash.edu\/sequenceserver\/).<\/p>\n<p>\u00a0<\/p>\n<p>I hope this answers your question.<\/p>\n<p>\u00a0<\/p>\n<p>Thanks,<\/p>\n<p>Jared<\/p>","body":"<p>Hi Pablo,<\/p>\n<p>\u00a0<\/p>\n<p>I can understand your frustration with this problem. In my opinion the decision to use the 'more complete' assembly (i.e. less transrate score, but better mapping) or the 'more accurate' assembly (better transrate score, less assembly artefacts) depends on\u00a0your desired applications.<\/p>\n<p>\u00a0<\/p>\n<p>If you plan to use the assembly as a reference to calculate differential gene expression then I personally have used the 'more complete' assembly then clustered similar transcripts at a later stage using the program Corset (https:\/\/github.com\/Oshlack\/Corset\/wiki). This approach is very effective at reducing the number of contigs you are working with and the Corset program itself is an incredibly elegant solution to this problem, producing gene-level counts that feed into edgeR giving accurate\/meaningful gene expression results.<\/p>\n<p>\u00a0<\/p>\n<p>If you are looking to produce a gene catalogue for your species of interest you will want to use the \"more accurate\" set of contigs. Some of the issues you are concerned about might be explained by other factors (for instance, one of my good.contigs.fa assemblies did not have 18\/28S rRNA sequence, and in my samples I had a relatively large\u00a0number of rRNA as my rRNA depletion was not very effective; this affected mapping, but when I removed the rRNA-specific reads my mapping rate improved to 90%).<\/p>\n<p>\u00a0<\/p>\n<p>You can also do both. In my spiny mouse transcriptome project (the one where this protocol came from) I assembled a large number of transcriptomes and have used different transcriptomes for different purposes. I set up a BLAST website giving users the option to choose the more complete assembly or the more accurate one (https:\/\/spinymouse.erc.monash.edu\/sequenceserver\/).<\/p>\n<p>\u00a0<\/p>\n<p>I hope this answers your question.<\/p>\n<p>\u00a0<\/p>\n<p>Thanks,<\/p>\n<p>Jared<\/p>","anonymously":"0","parent_comment_id":"3022","parent_id":"3022","comment_id":"3067","id":"3067","created_on":"1519119694","modified_on":null,"comment_rating":null,"can_edit":0,"can_remove":0,"is_private":"0","can_delete":0}]},"is_project":0}]},{"id":"333409","is_changed":"0","original_id":"0","is_skipped":"0","is_checked":"0","guid":"E147E689F2E942E0B081AA4C1FAC8E6A","previous_guid":"DE376DCEFB684AE8946DD223B44F1D3B","previous_id":"332556","last_modified":"1488275852","components":[{"component_id":"502451","previous_id":0,"original_id":"0","guid":"1ABB1E598C79439F9482CF4EDEFAE27D","previous_guid":null,"component_type_id":"1","data_id":"0","data":"<p>Idenitfy the\u00a0most complete and accurate de novo transcriptome assemblies based on BUSCO\/CEGMA scores, transrate scores, and properly paired read alignment, and annotate them\u00a0using the Trinotate or Dammit pipelines. Annotation of transcripts aids inferrence of biological function, for instance\u00a0identifying transcripts that have functional domains\u00a0(Pfam domains), signaling proteins, and transmembrane proteins.<\/p>\n<p>\u00a0<\/p>\n<p>Trinotate is a suite of tools for functional annotation of de novo assembled transcriptomes. Trinotate employs sequence homology search to known transcripts\u00a0(BLAST+\/SwissProt), protein domain identification (HMMER\/PFAM), protein signal peptide and transmembrane domain prediction (signalP\/tmHMM), and leveraging various annotation databases (eggNOG\/GO\/Kegg databases).<\/p>\n<p>\u00a0<\/p>\n<p>Dammit performs essentially the same task:\u00a0it\u00a0is a simple, yet comprehensive, de novo transcriptome annotator born from\u00a0the observations that annotation is time-consuming, mundane and often frustrating, with many\u00a0existing solutions being overly complicated or relying on non-free software.<\/p>\n<p>\u00a0<\/p>\n<p>First, install perl module URI::Escape using cpan or cpanm (curl -L https:\/\/cpanmin.us | perl - App::cpanminus). Download the swissprot\/uniprot database and prepare for blast.<\/p>\n<p>\u00a0<\/p>\n<p>Trinotate:<\/p>\n<p>Download - <a href=\"https:\/\/github.com\/Trinotate\/Trinotate\/releases\" target=\"_blank\">https:\/\/github.com\/Trinotate\/Trinotate\/releases<\/a>\u00a0(ver2.0.2)<\/p>\n<p>Documentation - <a href=\"https:\/\/trinotate.github.io\/\" target=\"_blank\">https:\/\/trinotate.github.io\/<\/a><\/p>\n<p>Requires -\u00a0<a href=\"https:\/\/github.com\/TransDecoder\/TransDecoder\/releases\" target=\"_blank\">transdecoder<\/a>, <a href=\"http:\/\/www.sqlite.org\/\" target=\"_blank\">sqlite<\/a>, <a href=\"https:\/\/www.ncbi.nlm.nih.gov\/books\/NBK52640\/\" target=\"_blank\">ncbi-blast+<\/a>, <a href=\"http:\/\/hmmer.org\/\" target=\"_blank\">HMMER\/PFAM<\/a>, <a href=\"http:\/\/www.cbs.dtu.dk\/cgi-bin\/nph-sw_request?signalp\" target=\"_blank\">signalP<\/a>, <a href=\"http:\/\/www.cbs.dtu.dk\/cgi-bin\/nph-sw_request?tmhmm\" target=\"_blank\">tmhmm<\/a>, <a href=\"http:\/\/www.cbs.dtu.dk\/cgi-bin\/sw_request?rnammer\" target=\"_blank\">RNAmmer<\/a>\u00a0(further details available at\u00a0https:\/\/trinotate.github.io\/)<\/p>\n<p>Reference - <a href=\"https:\/\/trinotate.github.io\/\" target=\"_blank\">https:\/\/trinotate.github.io\/<\/a><\/p>\n<p>\u00a0<\/p>\n<p>Dammit:<\/p>\n<p>Download - <a href=\"https:\/\/github.com\/camillescott\/dammit\" target=\"_blank\">https:\/\/github.com\/camillescott\/dammit<\/a><\/p>\n<p>Documentation - <a href=\"http:\/\/dammit.readthedocs.io\/en\/latest\/\" target=\"_blank\">http:\/\/dammit.readthedocs.io\/en\/latest\/<\/a> ; <a href=\"http:\/\/dammit.readthedocs.io\/en\/latest\/installing.html\" target=\"_blank\">http:\/\/dammit.readthedocs.io\/en\/latest\/installing.html<\/a><\/p>\n<p>Requires - many, many dependencies, run within\u00a0a virtual python environment. Further explained in the doumentation above<\/p>\n<p>Reference - Camille Scott (2016) 'dammit: an open and accessible de novo transcriptome annotator', in preparation; www.camillescott.org\/dammit<\/p>\n<p>\u00a0<\/p>","order_id":"0","name":"Description","data_by_id":"0","type_id":"1","source_data":{"description":"<p>Idenitfy the\u00a0most complete and accurate de novo transcriptome assemblies based on BUSCO\/CEGMA scores, transrate scores, and properly paired read alignment, and annotate them\u00a0using the Trinotate or Dammit pipelines. Annotation of transcripts aids inferrence of biological function, for instance\u00a0identifying transcripts that have functional domains\u00a0(Pfam domains), signaling proteins, and transmembrane proteins.<\/p>\n<p>\u00a0<\/p>\n<p>Trinotate is a suite of tools for functional annotation of de novo assembled transcriptomes. Trinotate employs sequence homology search to known transcripts\u00a0(BLAST+\/SwissProt), protein domain identification (HMMER\/PFAM), protein signal peptide and transmembrane domain prediction (signalP\/tmHMM), and leveraging various annotation databases (eggNOG\/GO\/Kegg databases).<\/p>\n<p>\u00a0<\/p>\n<p>Dammit performs essentially the same task:\u00a0it\u00a0is a simple, yet comprehensive, de novo transcriptome annotator born from\u00a0the observations that annotation is time-consuming, mundane and often frustrating, with many\u00a0existing solutions being overly complicated or relying on non-free software.<\/p>\n<p>\u00a0<\/p>\n<p>First, install perl module URI::Escape using cpan or cpanm (curl -L https:\/\/cpanmin.us | perl - App::cpanminus). Download the swissprot\/uniprot database and prepare for blast.<\/p>\n<p>\u00a0<\/p>\n<p>Trinotate:<\/p>\n<p>Download - <a href=\"https:\/\/github.com\/Trinotate\/Trinotate\/releases\" target=\"_blank\">https:\/\/github.com\/Trinotate\/Trinotate\/releases<\/a>\u00a0(ver2.0.2)<\/p>\n<p>Documentation - <a href=\"https:\/\/trinotate.github.io\/\" target=\"_blank\">https:\/\/trinotate.github.io\/<\/a><\/p>\n<p>Requires -\u00a0<a href=\"https:\/\/github.com\/TransDecoder\/TransDecoder\/releases\" target=\"_blank\">transdecoder<\/a>, <a href=\"http:\/\/www.sqlite.org\/\" target=\"_blank\">sqlite<\/a>, <a href=\"https:\/\/www.ncbi.nlm.nih.gov\/books\/NBK52640\/\" target=\"_blank\">ncbi-blast+<\/a>, <a href=\"http:\/\/hmmer.org\/\" target=\"_blank\">HMMER\/PFAM<\/a>, <a href=\"http:\/\/www.cbs.dtu.dk\/cgi-bin\/nph-sw_request?signalp\" target=\"_blank\">signalP<\/a>, <a href=\"http:\/\/www.cbs.dtu.dk\/cgi-bin\/nph-sw_request?tmhmm\" target=\"_blank\">tmhmm<\/a>, <a href=\"http:\/\/www.cbs.dtu.dk\/cgi-bin\/sw_request?rnammer\" target=\"_blank\">RNAmmer<\/a>\u00a0(further details available at\u00a0https:\/\/trinotate.github.io\/)<\/p>\n<p>Reference - <a href=\"https:\/\/trinotate.github.io\/\" target=\"_blank\">https:\/\/trinotate.github.io\/<\/a><\/p>\n<p>\u00a0<\/p>\n<p>Dammit:<\/p>\n<p>Download - <a href=\"https:\/\/github.com\/camillescott\/dammit\" target=\"_blank\">https:\/\/github.com\/camillescott\/dammit<\/a><\/p>\n<p>Documentation - <a href=\"http:\/\/dammit.readthedocs.io\/en\/latest\/\" target=\"_blank\">http:\/\/dammit.readthedocs.io\/en\/latest\/<\/a> ; <a href=\"http:\/\/dammit.readthedocs.io\/en\/latest\/installing.html\" target=\"_blank\">http:\/\/dammit.readthedocs.io\/en\/latest\/installing.html<\/a><\/p>\n<p>Requires - many, many dependencies, run within\u00a0a virtual python environment. Further explained in the doumentation above<\/p>\n<p>Reference - Camille Scott (2016) 'dammit: an open and accessible de novo transcriptome annotator', in preparation; www.camillescott.org\/dammit<\/p>\n<p>\u00a0<\/p>"},"is_project":0},{"component_id":"502449","previous_id":"502451","original_id":"0","guid":"42DB182557D04CE29AB6093F65F2633B","previous_guid":"1ABB1E598C79439F9482CF4EDEFAE27D","component_type_id":"6","data_id":"0","data":"Annotation","order_id":"1","name":"Section","data_by_id":"0","type_id":"6","source_data":{"section":"Annotation"},"is_project":0},{"component_id":"504464","previous_id":"502449","original_id":"0","guid":"A2F5128A41D84C1193C57981A9E15FE7","previous_guid":"42DB182557D04CE29AB6093F65F2633B","component_type_id":"15","data_id":"1629","data":"","order_id":"2","name":"Command","data_by_id":"1","type_id":"15","source_data":{"name":"#A guide for installing and using Trinotate is available at https:\/\/trinotate.github.io\/\ncd $PROGRAMDIR\ncpan URI::Escape\nwget https:\/\/github.com\/Trinotate\/Trinotate\/archive\/v3.0.1.tar.gz -O Trinotate_v3.0.1.tar.gz\ntar -zxvf Trinotate_v3.0.1.tar.gz && rm Trinotate_v3.0.1.tar.gz\ncd Trinotate_v3.0.1\/sample_data\n.\/runMe.sh\n#ensure 'runMe.sh' test completed successfully, then run:\n.\/cleanMe.pl\ncd $PROGRAMDIR\/Trinotate_v3.0.1\/admin\/\nBuild_Trinotate_Boilerplate_SQLite_db.pl  Trinotate\n\n#add executables from Trinotate directory and subdirectories to PATH\necho export PATH=$PATH$( find $PROGRAMDIR\/Trinotate_v3.0.1\/ -type d -printf \":%p\" ) >> ~\/.bashrc\n\n#Trinotate\n#Identify ORFs using TransDecoder\ncd $WORKDIR\/cleaned_trimmed_reads\/Trinity-DN\/\nTransDecoder.LongOrfs -t Trinity.fasta\n\n#Download, unpack, and build the Uniprot\/Swissprot database\ncd $PROGRAMDIR\nmkdir databases && cd databases\/\nwget ftp:\/\/ftp.uniprot.org\/pub\/databases\/uniprot\/current_release\/knowledgebase\/complete\/uniprot_sprot.fasta.gz && gunzip uniprot_sprot.fasta.gz\nmakeblastdb -in uniprot_sprot.fasta -dbtype prot -parse_seqids\n\n#Blast transcripts against the database to identify potential orthologs\ncd $WORKDIR\/cleaned_trimmed_reads\/Trinity-DN\/\nblastx -query Trinity.fasta -db $PROGRAMDIR\/databases\/uniprot_sprot -evalue 1e-5 -num_threads 40 -max_target_seqs 1 -outfmt 6 > blastx_uniprot_1e05.outfmt6\nblastp -query longest_orfs.pep -db $PROGRAMDIR\/databases\/uniprot_sprot -evalue 1e-5 -num_threads 40 -max_target_seqs 1 -outfmt 6 > blastp_uniprot_1e05.outfmt6\n\n#Use an HMM search to identify PFAM domains in the longest ORFs\nhmmscan --cpu 20 --domtblout TrinotatePFAM.out Pfam-A.hmm longest_orfs.pep\n\n#Use an HMM search to identify PFAM domains in uniprot_sprot blastp hits\nTransDecoder.Predict -t target_transcripts.fasta --retain_pfam_hits TrinotatePFAM.out --retain_blastp_hits blastp_uniprot_1e05.outfmt6\n\n#Identify signalling proteins in the longest ORFs using SignalP\nsignalp -f short -n signalp.out longest_orfs.pep &\n\n#Identify rRNA sequences within the transcriptome using RNAmmer\nRnammerTranscriptome.pl --transcriptome Trinity.fasta --path_to_rnammer $PROGRAMDIR\/rnammer-1.2\/rnammer\n\n#Identify transmembrane proteins using tmhmm\ntmhmm --short < transdecoder.pep > tmhmm.out\n\n#Build the boilerplate trinotate sqlite database\nTrinotate Trinotate.sqlite init --gene_trans_map Trinity.fasta.gene_trans_map --transcript_fasta Trinity.fasta --transdecoder_pep Trinity.fasta.transdecoder_dir\/longest_orfs.pep\n\n#Load annotation results into the SQLite database\nTrinotate Trinotate.sqlite LOAD_swissprot_blastp blastp_uniprot_1e05.outfmt6\nTrinotate Trinotate.sqlite LOAD_swissprot_blastx blastx_uniprot_1e05.outfmt6\nTrinotate Trinotate.sqlite LOAD_pfam TrinotatePFAM.out\nTrinotate Trinotate.sqlite LOAD_signalp signalp.out\nTrinotate Trinotate.sqlite LOAD_tmhmm tmhmm.out\nTrinotate Trinotate.sqlite LOAD_rnammer Trinity.fasta.rnammer.gffTrinotate \n\n#Generate annotation reports\nTrinotate Trinotate.sqlite report > trinotate_annotation_report.xls\nTrinotate Trinotate.sqlite report -E 0.00001 > trinotate_annotation_report_evalue00001.xls\n\n#Extract GO terms from the report\nextract_GO_assignments_from_Trinotate_xls.pl --Trinotate_xls trinotate_annotation_report.xls -G --include_ancestral_terms > go_annotations.txt\n\n#Use trinotate to import transcript name information into the report\nimport_transcript_names.pl Trinotate.sqlite Trinotate_report.xls\n\n#Identify and collate all columns containing a value for each loaded result\nawk '$3 ~ !\/.\/' trinotate_report_ex_GO.xls > trinotate_report_uniprot_hits.xls\nawk '$8 ~ !\/.\/' trinotate_report_ex_GO.xls > trinotate_report_uniprot_protein_hits.xls\nawk '$10 ~ !\/.\/' trinotate_report_ex_GO.xls > trinotate_report_pfam_hits.xls\nawk '$11 ~ !\/.\/' trinotate_report_ex_GO.xls > trinotate_report_signalling_protein_hits.xls\n\n#Include feature names\/IDs\nTrinotate_get_feature_name_encoding_attributes.pl Trinotate_report.xls > Trinotate_report.xls.annotate_ids\n\n#Extract GO term assignments for further analysis\nextract_GO_assignments_from_Trinotate_xls.pl Trinotate_report.xls > Trinotate_GO_assignments.txt\n\n#Dammit\n#Download and install\ncd $PROGRAMDIR\nwget https:\/\/github.com\/camillescott\/dammit\/archive\/v0.3.2.tar.gz -O dammit.tar.gz\ntar -zxvf dammit.tar.gz & rm dammit.tar.gz\ncd dammit-0.3.2\nmake\nsudo apt-get update\nsudo apt-get install python-pip python-dev python-numpy git ruby hmmer unzip infernal ncbi-blast+ liburi-escape-xs-perl emboss liburi-perl build-essential libsm6 libxrender1 libfontconfig1 parallel\nsudo gem install crb-blast\ncurl -LO https:\/\/github.com\/TransDecoder\/TransDecoder\/archive\/2.0.1.tar.gz -O TransDecoder_2.0.1.tar.gz\ntar -xvzf TransDecoder_2.0.1.tar.gz && rm TransDecoder_2.0.1.tar.gz\ncd TransDecoder-2.0.1\nmake\necho 'export PATH=$PATH:$PROGRAMDIR\/TransDecoder-2.0.1' >> ~\/.bashrc\ncurl -LO http:\/\/last.cbrc.jp\/last-658.zip\nunzip last-658.zip\ncd last-658\nmake\necho 'export PATH=$PATH:$PROGRAMDIR\/last-658\/src' >> ~\/.bashrc\ncurl -LO http:\/\/busco.ezlab.org\/v1\/files\/BUSCO_v1.22.tar.gz \ntar -xvzf BUSCO_v1.22.tar.gz\nchmod +x BUSCO_v1.22\/*.py\necho 'export PATH=$PROGRAMDIR\/BUSCO_v1.22:$PATH' >> ~\/.bashrc\nsudo pip install -U setuptools\nsudo pip install dammit\ndammit databases --install --all --busco-group vertebrata\n\n#to get the latest version of dammit: 'pip install git+https:\/\/github.com\/camillescott\/dammit.git'\n\n#load dependencies and virtual python environment per http:\/\/dammit.readthedocs.io\/en\/latest\/installing.html then activate environment\ncd $PROGRAMDIR\nsource activate dammit\n\n#Run dammit\ncd $WORKDIR\/cleaned_trimmed_reads\/Trinity-DN\/\ndammit annotate Trinity.fasta --busco-group eukaryota --n_threads 32 1>dammit_Trinity.log 2>dammit_Trinity.err &","description":"","os_name":"Unix","os_version":"bash","can_edit":"1"},"is_project":0}]},{"id":"336595","is_changed":"0","original_id":"0","is_skipped":"0","is_checked":"0","guid":"ADF7A3ACA1E045539FAF21D22BB23D2D","previous_guid":"E147E689F2E942E0B081AA4C1FAC8E6A","previous_id":"333409","last_modified":"1488676344","components":[{"component_id":"508235","previous_id":0,"original_id":"0","guid":"2B62F30FE77247F5B88E251EA0F26EC1","previous_guid":null,"component_type_id":"1","data_id":"0","data":"<p>Take all blastx hits from annotated transcriptomes with evalue &lt;1e-20, and use the 'analyze_blastPlus_topHit_coverage.pl' script bundled with Trinity to align assembled transcripts to corresponding entries in the Swissprot\/Uniprot database. This metric provides a measure of assembly completeness: if many transcripts are near-full-length compared to the reference transcript\/protein, it suggests the transcripts are well assembled. If few are near-full-length, it suggests transcripts are fragmented\/poorly assembled. This metric is useful for comparing multiple assemblies produced using the same dataset.<\/p>\n<p>\u00a0<\/p>\n<p>Only\u00a0the single best matching Trinity transcript is reported for each top matching database entry. If a target protein matches multiple Trinity transcripts as their best hits, that target protein is counted only once along with that Trinity transcript that provides the highest BLAST bit score and longest match length. Also compare distribution and size of contigs using bundled script 'trinity_component_distribution'.<\/p>\n<p>\u00a0<\/p>","order_id":"0","name":"Description","data_by_id":"0","type_id":"1","source_data":{"description":"<p>Take all blastx hits from annotated transcriptomes with evalue &lt;1e-20, and use the 'analyze_blastPlus_topHit_coverage.pl' script bundled with Trinity to align assembled transcripts to corresponding entries in the Swissprot\/Uniprot database. This metric provides a measure of assembly completeness: if many transcripts are near-full-length compared to the reference transcript\/protein, it suggests the transcripts are well assembled. If few are near-full-length, it suggests transcripts are fragmented\/poorly assembled. This metric is useful for comparing multiple assemblies produced using the same dataset.<\/p>\n<p>\u00a0<\/p>\n<p>Only\u00a0the single best matching Trinity transcript is reported for each top matching database entry. If a target protein matches multiple Trinity transcripts as their best hits, that target protein is counted only once along with that Trinity transcript that provides the highest BLAST bit score and longest match length. Also compare distribution and size of contigs using bundled script 'trinity_component_distribution'.<\/p>\n<p>\u00a0<\/p>"},"is_project":0},{"component_id":"508231","previous_id":"508235","original_id":"0","guid":"68E6CE78AAB94E53A8BD9AC31D63DA8C","previous_guid":"2B62F30FE77247F5B88E251EA0F26EC1","component_type_id":"6","data_id":"0","data":"Counting full-length transcripts","order_id":"1","name":"Section","data_by_id":"0","type_id":"6","source_data":{"section":"Counting full-length transcripts"},"is_project":0},{"component_id":"508249","previous_id":"508231","original_id":"0","guid":"FC774A57F68945A1A7732570A1F0058F","previous_guid":"68E6CE78AAB94E53A8BD9AC31D63DA8C","component_type_id":"15","data_id":"1640","data":"","order_id":"2","name":"Command","data_by_id":"1","type_id":"15","source_data":{"name":"#Parse blastx output to retain transcripts with evalues <=1e-20\ncd $WORKDIR\/cleaned_trimmed_reads\/Trinity-DN\/\nawk \u2018$11 <=1e-20\u2019 blastx_uniprot_1e-05.outfmt6 > blastx_uniprot_1e-20.outfmt6\n\n#Use the script bundled with Trinity to analyse blast hit coverage for each transcript\nanalyze_blastPlus_topHit_coverage.pl blastx.outfmt6_1e-20 Trinity.fasta $WORKDIR\/databases\/uniprot_sprot\n\n#Reformat SOAPdenovo-Trans assemblies for 'trinity_component_distribution.pl'\ncd $WORKDIR\/cleaned_trimmed_reads\/SOAPdenovo-Trans_output\/SOAP_assembly_fasta_files\nfor f in *.fasta; do perl -ane 'if(\/\\>\/){$a++;print \">c$a\\n\"}else{print;}' $f > tmp.fasta && sed 's\/>.*\/&_g1\/' tmp.fasta > {$f}_trinity_format.fasta && rm tmp.fasta; done\nfor f in *_trinity_format.fasta; do trinity_component_distribution.pl $f -o dist_$f 1>comp_distr.log 2>comp_distr.err; done\n\n#Reformat Velvet-oases assemblies for 'trinity_component_distribution.pl'\ncd $WORKDIR\/cleaned_trimmed_reads\/velvet-oases_output\/velvet-oases_fasta_files\nfor f in *.fasta; do perl -ane 'if(\/\\>\/){$a++;print \">c$a\\n\"}else{print;}' $f > tmp.fasta && sed 's\/>.*\/&_g1\/' tmp.fasta > {$f}_trinity_format.fasta && rm tmp.fasta; done\nfor f in *_trinity_format.fasta; do trinity_component_distribution.pl $f -o dist_$f 1>comp_distr.log 2>comp_distr.err; done","description":"","os_name":"Unix","os_version":"bash","can_edit":"1"},"is_project":0}]},{"id":"338164","is_changed":"0","original_id":"0","is_skipped":"0","is_checked":"0","guid":"1EB4D934A6054FABAEC941D49A1B3070","previous_guid":"CDEA336A810249F3AE0376EB12D433EF","previous_id":"353646","last_modified":"1488583086","components":[{"component_id":"511721","previous_id":0,"original_id":"0","guid":"F9ADB7C13E2341B39E426CC5A4DD2A95","previous_guid":null,"component_type_id":"1","data_id":"0","data":"<p>Use the\u00a0NCBI blast+ utility to identify Mus musculus orthologs within spiny mouse transcriptome assemblies. Download the Mus RefSeq protein and RNA catalogues and convert them to blast databases. Run blastn (transcripts vs transcripts) and blastx (transcripts vs proteins), parse the output to retain hits &lt;=1e-20, then identify which transcripts\/proteins in the RefSeq catalogue correspond to one (or more) transcripts in the spiny mouse transcriptome assembly used.<\/p>\n<p>\u00a0<\/p>\n<p>Download -\u00a0<a href=\"ftp:\/\/ftp.ncbi.nlm.nih.gov\/blast\/executables\/blast+\/LATEST\/\" target=\"_blank\">ftp:\/\/ftp.ncbi.nlm.nih.gov\/blast\/executables\/blast+\/LATEST\/<\/a>\u00a0(ver2.6.0)<\/p>\n<p>Documentation - <a href=\"https:\/\/www.ncbi.nlm.nih.gov\/books\/NBK279690\/\" target=\"_blank\">https:\/\/www.ncbi.nlm.nih.gov\/books\/NBK279690\/<\/a><\/p>\n<p>Reference -\u00a0<span style=\"font-weight: 400;\">Altschul et al. (1990) Altschul SF, Gish W, Miller W, Myers EW, Lipman DJ. Basic local alignment search tool. Journal of Molecular Biology. 1990;215(3):403\u2013410. doi: 10.1016\/S0022-2836(05)80360-2.<\/span><\/p>\n<p><span style=\"font-weight: 400;\">Camacho, C., Coulouris, G., Avagyan, V., Ma, N., Papadopoulos, J., Bealer, K. and Madden, T.L., 2009. BLAST+: architecture and applications. BMC bioinformatics, 10(1), p.421.\u00a0<br \/>Madden (2002) Madden T. The BLAST sequence analysis tool. In: McEntyre J, Ostell J, editors. The NCBI Handbook. Bethesda: National Center for Biotechnology Information; 2002. Chapter 16. https:\/\/www.ncbi.nlm.nih.gov\/books\/NBK153387\/<br \/><\/span><\/p>\n<p>\u00a0<\/p>\n<p><span style=\"font-weight: 400;\">\u00a0<\/span><\/p>","order_id":"0","name":"Description","data_by_id":"0","type_id":"1","source_data":{"description":"<p>Use the\u00a0NCBI blast+ utility to identify Mus musculus orthologs within spiny mouse transcriptome assemblies. Download the Mus RefSeq protein and RNA catalogues and convert them to blast databases. Run blastn (transcripts vs transcripts) and blastx (transcripts vs proteins), parse the output to retain hits &lt;=1e-20, then identify which transcripts\/proteins in the RefSeq catalogue correspond to one (or more) transcripts in the spiny mouse transcriptome assembly used.<\/p>\n<p>\u00a0<\/p>\n<p>Download -\u00a0<a href=\"ftp:\/\/ftp.ncbi.nlm.nih.gov\/blast\/executables\/blast+\/LATEST\/\" target=\"_blank\">ftp:\/\/ftp.ncbi.nlm.nih.gov\/blast\/executables\/blast+\/LATEST\/<\/a>\u00a0(ver2.6.0)<\/p>\n<p>Documentation - <a href=\"https:\/\/www.ncbi.nlm.nih.gov\/books\/NBK279690\/\" target=\"_blank\">https:\/\/www.ncbi.nlm.nih.gov\/books\/NBK279690\/<\/a><\/p>\n<p>Reference -\u00a0<span style=\"font-weight: 400;\">Altschul et al. (1990) Altschul SF, Gish W, Miller W, Myers EW, Lipman DJ. Basic local alignment search tool. Journal of Molecular Biology. 1990;215(3):403\u2013410. doi: 10.1016\/S0022-2836(05)80360-2.<\/span><\/p>\n<p><span style=\"font-weight: 400;\">Camacho, C., Coulouris, G., Avagyan, V., Ma, N., Papadopoulos, J., Bealer, K. and Madden, T.L., 2009. BLAST+: architecture and applications. BMC bioinformatics, 10(1), p.421.\u00a0<br \/>Madden (2002) Madden T. The BLAST sequence analysis tool. In: McEntyre J, Ostell J, editors. The NCBI Handbook. Bethesda: National Center for Biotechnology Information; 2002. Chapter 16. https:\/\/www.ncbi.nlm.nih.gov\/books\/NBK153387\/<br \/><\/span><\/p>\n<p>\u00a0<\/p>\n<p><span style=\"font-weight: 400;\">\u00a0<\/span><\/p>"},"is_project":0},{"component_id":"511713","previous_id":"511721","original_id":"0","guid":"B6A024777FFF40C0B565963F2F301AA9","previous_guid":"F9ADB7C13E2341B39E426CC5A4DD2A95","component_type_id":"6","data_id":"0","data":"Compare transcripts to a closely-related species","order_id":"1","name":"Section","data_by_id":"0","type_id":"6","source_data":{"section":"Compare transcripts to a closely-related species"},"is_project":0},{"component_id":"511841","previous_id":"511713","original_id":"0","guid":"ACFB5A7CEF6B43689D4E5C68D7FB92B3","previous_guid":"B6A024777FFF40C0B565963F2F301AA9","component_type_id":"15","data_id":"1651","data":"","order_id":"2","name":"Command","data_by_id":"1","type_id":"15","source_data":{"name":"#Obtain, unpack, and build blast databases for Mus musculus RefSeq sequences\ncd $WORKDIR\/databases\nascp -i ~\/.aspera\/connect\/etc\/asperaweb_id_dsa.openssh -QT -l 100M anonftp@ftp-private.ncbi.nlm.nih.gov:\/refseq\/M_musculus\/mRNA_Prot\/mouse.1.rna.fna.gz anonftp@ftp-private.ncbi.nlm.nih.gov:\/refseq\/M_musculus\/mRNA_Prot\/mouse.1.protein.faa.gz .\ngunzip *.gz\nmakeblastdb -in mouse.1.rna.fna -dbtype nucl -parse_seqids\nmakeblastdb -in mouse.1.protein.faa -dbtype prot -parse_seqids\n\n#Blast transcripts against the RefSeq databases\ncd $WORKDIR\/cleaned_trimmed_reads\/Trinity-DN\nblastn -query Trinity.fasta -db $WORKDIR\/databases\/mouse.1.rna.fna -num_threads 32 -max_target_seqs 1 -outfmt 6 > blastn_Trinity.fasta_vs_mus_musculus_refseq.outfmt6\nblastx -query Trinity.fasta -db mouse.1.protein.faa -num_threads 32 -max_target_seqs 1 -outfmt 6 > blastx_Trinity.fasta_vs_mus_musculus_refseq.outfmt6\n\n#Retain hits at <=1e-20\ncd $WORKDIR\/cleaned_trimmed_reads\/Trinity-DN\nawk \u2018$11 <=1e-20\u2019 blastn_Trinity.fasta_vs_mus_musculus_refseq.outfmt6 > blastn_Trinity.fasta_vs_mus_musculus_refseq_1e-20.outfmt6\nawk \u2018$11 <=1e-20\u2019 blastx_Trinity.fasta_vs_mus_musculus_refseq.outfmt6 > blastx_Trinity.fasta_vs_mus_musculus_refseq_1e-20.outfmt6\n\n#Identify the number of unique RefSeq transcripts with >=1 blast hit in the transcriptome assembly\ncd $WORKDIR\/cleaned_trimmed_reads\/Trinity-DN\ncut -f2 blastn_Trinity.fasta_vs_mus_musculus_refseq_1e-20.outfmt6 | sort | uniq -c | wc -l > count_uniq_blastn_vs_refseq_1e-20_hits.txt\ncut -f2 blastx_Trinity.fasta_vs_mus_musculus_refseq_1e-20.outfmt6 | sort | uniq -c | wc -l > count_uniq_blastx_vs_refseq_1e-20_hits.txt","description":"","os_name":"Unix","os_version":"bash","can_edit":"1"},"is_project":0}]},{"id":"353646","is_changed":"0","original_id":"0","is_skipped":"0","is_checked":"0","guid":"CDEA336A810249F3AE0376EB12D433EF","previous_guid":"ADF7A3ACA1E045539FAF21D22BB23D2D","previous_id":"336595","last_modified":"1489281965","components":[{"component_id":"541658","previous_id":0,"original_id":"0","guid":"E6DDF4741904454E92968115386DCA76","previous_guid":null,"component_type_id":"1","data_id":"0","data":"<p>Blastx is the recommended tool for aligning transcripts to the Uniprot\/Swissprot database, however alignment takes a relatively long time for large transcriptome assemblies (&gt;1 week with 40 threads). A considerably faster tool is DIAMOND ('DIAMOND blastx' is ~20,000X faster than NCBI Blast+ 'blastx').<\/p>\n<p>\u00a0<\/p>\n<p>Download - <a href=\"https:\/\/github.com\/bbuchfink\/diamond\/releases\/\" target=\"_blank\">https:\/\/github.com\/bbuchfink\/diamond\/releases\/<\/a>\u00a0(ver0.8.36)<\/p>\n<p>Documentation - <a href=\"https:\/\/github.com\/bbuchfink\/diamond\" target=\"_blank\">https:\/\/github.com\/bbuchfink\/diamond<\/a><\/p>\n<p>Reference -\u00a0B. Buchfink, Xie C., D. Huson (2015), 'Fast and sensitive protein alignment using DIAMOND', Nature Methods 12, 59-60.<\/p>\n<p>\u00a0<\/p>","order_id":"0","name":"Description","data_by_id":"0","type_id":"1","source_data":{"description":"<p>Blastx is the recommended tool for aligning transcripts to the Uniprot\/Swissprot database, however alignment takes a relatively long time for large transcriptome assemblies (&gt;1 week with 40 threads). A considerably faster tool is DIAMOND ('DIAMOND blastx' is ~20,000X faster than NCBI Blast+ 'blastx').<\/p>\n<p>\u00a0<\/p>\n<p>Download - <a href=\"https:\/\/github.com\/bbuchfink\/diamond\/releases\/\" target=\"_blank\">https:\/\/github.com\/bbuchfink\/diamond\/releases\/<\/a>\u00a0(ver0.8.36)<\/p>\n<p>Documentation - <a href=\"https:\/\/github.com\/bbuchfink\/diamond\" target=\"_blank\">https:\/\/github.com\/bbuchfink\/diamond<\/a><\/p>\n<p>Reference -\u00a0B. Buchfink, Xie C., D. Huson (2015), 'Fast and sensitive protein alignment using DIAMOND', Nature Methods 12, 59-60.<\/p>\n<p>\u00a0<\/p>"},"is_project":0},{"component_id":"541654","previous_id":"541658","original_id":"0","guid":"8132DC6803564795A7614743498405E1","previous_guid":"E6DDF4741904454E92968115386DCA76","component_type_id":"6","data_id":"0","data":"Count full-length transcripts for all assemblies","order_id":"1","name":"Section","data_by_id":"0","type_id":"6","source_data":{"section":"Count full-length transcripts for all assemblies"},"is_project":0},{"component_id":"569055","previous_id":"541654","original_id":"0","guid":"FC638B88C55D4E32B7461571B3987A6C","previous_guid":"8132DC6803564795A7614743498405E1","component_type_id":"13","data_id":"14785","data":"","order_id":"2","name":"Comment","data_by_id":"1","type_id":"13","source_data":{"annotation_id":"14785","thread_id":"14785","id":"14785","thread_title":"Annotation on step 19 of De novo transcriptome assembly workflow","uri":"annotation-on-step-19-of-de-novo-transcriptome-assembly","thread_uri":"annotation-on-step-19-of-de-novo-transcriptome-assembly","step_id":"353646","protocol_uri":"de-novo-transcriptome-assembly-workflow-ghebt3e","protocol_name":"De novo transcriptome assembly workflow","protocol_name_html":"De novo transcriptome assembly workflow","annotation":"<p>Diamond blastx is less sensitive than NCBI BLAST+ blastx, however the significant gain in speed facilitates\u00a0comparison with larger databases, such as the UniRef90 and nr.<\/p>","thread_text":"<p>Diamond blastx is less sensitive than NCBI BLAST+ blastx, however the significant gain in speed facilitates\u00a0comparison with larger databases, such as the UniRef90 and nr.<\/p>","body":"<p>Diamond blastx is less sensitive than NCBI BLAST+ blastx, however the significant gain in speed facilitates\u00a0comparison with larger databases, such as the UniRef90 and nr.<\/p>","is_private":"0","public_protocol":"1","can_edit":0,"can_delete":"0","show_name":"0","created_date":"1489281965","created_on":"1489281965","modified_on":null,"last_updated":null,"profile_image":"https:\/\/s3.amazonaws.com\/pr-journal\/d4bef86.jpg","full_name":"Jared Mamrot","affiliation":"Hudson Institute of Medical Research","username":"jared-mamrot","email":"jaredmamrot@gmail.com","pa_useranme":"jared-mamrot","comments":[]},"is_project":0},{"component_id":"541720","previous_id":"569055","original_id":"0","guid":"BE538444BBD74971AA12D0BA66BF90C2","previous_guid":"FC638B88C55D4E32B7461571B3987A6C","component_type_id":"15","data_id":"1675","data":"","order_id":"3","name":"Command","data_by_id":"1","type_id":"15","source_data":{"name":"#Download and install DIAMOND\ncd $PROGRAMDIR\nmkdir Diamond && cd Diamond\nwget http:\/\/github.com\/bbuchfink\/diamond\/releases\/download\/v0.8.36\/diamond-linux64.tar.gz -O diamond.tar.gz\ntar -zxvf diamond.tar.gz && rm diamond.tar.gz\n#add executables to a directory contained in PATH, or add current directory to PATH \necho export PATH=\\$PATH:`pwd`\\ >> ~\/.bashrc && source ~\/.bashrc\n\n#Prepare the Swissprot\/Uniprot database\ncd $PROGRAMDIR\/databases\/\ndiamond makedb --in uniprot_sprot.fasta -d uniprot_sprot\n\n#run DIAMOND blastx on each assembly\ncd $WORKDIR\/cleaned_trimmed_reads\/all_assemblies\/\nfor f in *.fasta; do diamond blastx -d $PROGRAMDIR\/databases\/uniprot_sprot -q $f -o diamond_$f --sensitive -p 32 -k 1 -e 1e-05 -b 10 -c 1; done\n\n#parse DIAMOND blastx output, retaining transcripts with evalues <=1e-20\nmkdir blast_hits_1e-20\nfor f in diamond*; do awk '$11 <=1e-20' $f > blast_hits_1e-20\/1e-20_$f; done\n\n#analyse transcript length compared to the length of the reference transcript\ncd $WORKDIR\/cleaned_trimmed_reads\/all_assemblies\nfor f in *.fasta; do analyze_blastPlus_topHit_coverage.pl .\/blast_hits_1e-20\/1e-20_diamond_$f $f $PROGRAMDIR\/databases\/uniprot_sprot; done\n\n#count unique blastx hits (i.e. the number of reference transcripts that align to one or more assembled transcripts)\ncd $WORKDIR\/cleaned_trimmed_reads\/all_assemblies\/\nmkdir number_of_unique_blastx_hits\nfor f in diamond_*; do cut -f2 $f | sort | uniq -c | wc -l > .\/number_of_unique_blastx_hits\/count_$f; done\n\ncd $WORKDIR\/cleaned_trimmed_reads\/all_assemblies\/blast_hits_1e-20\/\nmkdir number_of_unique_blastx_hits_1e-20\nfor f in 1e-20_diamond_*; do cut -f2 $f | sort | uniq -c | wc -l > .\/number_of_unique_blastx_hits_1e-20\/count_$f; done","description":"","os_name":"Unix","os_version":"bash","can_edit":"1"},"is_project":0}]},{"id":"355962","is_changed":"0","original_id":"0","is_skipped":"0","is_checked":"0","guid":"5A5057CFD2014890BDE3F34382B6D644","previous_guid":"1EB4D934A6054FABAEC941D49A1B3070","previous_id":"338164","last_modified":"1488795587","components":[{"component_id":"546437","previous_id":0,"original_id":"0","guid":"67AFA937251749228537647C49D023C7","previous_guid":null,"component_type_id":"1","data_id":"0","data":"<p>Use the\u00a0Coding-Non-Coding Index (CNCI) to identify\u00a0non-coding transcripts. CNCI profiles adjoining nucleotide triplets to distinguish protein-coding from\u00a0non-coding sequences, independent of known annotations. Align transcripts to the NONCODE database for <em>Mus musculus<\/em> and identify unique single best blast hits.<\/p>\n<p>\u00a0<\/p>\n<p>CNCI:<\/p>\n<p>Download - <a href=\"https:\/\/github.com\/www-bioinfo-org\/CNCI\" target=\"_blank\">https:\/\/github.com\/www-bioinfo-org\/CNCI<\/a>\u00a0(version 2)<\/p>\n<p>Documentation - <a href=\"https:\/\/github.com\/www-bioinfo-org\/CNCI\" target=\"_blank\">https:\/\/github.com\/www-bioinfo-org\/CNCI<\/a><\/p>\n<p>Reference -\u00a0Liang Sun, Haitao Luo, Dechao Bu, Guoguang Zhao, Kuntao Yu, Changhai Zhang, Yuanning Liu, RunSheng Chen and Yi Zhao* Utilizing sequence intrinsic composition to classify protein-coding and long non-coding transcripts. Nucleic Acids Research (2013), doi: 10.1093\/nar\/gkt646<\/p>\n<p>\u00a0<\/p>\n<p>NONCODE:<\/p>\n<p>Download - <a href=\"http:\/\/www.noncode.org\/download.php\" target=\"_blank\">http:\/\/www.noncode.org\/download.php<\/a>\u00a0(ver\u00a0NONCODE2016_mouse.fa.gz)<\/p>\n<p>Documentation - <a href=\"http:\/\/www.noncode.org\/\" target=\"_blank\">http:\/\/www.noncode.org\/<\/a><\/p>\n<p>Reference -\u00a0Zhao Y, Li H, Fang S, Kang Y, Hao Y, Li Z, Bu D, Sun N, Zhang MQ, Chen R. NONCODE 2016: an informative and valuable data source of long non-coding RNAs. Nucleic acids research. (2015) Nov 19:gkv1252.<\/p>\n<p>\u00a0<\/p>","order_id":"0","name":"Description","data_by_id":"0","type_id":"1","source_data":{"description":"<p>Use the\u00a0Coding-Non-Coding Index (CNCI) to identify\u00a0non-coding transcripts. CNCI profiles adjoining nucleotide triplets to distinguish protein-coding from\u00a0non-coding sequences, independent of known annotations. Align transcripts to the NONCODE database for <em>Mus musculus<\/em> and identify unique single best blast hits.<\/p>\n<p>\u00a0<\/p>\n<p>CNCI:<\/p>\n<p>Download - <a href=\"https:\/\/github.com\/www-bioinfo-org\/CNCI\" target=\"_blank\">https:\/\/github.com\/www-bioinfo-org\/CNCI<\/a>\u00a0(version 2)<\/p>\n<p>Documentation - <a href=\"https:\/\/github.com\/www-bioinfo-org\/CNCI\" target=\"_blank\">https:\/\/github.com\/www-bioinfo-org\/CNCI<\/a><\/p>\n<p>Reference -\u00a0Liang Sun, Haitao Luo, Dechao Bu, Guoguang Zhao, Kuntao Yu, Changhai Zhang, Yuanning Liu, RunSheng Chen and Yi Zhao* Utilizing sequence intrinsic composition to classify protein-coding and long non-coding transcripts. Nucleic Acids Research (2013), doi: 10.1093\/nar\/gkt646<\/p>\n<p>\u00a0<\/p>\n<p>NONCODE:<\/p>\n<p>Download - <a href=\"http:\/\/www.noncode.org\/download.php\" target=\"_blank\">http:\/\/www.noncode.org\/download.php<\/a>\u00a0(ver\u00a0NONCODE2016_mouse.fa.gz)<\/p>\n<p>Documentation - <a href=\"http:\/\/www.noncode.org\/\" target=\"_blank\">http:\/\/www.noncode.org\/<\/a><\/p>\n<p>Reference -\u00a0Zhao Y, Li H, Fang S, Kang Y, Hao Y, Li Z, Bu D, Sun N, Zhang MQ, Chen R. NONCODE 2016: an informative and valuable data source of long non-coding RNAs. Nucleic acids research. (2015) Nov 19:gkv1252.<\/p>\n<p>\u00a0<\/p>"},"is_project":0},{"component_id":"546435","previous_id":"546437","original_id":"0","guid":"143BAA6F941A40B784A677ED2764CAEF","previous_guid":"67AFA937251749228537647C49D023C7","component_type_id":"6","data_id":"0","data":"Identify non-coding RNAs","order_id":"1","name":"Section","data_by_id":"0","type_id":"6","source_data":{"section":"Identify non-coding RNAs"},"is_project":0},{"component_id":"546591","previous_id":"546435","original_id":"0","guid":"62ACE30C1479415FA8C9938B1D14263F","previous_guid":"143BAA6F941A40B784A677ED2764CAEF","component_type_id":"15","data_id":"1676","data":"","order_id":"2","name":"Command","data_by_id":"1","type_id":"15","source_data":{"name":"#Download and install CNCI\ncd $PROGRAMDIR\ngit clone https:\/\/github.com\/www-bioinfo-org\/CNCI.git\ncd CNCI\nunzip libsvm-3.0 && cd libsvm-3.0 && make && cd ..\nchmod 755 *.py *.pl\n#add scripts to a directory contained in PATH, or add current directory to PATH \necho export PATH=\\$PATH:`pwd`\\ >> ~\/.bashrc && source ~\/.bashrc\n\n#Run the CNCI script\ncd $WORKDIR\/cleaned_trimmed_reads\/Trinity-DN\/\npython CNCI.py -f Trinity.fasta -o Trinity_ncRNA -p 32 -m ve\n\n#Identify 'confident' non-coding transcripts (cutoff <= -0.05)\ncd $WORKDIR\/cleaned_trimmed_reads\/Trinity-DN\/Trinity_ncRNA\/\nawk '$3 <=-0.05' CNCI.index > CNCI_Trinity_ncRNA.txt\n\n#Download the NONCODE database and prepare for blast\ncd $WORKDIR\/databases\nwget http:\/\/www.noncode.org\/datadownload\/NONCODE2016_mouse.fa.gz\ngunzip NONCODE2016_mouse.fa.gz\nmakeblastdb -in NONCODE2016_mouse.fa -dbtype nucl -parse_seqids\n\n#Blast each assembly against the NONCODE database\ncd $WORKDIR\/cleaned_trimmed_reads\/all_assemblies\nfor f in *.fasta; do blastn -query $f -db $WORKDIR\/databases\/NONCODE2016_mouse.fa -num_threads 40 -max_target_seqs 1 -evalue 1e-05 -outfmt 6 > blastn_vs_noncode_$f; done\nmkdir noncode_output && mv blastn_vs_noncode* noncode_output\n\n#Parse blast output\ncd $WORKDIR\/cleaned_trimmed_reads\/all_assemblies\/noncode_output\nmkdir evalue_1e-20\nfor f in blastn*; do awk '$11 <=1e-20' $f > 1e-20_$f; done\nmv 1e-20_* evalue_1e-20 && cd evalue_1e-20\nfor f in 1e-20*; do cut -f2 | sort | uniq -c | wc -l > count_best_blast_hits_$f; done","description":"","os_name":"Unix","os_version":"bash","can_edit":"1"},"is_project":0}]}]}