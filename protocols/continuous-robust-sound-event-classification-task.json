{"uri":"continuous-robust-sound-event-classification-task-iw5cfg6","version_id":"0","protocol_name":"Continuous Robust Sound Event Classification Task","protocol_name_html":"Continuous Robust Sound Event Classification Task","is_prepublished":"0","can_edit":"0","parent_id":null,"api_version":"1","is_new_mode":"0","last_modified":"1521958261","type_id":"1","link":"https:\/\/doi.org\/10.1371\/journal.pone.0182309","fork_id":"","public_fork_note":"","number_of_steps":"4","has_versions":"1","first_published_date":"1499937582","publish_date":"2017-07-13 09:21:40","documents":null,"have_protocol_in_step":"0","is_protocol_in_step":"0","vendor_name":"Contributed by users","vendor_link":"https:\/\/www.protocols.io","vendor_logo":"\/img\/vendors\/1.png","mod_mins":"-45","mod_secs":"1","description":"<p>The task described here is that used in the PLoS ONE paper entitled \"Continuous Robust Sound Event Classification Using Time-Frequency Features and Deep Learning\". It builds upon the long established standard isolated sound evaluation task first described\u00a0by Jonathan Dennis, and widely used by a number of other authors - for evaluating classifiers of isolated sounds.<\/p>\n<p>\u00a0<\/p>\n<p>By contrast the current task extends this to potentially overlapping sounds with no a priori knowledge of start and end points.<\/p>\n<p><br \/>The advantage of having a standard task\u00a0is obvious: it makes experiments easily repeatable by others, and eases the comparison of results when other authors make use of the same method to evaluate their own research. With at least 15 state-of-the-art sound classification papers published with Dennis' isolated sound event detection method, it is easily the most popular task defined to date.<\/p>\n<p>\u00a0<\/p>\n<p>In this current task, exactly the same raw material is used, but\u00a0is extended through protocol and setup into a continuous, overlapping and robust classification task.<\/p>\n<p><br \/>The task uses freely available sound recordings from the Real World Computing Partnership (RWCP) Sound Scene Database in Real Acoustic Environments. These must be obtained directly by the RWCP, and are free for non-commercial or academic users, while\u00a0commercial users are charged a small free.<\/p>\n<p>\u00a0<\/p>\n<p>Robustness evaluation is performed by mixing raw\u00a0sounds with background noises from the NOISEX-92 database at several signal-to-noise (SNR) levels. The NOISEX-92 data is widely available online for download.<\/p>","is_bookmarked":"0","can_reassign":"1","before_start":null,"has_guidelines":"0","materials":[],"warning":null,"version_class":"6845","public":"1","is_owner":"1","is_original_owner":"1","created_on":"1499924842","protocol_affiliation":"The University of Kent","affiliation":null,"doi":"dx.doi.org\/10.17504\/protocols.io.iw5cfg6","doi_status":"2","changed_fork_steps":null,"profile_url":"x203c443v2","protocol_img":"https:\/\/s3.amazonaws.com\/pr-journal\/mcmg4ze.jpg","profile_image":"\/img\/avatars\/004.png","full_name":"Ian McLoughlin","created_by":"Ian McLoughlin","private_link":"56A77A0E38C3CE473B6C6D066D91CFEE","original_img":"1","username":"ian-mcloughlin","is_retracted":"0","retraction_reason":null,"plos_id":"10.1371\/journal.pone.0182309","manuscript_citation":"McLoughlin I,  Zhang H,  Xie Z,  Song Y,  Xiao W,  Phan H (2017) Continuous robust sound event classification using time-frequency features and deep learning. PLoS ONE  12(9): e0182309. doi: <a target=\"_blank\" href=\"https:\/\/dx.doi.org\/10.1371\/journal.pone.0182309\">10.1371\/journal.pone.0182309<\/a> ","journal_name":"PLOS One","is_donations_disabled":"0","is_donations_disabled_by_user":"9","item_record_id":253735,"fork_info":[],"compare_forks":[],"protocols":[],"groups":[],"number_of_shared_runs":[],"ownership_history":[],"keywords":"Audio, sound, classification, deep learning","transfer_to_user":[],"sub_transfer":false,"is_transfer_pending":false,"number_of_bookmarks":"0","collections":[],"tags":[{"tag_id":"720","tag_name":"Audio event detection"},{"tag_id":"721","tag_name":" sound event detection"},{"tag_id":"722","tag_name":" sound event classification"},{"tag_id":"723","tag_name":" audio event classification"}],"archived":0,"sub_authors":[],"sub_protocols_number":0,"can_edit_shared":0,"shared_runs":[],"is_shared_run":0,"is_shared":1,"banner":null,"contact_badges":[{"badge_id":"2","badge_image":"\/img\/badges\/bronze.svg","badge_description":"Author!"},{"badge_id":"5","badge_image":"\/img\/badges\/earlyadopter.svg","badge_description":"Early adopter"}],"number_of_comments":0,"big_protocol_img":"https:\/\/s3.amazonaws.com\/pr-journal\/mckg4ze.jpg","big_protocol_img_ofn":"block_diag-eps-converted-to.jpg","is_locked":0,"is_locked_by":false,"authors":"Ian McLoughlin","authors_list":[{"name":"Ian McLoughlin","affiliation":"The University of Kent","username":"ian-mcloughlin","profile_image":"\/img\/avatars\/004.png"}],"user":{"profile_image":"\/img\/avatars\/004.png","username":"ian-mcloughlin","full_name":"Ian McLoughlin","created_by":"Ian McLoughlin"},"access":{"can_view":"1","can_remove":"0","can_add":"0","can_edit":0,"can_publish":0,"can_get_doi":0,"can_share":"0","can_move":"1","can_transfer":"1","can_download":"1","is_locked":"0"},"is_contact_suspended":0,"guidelines":null,"status_id":"1","is_research":"1","status_info":null,"steps":[{"id":"579002","is_changed":"0","original_id":"0","is_skipped":"0","is_checked":"0","guid":"C65A461DBEAE4435967EF8453885854E","previous_guid":null,"previous_id":null,"last_modified":"1499925715","components":[{"component_id":"960698","previous_id":0,"original_id":"0","guid":"530DBE7FF67846CC94B1340F42D8A6D5","previous_guid":null,"component_type_id":"1","data_id":null,"data":"<p>1. The <strong>RWCP Sound Scene Database<\/strong><\/p>\n<p>2. <strong>NOISEX-92<\/strong> recordings of\u00a0<em>Destroyer Control Room<\/em>, <em>Speech Babble<\/em>, <em>Factory Floor 1<\/em> and <em>Jet Cockpit <\/em><\/p>\n<p><em>1<\/em>.<\/p>\n<p>3. All processing will be done within <strong>MATLAB<\/strong>. <strong>Octave<\/strong> is a free alternative which works well, but will require several minor changes in procedure and operating files.<\/p>\n<p>4. For classification purposes, a <strong>machine\u00a0learning toolbox<\/strong> is recommended (e.g. <a href=\"https:\/\/uk.mathworks.com\/matlabcentral\/fileexchange\/38310-deep-learning-toolbox\" target=\"_blank\">Deep Learning Toolbox<\/a> which is simple for beginners to start with, although has been superceded by tools such as MatConvNet or TensorFlow).<\/p>","order_id":"0","name":"Description","data_by_id":"0","type_id":"1","source_data":{"description":"<p>1. The <strong>RWCP Sound Scene Database<\/strong><\/p>\n<p>2. <strong>NOISEX-92<\/strong> recordings of\u00a0<em>Destroyer Control Room<\/em>, <em>Speech Babble<\/em>, <em>Factory Floor 1<\/em> and <em>Jet Cockpit <\/em><\/p>\n<p><em>1<\/em>.<\/p>\n<p>3. All processing will be done within <strong>MATLAB<\/strong>. <strong>Octave<\/strong> is a free alternative which works well, but will require several minor changes in procedure and operating files.<\/p>\n<p>4. For classification purposes, a <strong>machine\u00a0learning toolbox<\/strong> is recommended (e.g. <a href=\"https:\/\/uk.mathworks.com\/matlabcentral\/fileexchange\/38310-deep-learning-toolbox\" target=\"_blank\">Deep Learning Toolbox<\/a> which is simple for beginners to start with, although has been superceded by tools such as MatConvNet or TensorFlow).<\/p>"},"is_project":0},{"component_id":"960699","previous_id":"960698","original_id":"0","guid":"A77A20491903460CB6F0D6A3C1A4AF46","previous_guid":"530DBE7FF67846CC94B1340F42D8A6D5","component_type_id":"6","data_id":null,"data":"Obtain the required data and tools","order_id":"1","name":"Section","data_by_id":"0","type_id":"6","source_data":{"section":"Obtain the required data and tools"},"is_project":0}]},{"id":"579003","is_changed":"0","original_id":"0","is_skipped":"0","is_checked":"0","guid":"0D5E88D04ABE42CAB28DC59061A4A268","previous_guid":"C65A461DBEAE4435967EF8453885854E","previous_id":"579002","last_modified":"1499937260","components":[{"component_id":"960700","previous_id":0,"original_id":"0","guid":"1FCF1508DF0041049A9A607328AF98D7","previous_guid":null,"component_type_id":"1","data_id":null,"data":"<p>1. Put the RWCP database into a directory called 'data_wav'. We use the following 50 classes, based on Dennis's selection criteria:<\/p>\n<p>aircap , bank , bells5 , book1 , bottle1 , bowl , buzzer , candybwl , cap1 , case1 , cherry1 , clap1 , clock1 , coffcan , coffmill , coin1 , crumple , cup1 , cymbals , dice1 , doorlock , drum , dryer , file , horn , kara , magno1 , maracas , mechbell , metal05 , pan , particl1 , phone1 , pipong , pump , punch , ring , sandpp1 , saw1 , shaver , snap , spray , stapler , sticks , string , teak1 , tear , trashbox , whistle1 , wood1<\/p>\n<p>\u00a0<\/p>\n<p>So the directory structure looks like this;<\/p>\n<p><img id=\"s-mce-img\" class=\"s-mce-img\" src=\"https:\/\/s3.amazonaws.com\/pr-journal\/mcng4ze.png\" data-src=\"https:\/\/s3.amazonaws.com\/pr-journal\/mcng4ze.png\" data-ofn=\"Screen Shot 2017-07-13 at 09.55.57.png\" \/><\/p>\n<p>The .raw files go from 000.raw.wav to 079.raw.wav in each class subdirectory.<\/p>\n<p>\u00a0<\/p>\n<p>2. Put the NOISEX-92 files into another directory called 'noisex-92'. The files we tend to use are;<\/p>\n<p>babble.wav,\u00a0factory1.wav,\u00a0f16.wav,\u00a0destroyerengine.wav<\/p>\n<p>\u00a0<\/p>\n<p>3. Mix the files. The following MATLAB <em>might<\/em> work. It is courtest of H.-M. Zhang;<\/p>\n<p>\u00a0<\/p>\n<p>clear all;<br \/>SNR=0;<br \/>noise_path{1}='noisex-92\/babble.wav';<br \/>noise_path{2}='noisex-92\/factory1.wav';<br \/>noise_path{3}='noisex-92\/f16.wav';<br \/>noise_path{4}='noisex-92\/destroyerengine.wav';<br \/>wav_dir='data_wav\/';<br \/>mydir=dir(wav_dir);<\/p>\n<p>fs=16000;<br \/>t=60;<br \/>n=100;<br \/>m=15;<br \/>streams=zeros(fs*t,n);<br \/>scripts=zeros(m,3,n);<\/p>\n<p>datadir=cell(1,1500);<br \/>ntest=0;<br \/>for i=3:52<br \/> mysubdir=dir([wav_dir,mydir(i).name]);<br \/> for j=3:82<br \/> if mod(j-3,8)&lt;3<br \/> ntest=ntest+1;<br \/> a=[wav_dir,mydir(i).name];<br \/> a=[a,'\/'];<br \/> a=[a,mysubdir(j).name];<br \/> datadir{ntest}=a;<br \/> end;<br \/> end;<br \/>end;<\/p>\n<p>rand('state',0);<br \/>sq=randperm(1500);<br \/>for test=1:1500<br \/> [data,fs]=audioread(datadir{sq(test)});<br \/> len=length(data);<br \/> start=ceil(rand()*(fs*t-len+1));<br \/> <br \/> i=ceil(test\/m);<br \/> streams(start:start+len-1,i)=streams(start:start+len-1,i)+data;<br \/> scripts(mod(test-1,m)+1,1,i)=ceil(sq(test)\/30);<br \/> scripts(mod(test-1,m)+1,2,i)=start\/fs;<br \/> scripts(mod(test-1,m)+1,3,i)=(start+len-1)\/fs; <br \/>end;<\/p>\n<p>for j=1:n<br \/>% [streams(:,j),noise]=add_noisem(streams(:,j),noise_path{mod(j,4)+1},SNR,fs);<br \/>end;<\/p>\n<p>% sound(streams(:,1),fs);<\/p>\n<p>\u00a0<\/p>\n<p>\u00a0<\/p>\n<p>\u00a0<\/p>\n<p>These are the files used for <span style=\"text-decoration: underline;\"><strong>TESTING<\/strong><\/span>, but for <span style=\"text-decoration: underline;\"><strong>TRAINING<\/strong><\/span> the system it is slightly different.<\/p>\n<p>\u00a0<\/p>\n<p>4. Training\u00a0first requires a separate set of directories to be created to hold noise-corrupted sound files at 20dB, 10dB, 0dB and some also use -5dB and -10dB SNR. These directories are usually called;<\/p>\n<p>\u00a0<\/p>\n<p>data_wav_mix0<\/p>\n<p>data_wav_mix10<\/p>\n<p>data_wav_mix-5<\/p>\n<p>...<\/p>\n<p>and so on. Each has the same internal structure of 50 class subdirectories each containing 80 files, and the noise is mixed in the same way as above, using MATLAB.<\/p>\n<p>\u00a0<\/p>\n<p>\u00a0<\/p>\n<p>\u00a0<\/p>\n<p>\u00a0<\/p>","order_id":"0","name":"Description","data_by_id":"0","type_id":"1","source_data":{"description":"<p>1. Put the RWCP database into a directory called 'data_wav'. We use the following 50 classes, based on Dennis's selection criteria:<\/p>\n<p>aircap , bank , bells5 , book1 , bottle1 , bowl , buzzer , candybwl , cap1 , case1 , cherry1 , clap1 , clock1 , coffcan , coffmill , coin1 , crumple , cup1 , cymbals , dice1 , doorlock , drum , dryer , file , horn , kara , magno1 , maracas , mechbell , metal05 , pan , particl1 , phone1 , pipong , pump , punch , ring , sandpp1 , saw1 , shaver , snap , spray , stapler , sticks , string , teak1 , tear , trashbox , whistle1 , wood1<\/p>\n<p>\u00a0<\/p>\n<p>So the directory structure looks like this;<\/p>\n<p><img id=\"s-mce-img\" class=\"s-mce-img\" src=\"https:\/\/s3.amazonaws.com\/pr-journal\/mcng4ze.png\" data-src=\"https:\/\/s3.amazonaws.com\/pr-journal\/mcng4ze.png\" data-ofn=\"Screen Shot 2017-07-13 at 09.55.57.png\" \/><\/p>\n<p>The .raw files go from 000.raw.wav to 079.raw.wav in each class subdirectory.<\/p>\n<p>\u00a0<\/p>\n<p>2. Put the NOISEX-92 files into another directory called 'noisex-92'. The files we tend to use are;<\/p>\n<p>babble.wav,\u00a0factory1.wav,\u00a0f16.wav,\u00a0destroyerengine.wav<\/p>\n<p>\u00a0<\/p>\n<p>3. Mix the files. The following MATLAB <em>might<\/em> work. It is courtest of H.-M. Zhang;<\/p>\n<p>\u00a0<\/p>\n<p>clear all;<br \/>SNR=0;<br \/>noise_path{1}='noisex-92\/babble.wav';<br \/>noise_path{2}='noisex-92\/factory1.wav';<br \/>noise_path{3}='noisex-92\/f16.wav';<br \/>noise_path{4}='noisex-92\/destroyerengine.wav';<br \/>wav_dir='data_wav\/';<br \/>mydir=dir(wav_dir);<\/p>\n<p>fs=16000;<br \/>t=60;<br \/>n=100;<br \/>m=15;<br \/>streams=zeros(fs*t,n);<br \/>scripts=zeros(m,3,n);<\/p>\n<p>datadir=cell(1,1500);<br \/>ntest=0;<br \/>for i=3:52<br \/> mysubdir=dir([wav_dir,mydir(i).name]);<br \/> for j=3:82<br \/> if mod(j-3,8)&lt;3<br \/> ntest=ntest+1;<br \/> a=[wav_dir,mydir(i).name];<br \/> a=[a,'\/'];<br \/> a=[a,mysubdir(j).name];<br \/> datadir{ntest}=a;<br \/> end;<br \/> end;<br \/>end;<\/p>\n<p>rand('state',0);<br \/>sq=randperm(1500);<br \/>for test=1:1500<br \/> [data,fs]=audioread(datadir{sq(test)});<br \/> len=length(data);<br \/> start=ceil(rand()*(fs*t-len+1));<br \/> <br \/> i=ceil(test\/m);<br \/> streams(start:start+len-1,i)=streams(start:start+len-1,i)+data;<br \/> scripts(mod(test-1,m)+1,1,i)=ceil(sq(test)\/30);<br \/> scripts(mod(test-1,m)+1,2,i)=start\/fs;<br \/> scripts(mod(test-1,m)+1,3,i)=(start+len-1)\/fs; <br \/>end;<\/p>\n<p>for j=1:n<br \/>% [streams(:,j),noise]=add_noisem(streams(:,j),noise_path{mod(j,4)+1},SNR,fs);<br \/>end;<\/p>\n<p>% sound(streams(:,1),fs);<\/p>\n<p>\u00a0<\/p>\n<p>\u00a0<\/p>\n<p>\u00a0<\/p>\n<p>These are the files used for <span style=\"text-decoration: underline;\"><strong>TESTING<\/strong><\/span>, but for <span style=\"text-decoration: underline;\"><strong>TRAINING<\/strong><\/span> the system it is slightly different.<\/p>\n<p>\u00a0<\/p>\n<p>4. Training\u00a0first requires a separate set of directories to be created to hold noise-corrupted sound files at 20dB, 10dB, 0dB and some also use -5dB and -10dB SNR. These directories are usually called;<\/p>\n<p>\u00a0<\/p>\n<p>data_wav_mix0<\/p>\n<p>data_wav_mix10<\/p>\n<p>data_wav_mix-5<\/p>\n<p>...<\/p>\n<p>and so on. Each has the same internal structure of 50 class subdirectories each containing 80 files, and the noise is mixed in the same way as above, using MATLAB.<\/p>\n<p>\u00a0<\/p>\n<p>\u00a0<\/p>\n<p>\u00a0<\/p>\n<p>\u00a0<\/p>"},"is_project":0},{"component_id":"960701","previous_id":"960700","original_id":"0","guid":"BC5850A64503428D93ECED0EC81E88A6","previous_guid":"1FCF1508DF0041049A9A607328AF98D7","component_type_id":"6","data_id":null,"data":"Prepare the data","order_id":"1","name":"Section","data_by_id":"0","type_id":"6","source_data":{"section":"Prepare the data"},"is_project":0}]},{"id":"579004","is_changed":"0","original_id":"0","is_skipped":"0","is_checked":"0","guid":"FC535167610F4338BAF0148A22FD63F9","previous_guid":"0D5E88D04ABE42CAB28DC59061A4A268","previous_id":"579003","last_modified":"1499936993","components":[{"component_id":"960702","previous_id":0,"original_id":"0","guid":"31E06A9A86CC43B191D33571BD573ED5","previous_guid":null,"component_type_id":"1","data_id":null,"data":"<p>In the current paper, the classifier is trained on single, isolated sounds, following the procedure outlined a<a href=\"t http:\/\/www.lintech.org\/machine_hearing\" target=\"_blank\">t http:\/\/www.lintech.org\/machine_hearing<\/a><\/p>\n<p>\u00a0<\/p>\n<p>\u00a0<\/p>","order_id":"0","name":"Description","data_by_id":"0","type_id":"1","source_data":{"description":"<p>In the current paper, the classifier is trained on single, isolated sounds, following the procedure outlined a<a href=\"t http:\/\/www.lintech.org\/machine_hearing\" target=\"_blank\">t http:\/\/www.lintech.org\/machine_hearing<\/a><\/p>\n<p>\u00a0<\/p>\n<p>\u00a0<\/p>"},"is_project":0},{"component_id":"960703","previous_id":"960702","original_id":"0","guid":"B169A905FE0D4851B48648AD09971ECB","previous_guid":"31E06A9A86CC43B191D33571BD573ED5","component_type_id":"6","data_id":null,"data":"Training","order_id":"1","name":"Section","data_by_id":"0","type_id":"6","source_data":{"section":"Training"},"is_project":0}]},{"id":"579005","is_changed":"0","original_id":"0","is_skipped":"0","is_checked":"0","guid":"E7CC3BF4527E42398A03BB4DBAB08CF6","previous_guid":"FC535167610F4338BAF0148A22FD63F9","previous_id":"579004","last_modified":"1499937312","components":[{"component_id":"960704","previous_id":0,"original_id":"0","guid":"E2D6FEA170E340A59F59F5E24ACC5A35","previous_guid":null,"component_type_id":"1","data_id":null,"data":"<p>Testing proceeds using the structure outlined in the current paper. It will be made available when the paper is published on PLoS-One.<\/p>","order_id":"0","name":"Description","data_by_id":"0","type_id":"1","source_data":{"description":"<p>Testing proceeds using the structure outlined in the current paper. It will be made available when the paper is published on PLoS-One.<\/p>"},"is_project":0},{"component_id":"960705","previous_id":"960704","original_id":"0","guid":"4785958146464108BAA613B8D886FD51","previous_guid":"E2D6FEA170E340A59F59F5E24ACC5A35","component_type_id":"6","data_id":null,"data":"Testing","order_id":"1","name":"Section","data_by_id":"0","type_id":"6","source_data":{"section":"Testing"},"is_project":0}]}]}