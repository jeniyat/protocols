{"uri":"binning-procedure-applied-to-tara-oceans-dataset-u-iwgcfbw","version_id":"0","protocol_name":"Binning Procedure applied to Tara Oceans Dataset using BinSanity (e.g., South Pacific)","protocol_name_html":"Binning Procedure applied to Tara Oceans Dataset using BinSanity (e.g., South Pacific)","is_prepublished":"0","can_edit":"0","parent_id":null,"api_version":"1","is_new_mode":"0","last_modified":"1522216802","type_id":"1","link":"https:\/\/www.nature.com\/articles\/sdata2017203","fork_id":"","public_fork_note":"","number_of_steps":"17","has_versions":"0","first_published_date":"1499956834","publish_date":"2017-07-13 14:40:34","documents":null,"have_protocol_in_step":"0","is_protocol_in_step":"0","vendor_name":"Contributed by users","vendor_link":"https:\/\/www.protocols.io","vendor_logo":"\/img\/vendors\/1.png","mod_mins":"-45","mod_secs":"1","description":"<p>This is the procedure used to cluster MAGs for the <em>Tara Oceans<\/em> dataset assembled by Benjamin Tully and Elaina Graham<\/p>","is_bookmarked":"0","can_reassign":"1","before_start":"<p>Before starting be sure you have downloaded Binsanity. Please see the <a href=\"https:\/\/github.com\/edgraham\/BinSanity\" target=\"_blank\">Binsanity github page<\/a>\u00a0for full installation instructions and a walkthrough of parameters for each program.<\/p>","has_guidelines":"0","materials":[],"warning":null,"version_class":"6824","public":"1","is_owner":"1","is_original_owner":"1","created_on":"1499814886","protocol_affiliation":"University of Southern California","affiliation":"University of Southern California","doi":"dx.doi.org\/10.17504\/protocols.io.iwgcfbw","doi_status":"1","changed_fork_steps":null,"profile_url":"Elaina-w213b4v2v2","protocol_img":"https:\/\/www.protocols.io\/img\/default_protocol.png","profile_image":"\/img\/avatars\/011.png","full_name":"Elaina Graham","created_by":"Elaina Graham","private_link":"055702FC8F12C4A14081C9C474BAC882","original_img":"1","username":"elaina-graham","is_retracted":"0","retraction_reason":null,"plos_id":null,"manuscript_citation":"Tully BJ,  Graham ED,  Heidelberg JF, The reconstruction of 2,631 draft metagenome-assembled genomes from the global oceans. Scientific Data  doi: <a target=\"_blank\" href=\"https:\/\/www.nature.com\/articles\/sdata2017203\">sdata2017203<\/a> ","journal_name":"Scientific Data","is_donations_disabled":"0","is_donations_disabled_by_user":"9","item_record_id":232652,"fork_info":[],"compare_forks":[],"protocols":[],"groups":[{"group_id":"102","group_uri":"center-for-dark-energy-biosphere-investigations","group_name":"Center for Dark Energy Biosphere Investigations","group_logo":"https:\/\/s3.amazonaws.com\/pr-journal\/buddabw.jpg","requested_uid":null,"request_flag":null,"my_request":"1"}],"number_of_shared_runs":[],"ownership_history":[],"keywords":"binning, binsanity","transfer_to_user":[],"sub_transfer":false,"is_transfer_pending":false,"number_of_bookmarks":"1","collections":[],"tags":[{"tag_id":"106","tag_name":"metagenomics"},{"tag_id":"454","tag_name":"bioinformatics"},{"tag_id":"488","tag_name":"clustering"}],"archived":0,"sub_authors":[],"sub_protocols_number":0,"can_edit_shared":0,"shared_runs":[],"is_shared_run":0,"is_shared":1,"banner":null,"contact_badges":[{"badge_id":"2","badge_image":"\/img\/badges\/bronze.svg","badge_description":"Author!"},{"badge_id":"5","badge_image":"\/img\/badges\/earlyadopter.svg","badge_description":"Early adopter"}],"number_of_comments":0,"is_locked":0,"is_locked_by":false,"authors":"Elaina Graham,Benjamin Tully","authors_list":[{"name":"Elaina Graham","affiliation":"University of Southern California","username":"elaina-graham","profile_image":"\/img\/avatars\/011.png"},{"name":"Benjamin Tully","affiliation":"University of Southern California","username":"benjamin-tully","profile_image":"https:\/\/s3.amazonaws.com\/pr-journal\/bufdabw.jpg"}],"user":{"profile_image":"\/img\/avatars\/011.png","username":"elaina-graham","full_name":"Elaina Graham","created_by":"Elaina Graham"},"access":{"can_view":"1","can_remove":"0","can_add":"0","can_edit":0,"can_publish":0,"can_get_doi":0,"can_share":"0","can_move":"1","can_transfer":"1","can_download":"1","is_locked":"0"},"is_contact_suspended":0,"guidelines":null,"status_id":"1","is_research":"1","status_info":null,"steps":[{"id":"578718","is_changed":"0","original_id":"0","is_skipped":"0","is_checked":"0","guid":"769D8FB438BE44698EE69D33B5AC07C5","previous_guid":null,"previous_id":"0","last_modified":"1499888638","components":[{"component_id":"959945","previous_id":0,"original_id":"0","guid":"CF657808CA2646D8AFBF11D5E4A4855F","previous_guid":null,"component_type_id":"1","data_id":null,"data":"<p>A profile should be generated for all contigs from each seperate metagenome.<\/p>\n<p>\u00a0<\/p>\n<p>An example of the Tara Oceans assembly procedure can be found\u00a0<strong><a href=\"https:\/\/www.protocols.io\/view\/assembly-procedure-applied-to-tara-oceans-data-ex-hfqb3mw\" target=\"_blank\">here<\/a><\/strong>.<\/p>\n<p>\u00a0<\/p>\n<p>To do this first you will need to generate a list of contig ids that will be binned. This can be done using the <strong>get-ids<\/strong> command available through <strong><a href=\"https:\/\/github.com\/edgraham\/BinSanity\" target=\"_blank\">BinSanity<\/a><\/strong><\/p>\n<p>\u00a0<\/p>\n<p>Following this run <strong>Binsanity-Profile<\/strong>:<\/p>\n<p>\u00a0<\/p>\n<p>\u00a0<\/p>","order_id":"0","name":"Description","data_by_id":"0","type_id":"1","source_data":{"description":"<p>A profile should be generated for all contigs from each seperate metagenome.<\/p>\n<p>\u00a0<\/p>\n<p>An example of the Tara Oceans assembly procedure can be found\u00a0<strong><a href=\"https:\/\/www.protocols.io\/view\/assembly-procedure-applied-to-tara-oceans-data-ex-hfqb3mw\" target=\"_blank\">here<\/a><\/strong>.<\/p>\n<p>\u00a0<\/p>\n<p>To do this first you will need to generate a list of contig ids that will be binned. This can be done using the <strong>get-ids<\/strong> command available through <strong><a href=\"https:\/\/github.com\/edgraham\/BinSanity\" target=\"_blank\">BinSanity<\/a><\/strong><\/p>\n<p>\u00a0<\/p>\n<p>Following this run <strong>Binsanity-Profile<\/strong>:<\/p>\n<p>\u00a0<\/p>\n<p>\u00a0<\/p>"},"is_project":0},{"component_id":"959946","previous_id":"959945","original_id":"0","guid":"87F9A356C00B4DCE9E4E9D3C7E3FA6A4","previous_guid":"CF657808CA2646D8AFBF11D5E4A4855F","component_type_id":"6","data_id":null,"data":"Generate a coverage profile using Binsanity-profile ","order_id":"1","name":"Section","data_by_id":"0","type_id":"6","source_data":{"section":"Generate a coverage profile using Binsanity-profile "},"is_project":0},{"component_id":"959950","previous_id":"959946","original_id":"0","guid":"8A9D8610D81E4D0F8B6548A12FF80552","previous_guid":"87F9A356C00B4DCE9E4E9D3C7E3FA6A4","component_type_id":"8","data_id":"126","data":"","order_id":"2","name":"Software package","data_by_id":"1","type_id":"8","source_data":{"id":"126","name":"BinSanity","developer":"Elaina Graham","repository":"https:\/\/github.com\/edgraham\/BinSanity","link":"","os_name":"N\/A","os_version":"N\/A","version":"0.2.5.1","can_edit":"1"},"is_project":0},{"component_id":"960283","previous_id":"959950","original_id":"0","guid":"E02CA17BEF984457ADF81679BE1CF8FF","previous_guid":"8A9D8610D81E4D0F8B6548A12FF80552","component_type_id":"15","data_id":"1971","data":"","order_id":"3","name":"Command","data_by_id":"1","type_id":"15","source_data":{"name":"Binsanity-profile -i tara_southpacific_SECONDARY_contigs.min14000.fasta -s directory\/to\/BAM\/files --ids tara_southpacific_SECONDARY_contigs.min14000.ids --transform scale","description":"","os_name":"","os_version":"","can_edit":"0"},"is_project":0}]},{"id":"578719","is_changed":"0","original_id":"0","is_skipped":"0","is_checked":"0","guid":"C7E50FF1423C49538ADE1A6F7EA95663","previous_guid":"769D8FB438BE44698EE69D33B5AC07C5","previous_id":"578718","last_modified":"1499888729","components":[{"component_id":"959947","previous_id":0,"original_id":"0","guid":"A62C08643BAA469CAD69004264A51166","previous_guid":null,"component_type_id":"1","data_id":null,"data":"<p>\u00a0<\/p>\n<p>Now that you have a coverage file you will want to create a directory called \"Tara-MAGs\" and move the coverage file into this directory.<\/p>\n<p>\u00a0<\/p>\n<p>Once this is done <em>cd\u00a0<\/em>\u00a0into the \"Tara-MAGs directory and run the first round of Binsanity using a preference of -10 (All other parameters should remain at default).\u00a0<\/p>","order_id":"0","name":"Description","data_by_id":"0","type_id":"1","source_data":{"description":"<p>\u00a0<\/p>\n<p>Now that you have a coverage file you will want to create a directory called \"Tara-MAGs\" and move the coverage file into this directory.<\/p>\n<p>\u00a0<\/p>\n<p>Once this is done <em>cd\u00a0<\/em>\u00a0into the \"Tara-MAGs directory and run the first round of Binsanity using a preference of -10 (All other parameters should remain at default).\u00a0<\/p>"},"is_project":0},{"component_id":"959948","previous_id":"959947","original_id":"0","guid":"0B3976F40D99466D823BF3C3E9D155B2","previous_guid":"A62C08643BAA469CAD69004264A51166","component_type_id":"6","data_id":null,"data":"Run BinSanity Pass1","order_id":"1","name":"Section","data_by_id":"0","type_id":"6","source_data":{"section":"Run BinSanity Pass1"},"is_project":0},{"component_id":"960284","previous_id":"959948","original_id":"0","guid":"E28688B846624EEBB5D99A84BBBDF749","previous_guid":"0B3976F40D99466D823BF3C3E9D155B2","component_type_id":"15","data_id":"1972","data":"","order_id":"2","name":"Command","data_by_id":"1","type_id":"15","source_data":{"name":"Binsanity -f . -l tara_southpacific_SECONDARY_contigs.min14000.fasta -p -10 -c tara_southpacific_SECONDARY_min14000.ALLSAMPLES.coverage.x100.lognorm -o PASS1","description":"","os_name":"","os_version":"","can_edit":"0"},"is_project":0}]},{"id":"578720","is_changed":"0","original_id":"0","is_skipped":"0","is_checked":"0","guid":"A70D1EB874CC4529A751A6B3879AAFCB","previous_guid":"C7E50FF1423C49538ADE1A6F7EA95663","previous_id":"578719","last_modified":"1499818141","components":[{"component_id":"959951","previous_id":0,"original_id":"0","guid":"A979FD68B6FE491D935CE2E386507E05","previous_guid":null,"component_type_id":"1","data_id":null,"data":"<p>Following the commands below you will do the following:<\/p>\n<p>\u00a0<\/p>\n<p>1. First mv the log file into the PASS1 directory.\u00a0<\/p>\n<p>\u00a0<\/p>\n<p>2.\u00a0Rename the log file to reflect the clustering step<\/p>\n<p>\u00a0<\/p>\n<p>3. rename the files in PASS1 to reflect the clustering step<\/p>","order_id":"0","name":"Description","data_by_id":"0","type_id":"1","source_data":{"description":"<p>Following the commands below you will do the following:<\/p>\n<p>\u00a0<\/p>\n<p>1. First mv the log file into the PASS1 directory.\u00a0<\/p>\n<p>\u00a0<\/p>\n<p>2.\u00a0Rename the log file to reflect the clustering step<\/p>\n<p>\u00a0<\/p>\n<p>3. rename the files in PASS1 to reflect the clustering step<\/p>"},"is_project":0},{"component_id":"959952","previous_id":"959951","original_id":"0","guid":"938B768BC5CA467BB6C9BB4A5F70718D","previous_guid":"A979FD68B6FE491D935CE2E386507E05","component_type_id":"6","data_id":null,"data":"Rename Output Files","order_id":"1","name":"Section","data_by_id":"0","type_id":"6","source_data":{"section":"Rename Output Files"},"is_project":0},{"component_id":"959954","previous_id":"959952","original_id":"0","guid":"B7630EF3C73A4939B0BB737AA6655930","previous_guid":"938B768BC5CA467BB6C9BB4A5F70718D","component_type_id":"15","data_id":"1932","data":"","order_id":"2","name":"Command","data_by_id":"1","type_id":"15","source_data":{"name":"mv *.txt PASS1\ncd PASS1\nmv *.txt PASS1-log.txt\nnum=1\nfor file in *.fna; do\n       mv \"$file\" \"$(printf \"PASS1-%u\" $num).fna\"\n       let num=$num+1\ndone\n","description":"","os_name":"","os_version":"","can_edit":"1"},"is_project":0}]},{"id":"578721","is_changed":"0","original_id":"0","is_skipped":"0","is_checked":"0","guid":"CACA2212BADB4C03AA92AFDD84B65529","previous_guid":"A70D1EB874CC4529A751A6B3879AAFCB","previous_id":"578720","last_modified":"1499896271","components":[{"component_id":"959955","previous_id":0,"original_id":"0","guid":"D9DB1FF396CE44F8A01844BE0414F996","previous_guid":null,"component_type_id":"1","data_id":null,"data":"<p>In this next step you will run CheckM and asses the output.\u00a0The script\u00a0<strong>checkm_analysis\u00a0<\/strong>is a part of BinSanity's suite of scripts.<\/p>\n<p>The commands below do the following:<\/p>\n<p>\u00a0<\/p>\n<p>1. Run CheckM lineage_wf to assess PASS1 genomes for completion and redundancy estimates<\/p>\n<p>2. Split Genomes into categories considered\u00a0<em>high_completion, high_redundnacy, <\/em>and<em> low_completion.\u00a0<\/em><\/p>\n<ul>\n<li>High completion: &gt;90% complete with &lt;10% redundancy, greater than 80% with &lt;5% redundancy, or &gt;50% with &lt;2% redundacy<\/li>\n<li>Low completion: &lt;50% complete with &lt;5%redundancy<\/li>\n<li>Strain heterogeneity: &gt;90% complete with &gt;90% strain heterogeneity<\/li>\n<li>High Redundancy: &gt;80% complete with &gt;10% redundacy, or &gt;50% complete &gt;5% redundacy<\/li>\n<\/ul>\n<p>3. Prior to refinement you'll want to combine all bins in the low_completion category together - contigs from these bins will be used for the next stage of clustering.<\/p>\n<p>4. Add the bins in the strain_heterogeneity directory to high_redundancy<\/p>\n<p>5. Remove\u00a0the low_completion and strain_heterogeneity directories.<\/p>","order_id":"0","name":"Description","data_by_id":"0","type_id":"1","source_data":{"description":"<p>In this next step you will run CheckM and asses the output.\u00a0The script\u00a0<strong>checkm_analysis\u00a0<\/strong>is a part of BinSanity's suite of scripts.<\/p>\n<p>The commands below do the following:<\/p>\n<p>\u00a0<\/p>\n<p>1. Run CheckM lineage_wf to assess PASS1 genomes for completion and redundancy estimates<\/p>\n<p>2. Split Genomes into categories considered\u00a0<em>high_completion, high_redundnacy, <\/em>and<em> low_completion.\u00a0<\/em><\/p>\n<ul>\n<li>High completion: &gt;90% complete with &lt;10% redundancy, greater than 80% with &lt;5% redundancy, or &gt;50% with &lt;2% redundacy<\/li>\n<li>Low completion: &lt;50% complete with &lt;5%redundancy<\/li>\n<li>Strain heterogeneity: &gt;90% complete with &gt;90% strain heterogeneity<\/li>\n<li>High Redundancy: &gt;80% complete with &gt;10% redundacy, or &gt;50% complete &gt;5% redundacy<\/li>\n<\/ul>\n<p>3. Prior to refinement you'll want to combine all bins in the low_completion category together - contigs from these bins will be used for the next stage of clustering.<\/p>\n<p>4. Add the bins in the strain_heterogeneity directory to high_redundancy<\/p>\n<p>5. Remove\u00a0the low_completion and strain_heterogeneity directories.<\/p>"},"is_project":0},{"component_id":"959956","previous_id":"959955","original_id":"0","guid":"9C481761E9D6492FAB41A68DD3D05C76","previous_guid":"D9DB1FF396CE44F8A01844BE0414F996","component_type_id":"6","data_id":null,"data":"Run CheckM","order_id":"1","name":"Section","data_by_id":"0","type_id":"6","source_data":{"section":"Run CheckM"},"is_project":0},{"component_id":"959959","previous_id":"959956","original_id":"0","guid":"24BF2C879CD7435594EB39A277B6F352","previous_guid":"9C481761E9D6492FAB41A68DD3D05C76","component_type_id":"15","data_id":"1933","data":"","order_id":"2","name":"Command","data_by_id":"1","type_id":"15","source_data":{"name":"checkm lineage_wf -x fna -t 30 . PASS1-checkm> PASS1-checkm_out\ncheckm_analysis -checkM PASS1-checkm_out\nfor file in low_completion\/*.fna; do cat \"$file\" >>high_redundancy\/low_completion.fna; done\nmv strain*\/*.fna high_redundancy\nrm -r strain_heterogeneity\nrm -r low_completion\n","description":"","os_name":"","os_version":"","can_edit":"1"},"is_project":0},{"component_id":"960555","previous_id":"959959","original_id":"0","guid":"218642A5A311417D977B6674C5B5C96A","previous_guid":"24BF2C879CD7435594EB39A277B6F352","component_type_id":"17","data_id":"1134","data":"<p>PASS1<\/p>\n<p>Total bins = 2184<\/p>\n<p>High completion = 190<\/p>\n<p>High redundancy = 396<\/p>","order_id":"3","name":"Expected result","data_by_id":"1","type_id":"17","source_data":{"result":"<p>PASS1<\/p>\n<p>Total bins = 2184<\/p>\n<p>High completion = 190<\/p>\n<p>High redundancy = 396<\/p>"},"is_project":0}]},{"id":"578722","is_changed":"0","original_id":"0","is_skipped":"0","is_checked":"0","guid":"697B4303FA704D69955A9F56D6592C25","previous_guid":"CACA2212BADB4C03AA92AFDD84B65529","previous_id":"578721","last_modified":"1499889150","components":[{"component_id":"959957","previous_id":0,"original_id":"0","guid":"DC6A0BDA186B47588E32E2162F127261","previous_guid":null,"component_type_id":"1","data_id":null,"data":"<p>Now you can run<strong> Binsanity-refine.<\/strong>\u00a0<\/p>\n<p>To do this we will first\u00a0go into the\u00a0<em>high_redundancy<\/em>\u00a0directory.<\/p>\n<p>\u00a0<\/p>\n<p>Once in the <em>high_redundancy<\/em> directory you can run <strong>Binsanity-refine\u00a0<\/strong>with a preference of -25 and default parameters.<\/p>\n<p>\u00a0<\/p>\n<p>\u00a0<\/p>","order_id":"0","name":"Description","data_by_id":"0","type_id":"1","source_data":{"description":"<p>Now you can run<strong> Binsanity-refine.<\/strong>\u00a0<\/p>\n<p>To do this we will first\u00a0go into the\u00a0<em>high_redundancy<\/em>\u00a0directory.<\/p>\n<p>\u00a0<\/p>\n<p>Once in the <em>high_redundancy<\/em> directory you can run <strong>Binsanity-refine\u00a0<\/strong>with a preference of -25 and default parameters.<\/p>\n<p>\u00a0<\/p>\n<p>\u00a0<\/p>"},"is_project":0},{"component_id":"959958","previous_id":"959957","original_id":"0","guid":"78DF366EA0CA4D7EB9FBDB3DC6F1FB7C","previous_guid":"DC6A0BDA186B47588E32E2162F127261","component_type_id":"6","data_id":null,"data":"Run Binsanity Refinement on Pass1","order_id":"1","name":"Section","data_by_id":"0","type_id":"6","source_data":{"section":"Run Binsanity Refinement on Pass1"},"is_project":0},{"component_id":"959960","previous_id":"959958","original_id":"0","guid":"F7C80B04555946F09E7BB3A4463B23E8","previous_guid":"78DF366EA0CA4D7EB9FBDB3DC6F1FB7C","component_type_id":"15","data_id":"1934","data":"","order_id":"2","name":"Command","data_by_id":"1","type_id":"15","source_data":{"name":"cd high_redundancy\nfor file in *.fna; do Binsanity-refine -c ..\/..\/*lognorm -f . -l \"$file\" -p -25 -o ..\/..\/PASS1-refine;done","description":"","os_name":"","os_version":"","can_edit":"1"},"is_project":0}]},{"id":"578723","is_changed":"0","original_id":"0","is_skipped":"0","is_checked":"0","guid":"3DD5C67E40804426A032DD7B0890E62A","previous_guid":"697B4303FA704D69955A9F56D6592C25","previous_id":"578722","last_modified":"1499827914","components":[{"component_id":"959961","previous_id":0,"original_id":"0","guid":"F37733B97EF34A8C86DE55CAF812ED34","previous_guid":null,"component_type_id":"1","data_id":null,"data":"<p>\u00a0<\/p>\n<p>Repeat step-3 replacing PASS1 with Pass1-refine<\/p>","order_id":"0","name":"Description","data_by_id":"0","type_id":"1","source_data":{"description":"<p>\u00a0<\/p>\n<p>Repeat step-3 replacing PASS1 with Pass1-refine<\/p>"},"is_project":0},{"component_id":"959962","previous_id":"959961","original_id":"0","guid":"3FD0A7EBF5E243B099EF8CD4F6D69120","previous_guid":"F37733B97EF34A8C86DE55CAF812ED34","component_type_id":"6","data_id":null,"data":"Rename output files for PASS1-Refine","order_id":"1","name":"Section","data_by_id":"0","type_id":"6","source_data":{"section":"Rename output files for PASS1-Refine"},"is_project":0},{"component_id":"959963","previous_id":"959962","original_id":"0","guid":"E8A5AC5F57C9486F91708867F44F6009","previous_guid":"3FD0A7EBF5E243B099EF8CD4F6D69120","component_type_id":"15","data_id":"1935","data":"","order_id":"2","name":"Command","data_by_id":"1","type_id":"15","source_data":{"name":"mv *.txt ..\/..\/PASS1-refine\ncd ..\/..\/PASS1-refine\nmv *.txt PASS1-refine-log.txt\nfind . -size 0 -delete\nnum=1\nfor file in *.fna; do\n       mv \"$file\" \"$(printf \"PASS1-refine-%u\" $num).fna\"\n       let num=$num+1\ndone","description":"","os_name":"","os_version":"","can_edit":"1"},"is_project":0}]},{"id":"578724","is_changed":"0","original_id":"0","is_skipped":"0","is_checked":"0","guid":"1CF5368847F64A9896756491C447734F","previous_guid":"3DD5C67E40804426A032DD7B0890E62A","previous_id":"578723","last_modified":"1499896309","components":[{"component_id":"959964","previous_id":0,"original_id":"0","guid":"813C5D37FB0A463A94617FB2AA1FD6C1","previous_guid":null,"component_type_id":"1","data_id":null,"data":"<p>Now you need to run CheckM to check for redundancy, completion, and strain heterogeneity of each bin.\u00a0<\/p>\n<p>\u00a0<\/p>\n<p>Once CheckM is completed the output file will be `PASS1-refine-checkm_out`<\/p>\n<p>\u00a0<\/p>\n<p>Using the `checkm_analysis` script you can separate bins based on the categories in Step 4 part 2.\u00a0<\/p>\n<p>\u00a0<\/p>\n<p>The low completion bins will be re-combined and moved to the high_redundancy directory for further refinement.<\/p>\n<p>\u00a0<\/p>\n<p>All bins with high strain heterogeneity will also be moved to the high_redundancy directory.<\/p>\n<p>\u00a0<\/p>\n<p>Then to clean up the files you can remove the strain_heterogeneity and low_completion directories as you have now moved all bins to the high_redundancy directory.<\/p>","order_id":"0","name":"Description","data_by_id":"0","type_id":"1","source_data":{"description":"<p>Now you need to run CheckM to check for redundancy, completion, and strain heterogeneity of each bin.\u00a0<\/p>\n<p>\u00a0<\/p>\n<p>Once CheckM is completed the output file will be `PASS1-refine-checkm_out`<\/p>\n<p>\u00a0<\/p>\n<p>Using the `checkm_analysis` script you can separate bins based on the categories in Step 4 part 2.\u00a0<\/p>\n<p>\u00a0<\/p>\n<p>The low completion bins will be re-combined and moved to the high_redundancy directory for further refinement.<\/p>\n<p>\u00a0<\/p>\n<p>All bins with high strain heterogeneity will also be moved to the high_redundancy directory.<\/p>\n<p>\u00a0<\/p>\n<p>Then to clean up the files you can remove the strain_heterogeneity and low_completion directories as you have now moved all bins to the high_redundancy directory.<\/p>"},"is_project":0},{"component_id":"959965","previous_id":"959964","original_id":"0","guid":"5F1A284DAD1E4590ADB5F9E42724BE18","previous_guid":"813C5D37FB0A463A94617FB2AA1FD6C1","component_type_id":"6","data_id":null,"data":"Run CheckM on PASS1-Refine results","order_id":"1","name":"Section","data_by_id":"0","type_id":"6","source_data":{"section":"Run CheckM on PASS1-Refine results"},"is_project":0},{"component_id":"959966","previous_id":"959965","original_id":"0","guid":"DC9DF1C7192542C3837DA68B0B63CDE3","previous_guid":"5F1A284DAD1E4590ADB5F9E42724BE18","component_type_id":"15","data_id":"1936","data":"","order_id":"2","name":"Command","data_by_id":"1","type_id":"15","source_data":{"name":"checkm lineage_wf -x fna -t 30 . PASS1-refine-checkm> PASS1-refine-checkm_out\ncheckm_analysis -checkM PASS1-refine-checkm_out\nfor file in low_completion\/*.fna; do cat \"$file\" >>high_redundancy\/low_completion.fna; done\nmv strain*\/*.fna high_redundancy\nrm -r strain*\nrm -r low_completion","description":"","os_name":"","os_version":"","can_edit":"1"},"is_project":0},{"component_id":"960556","previous_id":"959966","original_id":"0","guid":"639B8210DD6E4521A1DD5E8499BBBDCD","previous_guid":"DC9DF1C7192542C3837DA68B0B63CDE3","component_type_id":"17","data_id":"1135","data":"<p>PASS1-refine<\/p>\n<p>Total bins = 1160<br \/>High completion = 51\u00a0<br \/>High redundancy = 423<\/p>","order_id":"3","name":"Expected result","data_by_id":"1","type_id":"17","source_data":{"result":"<p>PASS1-refine<\/p>\n<p>Total bins = 1160<br \/>High completion = 51\u00a0<br \/>High redundancy = 423<\/p>"},"is_project":0}]},{"id":"578725","is_changed":"0","original_id":"0","is_skipped":"0","is_checked":"0","guid":"886C42A7581A40889F18B63E80D55831","previous_guid":"1CF5368847F64A9896756491C447734F","previous_id":"578724","last_modified":"1499896497","components":[{"component_id":"959967","previous_id":0,"original_id":"0","guid":"9D6384F9D433485092950921987BD2BB","previous_guid":null,"component_type_id":"1","data_id":null,"data":"<p>BinSanity will be run an additional 5 times, with Binsanity-refine being run between each step, except for a modification after iteration 6. Modifications to commands above will generate the correct files.<\/p>\n<p>Preference values used for each PASS<\/p>\n<p>PASS2 -p -5 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0PASS2-refine -p -25<\/p>\n<p>PASS3 -p -3 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0PASS3-refine -p -25<\/p>\n<p>PASS4 -p -3 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0PASS4-refine -p -25<\/p>\n<p>PASS5 -p -3\u00a0\u00a0 \u00a0 \u00a0 \u00a0 \u00a0PASS5-refine -p -25<\/p>\n<p>PASS6 -p -3<\/p>","order_id":"0","name":"Description","data_by_id":"0","type_id":"1","source_data":{"description":"<p>BinSanity will be run an additional 5 times, with Binsanity-refine being run between each step, except for a modification after iteration 6. Modifications to commands above will generate the correct files.<\/p>\n<p>Preference values used for each PASS<\/p>\n<p>PASS2 -p -5 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0PASS2-refine -p -25<\/p>\n<p>PASS3 -p -3 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0PASS3-refine -p -25<\/p>\n<p>PASS4 -p -3 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0PASS4-refine -p -25<\/p>\n<p>PASS5 -p -3\u00a0\u00a0 \u00a0 \u00a0 \u00a0 \u00a0PASS5-refine -p -25<\/p>\n<p>PASS6 -p -3<\/p>"},"is_project":0},{"component_id":"959968","previous_id":"959967","original_id":"0","guid":"69289A86D2C0415CBF76741840EE608C","previous_guid":"9D6384F9D433485092950921987BD2BB","component_type_id":"6","data_id":null,"data":"Run Additional Iterations of Binsanity","order_id":"1","name":"Section","data_by_id":"0","type_id":"6","source_data":{"section":"Run Additional Iterations of Binsanity"},"is_project":0},{"component_id":"960558","previous_id":"959968","original_id":"0","guid":"ACDBC5B600674A7A85121775681E6255","previous_guid":"69289A86D2C0415CBF76741840EE608C","component_type_id":"17","data_id":"1137","data":"<p>PASS2<br \/>Total bins = 2362<br \/>High completion = 52\u00a0<br \/>High redundancy = 397<\/p>\n<p>PASS2-refine<br \/>Total bins = 1175<br \/>High completion = 5<br \/>High redundancy = 465<\/p>\n<p>PASS3<br \/>Total bins = 3053<br \/>High completion = 52<br \/>High redundancy = 332<\/p>\n<p>PASS3-refine<br \/>Total bins = 1183<br \/>High completion = 6<br \/>High redundancy = 459<\/p>\n<p>PASS4<br \/>Total bins = 3012<br \/>High completion = 4<br \/>High redundancy = 340<\/p>\n<p>PASS4-refine<br \/>Total bins = 1176<br \/>High completion = 1<br \/>High redundancy = 462<\/p>\n<p>PASS5<br \/>Total bins = 3031<br \/>High completion = 1<br \/>High redundancy = 342<\/p>\n<p>PASS5-refine<br \/>Total bins = 1175<br \/>High completion = 1<br \/>High redundancy = 466<\/p>","order_id":"2","name":"Expected result","data_by_id":"1","type_id":"17","source_data":{"result":"<p>PASS2<br \/>Total bins = 2362<br \/>High completion = 52\u00a0<br \/>High redundancy = 397<\/p>\n<p>PASS2-refine<br \/>Total bins = 1175<br \/>High completion = 5<br \/>High redundancy = 465<\/p>\n<p>PASS3<br \/>Total bins = 3053<br \/>High completion = 52<br \/>High redundancy = 332<\/p>\n<p>PASS3-refine<br \/>Total bins = 1183<br \/>High completion = 6<br \/>High redundancy = 459<\/p>\n<p>PASS4<br \/>Total bins = 3012<br \/>High completion = 4<br \/>High redundancy = 340<\/p>\n<p>PASS4-refine<br \/>Total bins = 1176<br \/>High completion = 1<br \/>High redundancy = 462<\/p>\n<p>PASS5<br \/>Total bins = 3031<br \/>High completion = 1<br \/>High redundancy = 342<\/p>\n<p>PASS5-refine<br \/>Total bins = 1175<br \/>High completion = 1<br \/>High redundancy = 466<\/p>"},"is_project":0}]},{"id":"578751","is_changed":"0","original_id":"0","is_skipped":"0","is_checked":"0","guid":"4BAC4985A93E4A3A830B9D661F8FEDAA","previous_guid":"886C42A7581A40889F18B63E80D55831","previous_id":"578725","last_modified":"1499896352","components":[{"component_id":"960045","previous_id":0,"original_id":"0","guid":"23D55F5DE10E49C98B3877A92A630AFA","previous_guid":null,"component_type_id":"1","data_id":null,"data":"","order_id":"0","name":"Description","data_by_id":"0","type_id":"1","source_data":{"description":""},"is_project":0},{"component_id":"960046","previous_id":"960045","original_id":"0","guid":"3C6C185CBE274CEDB05D9FE460502041","previous_guid":"23D55F5DE10E49C98B3877A92A630AFA","component_type_id":"6","data_id":null,"data":"Run CheckM on PASS6","order_id":"1","name":"Section","data_by_id":"0","type_id":"6","source_data":{"section":"Run CheckM on PASS6"},"is_project":0},{"component_id":"960047","previous_id":"960046","original_id":"0","guid":"0783551A3E2B4A4986D5CBD1A5F025DF","previous_guid":"3C6C185CBE274CEDB05D9FE460502041","component_type_id":"15","data_id":"1963","data":"","order_id":"2","name":"Command","data_by_id":"1","type_id":"15","source_data":{"name":"checkm lineage_wf -x fna -t 30 . PASS6-checkm > PASS6-checkm_out\ncheckm_analysis_final -checkM PASS6-checkm_out","description":"","os_name":"","os_version":"","can_edit":"1"},"is_project":0},{"component_id":"960557","previous_id":"960047","original_id":"0","guid":"77A2D398F89346BC81B3BF8A4E485610","previous_guid":"0783551A3E2B4A4986D5CBD1A5F025DF","component_type_id":"17","data_id":"1136","data":"<p>PASS6<br \/>Total bins = 3022<br \/>High completion = 116\u00a0<br \/>High redundancy = 225<\/p>","order_id":"3","name":"Expected result","data_by_id":"1","type_id":"17","source_data":{"result":"<p>PASS6<br \/>Total bins = 3022<br \/>High completion = 116\u00a0<br \/>High redundancy = 225<\/p>"},"is_project":0}]},{"id":"578752","is_changed":"0","original_id":"0","is_skipped":"0","is_checked":"0","guid":"26F17061AE3D4C369A4CFC3363DBCA12","previous_guid":"4BAC4985A93E4A3A830B9D661F8FEDAA","previous_id":"578751","last_modified":"1499828624","components":[{"component_id":"960048","previous_id":0,"original_id":"0","guid":"84882925B4374D8F8125B18E39C2EE32","previous_guid":null,"component_type_id":"1","data_id":null,"data":"<p>Following CheckM on Binsanity PASS6 is where we will change things up. You will no longer move or alter the low_completion files. Instead you will go directly into the high redundancy file for PASS6 and run <strong>Binsanity-refine<\/strong> at a preference of -10.\u00a0<\/p>","order_id":"0","name":"Description","data_by_id":"0","type_id":"1","source_data":{"description":"<p>Following CheckM on Binsanity PASS6 is where we will change things up. You will no longer move or alter the low_completion files. Instead you will go directly into the high redundancy file for PASS6 and run <strong>Binsanity-refine<\/strong> at a preference of -10.\u00a0<\/p>"},"is_project":0},{"component_id":"960049","previous_id":"960048","original_id":"0","guid":"A88428565B8F4568AD1AA8950404AE2F","previous_guid":"84882925B4374D8F8125B18E39C2EE32","component_type_id":"6","data_id":null,"data":"Run Binsanity-refine on PASS6 high redundancy  at preference -10","order_id":"1","name":"Section","data_by_id":"0","type_id":"6","source_data":{"section":"Run Binsanity-refine on PASS6 high redundancy  at preference -10"},"is_project":0},{"component_id":"960050","previous_id":"960049","original_id":"0","guid":"FD55200D74D648C4BF9E3CC1A02C1256","previous_guid":"A88428565B8F4568AD1AA8950404AE2F","component_type_id":"15","data_id":"1964","data":"","order_id":"2","name":"Command","data_by_id":"1","type_id":"15","source_data":{"name":"cd high_redundancy\nfor file in *.fna; do Binsanity-refine -f . -l \"$file\" -p -10 -c ..\/..\/*lognorm -o ..\/..\/PASS6-refine-redundant-pref10; done","description":"","os_name":"","os_version":"","can_edit":"1"},"is_project":0}]},{"id":"578753","is_changed":"0","original_id":"0","is_skipped":"0","is_checked":"0","guid":"D301B38571AC4665B34586C9E67BC0C0","previous_guid":"26F17061AE3D4C369A4CFC3363DBCA12","previous_id":"578752","last_modified":"1499828676","components":[{"component_id":"960051","previous_id":0,"original_id":"0","guid":"DE4412A14A864CB1A81B0E09B7805A65","previous_guid":null,"component_type_id":"1","data_id":null,"data":"<p>You can now rename the output files for PASS6 refinement at a preference of -10 for downstream refinement.<\/p>","order_id":"0","name":"Description","data_by_id":"0","type_id":"1","source_data":{"description":"<p>You can now rename the output files for PASS6 refinement at a preference of -10 for downstream refinement.<\/p>"},"is_project":0},{"component_id":"960052","previous_id":"960051","original_id":"0","guid":"10B1E0B60F13489B88E9B730348B501E","previous_guid":"DE4412A14A864CB1A81B0E09B7805A65","component_type_id":"6","data_id":null,"data":"Rename output files for PASS6 refinement of redundancy bins","order_id":"1","name":"Section","data_by_id":"0","type_id":"6","source_data":{"section":"Rename output files for PASS6 refinement of redundancy bins"},"is_project":0},{"component_id":"960053","previous_id":"960052","original_id":"0","guid":"C3155DF5B20F4EBA81948BACB0C6AD75","previous_guid":"10B1E0B60F13489B88E9B730348B501E","component_type_id":"15","data_id":"1965","data":"","order_id":"2","name":"Command","data_by_id":"1","type_id":"15","source_data":{"name":"mv *.txt ..\/..\/PASS6-refine-redundant-pref10\ncd ..\/..\/PASS6-refine-redundant-pref10\nmv *.txt PASS6-refine-redundant-pref10-log.txt\nfind . -size 0 -delete\nnum=1\nfor file in *.fna; do\n       mv \"$file\" \"$(printf \"PASS6-refine-redundant-%u\" $num).fna\"\n       let num=$num+1\ndone","description":"","os_name":"","os_version":"","can_edit":"1"},"is_project":0}]},{"id":"578754","is_changed":"0","original_id":"0","is_skipped":"0","is_checked":"0","guid":"42DED87140F04B6B940D5A570A976AFE","previous_guid":"D301B38571AC4665B34586C9E67BC0C0","previous_id":"578753","last_modified":"1499896539","components":[{"component_id":"960054","previous_id":0,"original_id":"0","guid":"CFB1D3DAEB46409FB54DA568AD19D653","previous_guid":null,"component_type_id":"1","data_id":null,"data":"<p>Here we will run CheckM on the bins generated using Binsanity-refine on PASS6 high_redundnacy bins at a preference of -10.<\/p>","order_id":"0","name":"Description","data_by_id":"0","type_id":"1","source_data":{"description":"<p>Here we will run CheckM on the bins generated using Binsanity-refine on PASS6 high_redundnacy bins at a preference of -10.<\/p>"},"is_project":0},{"component_id":"960055","previous_id":"960054","original_id":"0","guid":"72676EED04C94F428B9F318EE34B395D","previous_guid":"CFB1D3DAEB46409FB54DA568AD19D653","component_type_id":"6","data_id":null,"data":"Run CheckM on bins generated from PASS6 refinement","order_id":"1","name":"Section","data_by_id":"0","type_id":"6","source_data":{"section":"Run CheckM on bins generated from PASS6 refinement"},"is_project":0},{"component_id":"960056","previous_id":"960055","original_id":"0","guid":"6A4F10E8DCBF4B4F8634858C07BDBB09","previous_guid":"72676EED04C94F428B9F318EE34B395D","component_type_id":"15","data_id":"1966","data":"","order_id":"2","name":"Command","data_by_id":"1","type_id":"15","source_data":{"name":"checkm lineage_wf -x fna -t 30 . PASS6-refine-redundant-checkm > PASS6-refine-redundant-checkm_out\ncheckm_analysis_final -checkM PASS6-refine-redundant-checkm_out","description":"","os_name":"","os_version":"","can_edit":"1"},"is_project":0},{"component_id":"960559","previous_id":"960056","original_id":"0","guid":"0A6CF1FDDB56477DA912229E23DC35BE","previous_guid":"6A4F10E8DCBF4B4F8634858C07BDBB09","component_type_id":"17","data_id":"1138","data":"<p>PASS6-refine-10<\/p>\n<p>Total bins = 225<br \/>High completion = 22<br \/>High redundancy = 198<\/p>","order_id":"3","name":"Expected result","data_by_id":"1","type_id":"17","source_data":{"result":"<p>PASS6-refine-10<\/p>\n<p>Total bins = 225<br \/>High completion = 22<br \/>High redundancy = 198<\/p>"},"is_project":0}]},{"id":"578755","is_changed":"0","original_id":"0","is_skipped":"0","is_checked":"0","guid":"896A11B2E13B41A6A63D1828F9BA116E","previous_guid":"42DED87140F04B6B940D5A570A976AFE","previous_id":"578754","last_modified":"1499828844","components":[{"component_id":"960057","previous_id":0,"original_id":"0","guid":"6516CFC4D6BA4D0A8DE43617B7405719","previous_guid":null,"component_type_id":"1","data_id":null,"data":"<p>Finally we will run another round of refinement on ONLY the high_redundancy bins for PASS6-refine-redundant-pref10. This time Binsanity-refine will be run with a preference of -3.\u00a0<\/p>","order_id":"0","name":"Description","data_by_id":"0","type_id":"1","source_data":{"description":"<p>Finally we will run another round of refinement on ONLY the high_redundancy bins for PASS6-refine-redundant-pref10. This time Binsanity-refine will be run with a preference of -3.\u00a0<\/p>"},"is_project":0},{"component_id":"960058","previous_id":"960057","original_id":"0","guid":"7C9B9CB8B1F7401497BB52A7638F2FB4","previous_guid":"6516CFC4D6BA4D0A8DE43617B7405719","component_type_id":"6","data_id":null,"data":"Run a second round of refinement on the remaining high redundancy bins at preference -3","order_id":"1","name":"Section","data_by_id":"0","type_id":"6","source_data":{"section":"Run a second round of refinement on the remaining high redundancy bins at preference -3"},"is_project":0},{"component_id":"960059","previous_id":"960058","original_id":"0","guid":"B1D0FE82378F46B08F7F2393556DF568","previous_guid":"7C9B9CB8B1F7401497BB52A7638F2FB4","component_type_id":"15","data_id":"1967","data":"","order_id":"2","name":"Command","data_by_id":"1","type_id":"15","source_data":{"name":"cd high_redundancy\nfor file in *.fna; do Binsanity-refine -f . -l \"$file\" -p -3 -c ..\/..\/*lognorm -o ..\/..\/PASS6-refine-2-redundant-pref3; done","description":"","os_name":"","os_version":"","can_edit":"1"},"is_project":0}]},{"id":"578756","is_changed":"0","original_id":"0","is_skipped":"0","is_checked":"0","guid":"E9C6FAAAD8C64EE1B5992B5A9E65AF6B","previous_guid":"896A11B2E13B41A6A63D1828F9BA116E","previous_id":"578755","last_modified":"1499820661","components":[{"component_id":"960060","previous_id":0,"original_id":"0","guid":"964F33BD06D7419BA24C531998AF75B6","previous_guid":null,"component_type_id":"1","data_id":null,"data":"","order_id":"0","name":"Description","data_by_id":"0","type_id":"1","source_data":{"description":""},"is_project":0},{"component_id":"960061","previous_id":"960060","original_id":"0","guid":"B7FB3F1B1B1C4452A5D4768A4627DAFD","previous_guid":"964F33BD06D7419BA24C531998AF75B6","component_type_id":"6","data_id":null,"data":"Rename output files from PASS6 refinement round 2","order_id":"1","name":"Section","data_by_id":"0","type_id":"6","source_data":{"section":"Rename output files from PASS6 refinement round 2"},"is_project":0},{"component_id":"960062","previous_id":"960061","original_id":"0","guid":"0AFFC312F03A4F8F8F0035CF290E3397","previous_guid":"B7FB3F1B1B1C4452A5D4768A4627DAFD","component_type_id":"15","data_id":"1968","data":"","order_id":"2","name":"Command","data_by_id":"1","type_id":"15","source_data":{"name":"mv *.txt ..\/..\/PASS6-refine-2-redundant-pref3\ncd ..\/..\/PASS6-refine-2-redundant-pref3\nmv *.txt PASS6-refine-redundant-2-pref3-log.txt\nfind . -size 0 -delete\nnum=1\nfor file in *.fna; do\n       mv \"$file\" \"$(printf \"PASS6-refine-redundant-2-%u\" $num).fna\"\n       let num=$num+1\ndone","description":"","os_name":"","os_version":"","can_edit":"1"},"is_project":0}]},{"id":"578757","is_changed":"0","original_id":"0","is_skipped":"0","is_checked":"0","guid":"38195D2714504DA9B27C1F7322B9470C","previous_guid":"E9C6FAAAD8C64EE1B5992B5A9E65AF6B","previous_id":"578756","last_modified":"1499896566","components":[{"component_id":"960063","previous_id":0,"original_id":"0","guid":"3C085207644046F4B1059FBCCB48B3C7","previous_guid":null,"component_type_id":"1","data_id":null,"data":"","order_id":"0","name":"Description","data_by_id":"0","type_id":"1","source_data":{"description":""},"is_project":0},{"component_id":"960064","previous_id":"960063","original_id":"0","guid":"9EEE3095B66C4EA2BE8D7C328A26FEBF","previous_guid":"3C085207644046F4B1059FBCCB48B3C7","component_type_id":"6","data_id":null,"data":"Run CheckM and evaluate high completion bins for PASS6 refinement round 2","order_id":"1","name":"Section","data_by_id":"0","type_id":"6","source_data":{"section":"Run CheckM and evaluate high completion bins for PASS6 refinement round 2"},"is_project":0},{"component_id":"960065","previous_id":"960064","original_id":"0","guid":"05D67A53B5454B3A847FDB177B7F1B4D","previous_guid":"9EEE3095B66C4EA2BE8D7C328A26FEBF","component_type_id":"15","data_id":"1969","data":"","order_id":"2","name":"Command","data_by_id":"1","type_id":"15","source_data":{"name":"checkm lineage_wf -x fna -t 30 . PASS6-refine-redundant-2-checkm > PASS6-refine-redundant-2-checkm_out\ncheckm_analysis -checkM PASS6-refine-redundant -checkM PASS6-refine-redundant-2-checkm_out\n","description":"","os_name":"","os_version":"","can_edit":"1"},"is_project":0},{"component_id":"960560","previous_id":"960065","original_id":"0","guid":"7E1DE6089A4E48218D84EF3141045088","previous_guid":"05D67A53B5454B3A847FDB177B7F1B4D","component_type_id":"17","data_id":"1139","data":"<p>PASS6-refine-3<\/p>\n<p>Total bins = 198<br \/>High completion = 36\u00a0<br \/>High redundancy = 124<\/p>","order_id":"3","name":"Expected result","data_by_id":"1","type_id":"17","source_data":{"result":"<p>PASS6-refine-3<\/p>\n<p>Total bins = 198<br \/>High completion = 36\u00a0<br \/>High redundancy = 124<\/p>"},"is_project":0}]},{"id":"578780","is_changed":"0","original_id":"0","is_skipped":"0","is_checked":"0","guid":"79879DCA00D243FB8E323053E6FFE46C","previous_guid":"38195D2714504DA9B27C1F7322B9470C","previous_id":"578757","last_modified":"1499896610","components":[{"component_id":"960113","previous_id":0,"original_id":"0","guid":"662ABC10E9224A52B652CA02F557D6A3","previous_guid":null,"component_type_id":"1","data_id":null,"data":"<p>Now we want to collect all our final bins in one place.<\/p>\n<p>\u00a0<\/p>\n<p>To do this we will organize the high_completion, low_completion, and remaining high_redundancy in one place. Follow the structure below.<\/p>\n<p>\u00a0<\/p>\n<p>Once this is done you can confirm that none of your bins were accidently duplicated by using the `checkm unique` function.<\/p>\n<p>\u00a0<\/p>\n<p>You have now generated your bins for analysis!<\/p>","order_id":"0","name":"Description","data_by_id":"0","type_id":"1","source_data":{"description":"<p>Now we want to collect all our final bins in one place.<\/p>\n<p>\u00a0<\/p>\n<p>To do this we will organize the high_completion, low_completion, and remaining high_redundancy in one place. Follow the structure below.<\/p>\n<p>\u00a0<\/p>\n<p>Once this is done you can confirm that none of your bins were accidently duplicated by using the `checkm unique` function.<\/p>\n<p>\u00a0<\/p>\n<p>You have now generated your bins for analysis!<\/p>"},"is_project":0},{"component_id":"960114","previous_id":"960113","original_id":"0","guid":"67D046B7FB76497C9E1631C76DEBB244","previous_guid":"662ABC10E9224A52B652CA02F557D6A3","component_type_id":"6","data_id":null,"data":"Make a final bin directory","order_id":"1","name":"Section","data_by_id":"0","type_id":"6","source_data":{"section":"Make a final bin directory"},"is_project":0},{"component_id":"960115","previous_id":"960114","original_id":"0","guid":"05690B147D184A97929021B1A766CFC0","previous_guid":"67D046B7FB76497C9E1631C76DEBB244","component_type_id":"15","data_id":"1970","data":"","order_id":"2","name":"Command","data_by_id":"1","type_id":"15","source_data":{"name":"mkdir FINAL-HIGH-COMPLETION FINAL-LOW-COMPLETION FINAL-HIGH-REDUNDANCY\ncp PASS*\/high_completion\/*.fna FINAL-HIGH-COMPLETION\ncp PASS6-refine-redundant-pref10\/low_completion FINAL-LOW-COMPLETION\ncp PASS6-refine-2-redundant-pref3\/low_completion FINAL-LOW-COMPLETION\ncp PASS6-refine2-redundancy-pref3\/high_redundancy FINAL-HIGH-REDUNDANCY\n","description":"","os_name":"","os_version":"","can_edit":"1"},"is_project":0},{"component_id":"960561","previous_id":"960115","original_id":"0","guid":"EDDC2C175AA24397BD737694D4548553","previous_guid":"05690B147D184A97929021B1A766CFC0","component_type_id":"17","data_id":"1140","data":"<p>FINAL RESULTS<\/p>\n<p>High completion bins = 537<\/p>\n<p>\u00a0<\/p>\n<p>TOBG Draft genomes = 536<\/p>\n<p>High redundancy = 124<\/p>\n<p>Low completion = 3730<\/p>","order_id":"3","name":"Expected result","data_by_id":"1","type_id":"17","source_data":{"result":"<p>FINAL RESULTS<\/p>\n<p>High completion bins = 537<\/p>\n<p>\u00a0<\/p>\n<p>TOBG Draft genomes = 536<\/p>\n<p>High redundancy = 124<\/p>\n<p>Low completion = 3730<\/p>"},"is_project":0}]},{"id":"578854","is_changed":"0","original_id":"0","is_skipped":"0","is_checked":"0","guid":"C7E54C280DA84AF0A140CB73E220695F","previous_guid":"79879DCA00D243FB8E323053E6FFE46C","previous_id":"578780","last_modified":"1499896867","components":[{"component_id":"960285","previous_id":0,"original_id":"0","guid":"F7853F292B6D4DEAB150FECF486AC0AB","previous_guid":null,"component_type_id":"1","data_id":null,"data":"<p>The entire process desrcibed above has been automated in a shell script that can be run through all of these steps. Modification of the shell script can increase or decrease the number of BinSanity passes. Shell script assumes that all of the BinSanity scripts are available in your $PATH.<\/p>\n<p>\u00a0<\/p>\n<p>The Tara Oceans project utilized 6 passes of BinSanity, but fewer passes can yield similar outputs.<\/p>","order_id":"0","name":"Description","data_by_id":"0","type_id":"1","source_data":{"description":"<p>The entire process desrcibed above has been automated in a shell script that can be run through all of these steps. Modification of the shell script can increase or decrease the number of BinSanity passes. Shell script assumes that all of the BinSanity scripts are available in your $PATH.<\/p>\n<p>\u00a0<\/p>\n<p>The Tara Oceans project utilized 6 passes of BinSanity, but fewer passes can yield similar outputs.<\/p>"},"is_project":0},{"component_id":"960286","previous_id":"960285","original_id":"0","guid":"B7EEA376E89A4A8B80E6229BB2C35C5D","previous_guid":"F7853F292B6D4DEAB150FECF486AC0AB","component_type_id":"6","data_id":null,"data":"Automate whole process using shell script","order_id":"1","name":"Section","data_by_id":"0","type_id":"6","source_data":{"section":"Automate whole process using shell script"},"is_project":0},{"component_id":"960550","previous_id":"960286","original_id":"0","guid":"155D365806E84AD48F4C79BC38E5111D","previous_guid":"B7EEA376E89A4A8B80E6229BB2C35C5D","component_type_id":"15","data_id":"1973","data":"","order_id":"2","name":"Command","data_by_id":"1","type_id":"15","source_data":{"name":"#!\/bin\/bash\nBinsanity -f . -l tara_southpacific_SECONDARY_contigs.min14000.fasta -p -10 -c tara_southpacific_SECONDARY_min14000.ALLSAMPLES.coverage.x100.lognorm -o PASS1\nmv *.txt PASS1\ncd PASS1\nmv *.txt PASS1-log.txt\nfind . -size 0 -delete\nnum=1\nfor file in *.fna; do\n       mv \"$file\" \"$(printf \"PASS1-%u\" $num).fna\"\n       let num=$num+1\ndone\ncheckm lineage_wf -x fna -t 30 . PASS1-checkm> PASS1-checkm_out\ncheckm_analysis -checkM PASS1-checkm_out\nfor file in low_completion\/*.fna; do cat \"$file\" >>high_redundancy\/low_completion.fna; done\nmv strain*\/*.fna high_redundancy\nrm -r strain*\nrm -r low_completion\ncd high_redundancy\nfor file in *.fna; do Binsanity-refine -c ..\/..\/*lognorm -f . -l \"$file\" -p -25 -o ..\/..\/PASS1-refine;done\nmv *.txt ..\/..\/PASS1-refine\ncd ..\/..\/PASS1-refine\nmv *.txt PASS1-refine-log.txt\nfind . -size 0 -delete\nnum=1\nfor file in *.fna; do\n       mv \"$file\" \"$(printf \"PASS1-refine-%u\" $num).fna\"\n       let num=$num+1\ndone\ncheckm lineage_wf -x fna -t 30 . PASS1-refine-checkm> PASS1-refine-checkm_out\ncheckm_analysis -checkM PASS1-refine-checkm_out\nfor file in low_completion\/*.fna; do cat \"$file\" >>high_redundancy\/low_completion.fna; done\nmv strain*\/*.fna high_redundancy\nrm -r strain*\nrm -r low_completion\ncd high_redundancy\nfor file in *.fna; do Binsanity -c ..\/..\/*lognorm -f . -l \"$file\" -p -5 -o ..\/..\/PASS2;done\n####\nmv *.txt ..\/..\/PASS2\ncd ..\/..\/PASS2\nmv *.txt PASS2-log.txt\nfind . -size 0 -delete\nnum=1\nfor file in *.fna; do\n       mv \"$file\" \"$(printf \"PASS2-%u\" $num).fna\"\n       let num=$num+1\ndone\ncheckm lineage_wf -x fna -t 30 . PASS2-checkm> PASS2-checkm_out\ncheckm_analysis -checkM PASS2-checkm_out\nfor file in low_completion\/*.fna; do cat \"$file\" >>high_redundancy\/low_completion.fna; done\nmv strain*\/*.fna high_redundancy\nrm -r strain*\nrm -r low_completion\ncd high_redundancy\nfor file in *.fna; do Binsanity-refine -c ..\/..\/*lognorm -f . -l \"$file\" -p -25 -o ..\/..\/PASS2-refine;done\nmv *.txt ..\/..\/PASS2-refine\ncd ..\/..\/PASS2-refine\nmv *.txt PASS2-refine-log.txt\nfind . -size 0 -delete\nnum=1\nfor file in *.fna; do\n       mv \"$file\" \"$(printf \"PASS2-refine-%u\" $num).fna\"\n       let num=$num+1\ndone\ncheckm lineage_wf -x fna -t 30 . PASS2-refine-checkm> PASS2-refine-checkm_out\ncheckm_analysis -checkM PASS2-refine-checkm_out\nfor file in low_completion\/*.fna; do cat \"$file\" >>high_redundancy\/low_completion.fna; done\nmv strain*\/*.fna high_redundancy\nrm -r strain*\nrm -r low_completion\ncd high_redundancy\nfor file in *.fna; do Binsanity -c ..\/..\/*lognorm -f . -l \"$file\" -p -3 -o ..\/..\/PASS3;done\n###\nmv *.txt ..\/..\/PASS3\ncd ..\/..\/PASS3\nmv *.txt PASS3-log.txt\nfind . -size 0 -delete\nnum=1\nfor file in *.fna; do\n       mv \"$file\" \"$(printf \"PASS3-%u\" $num).fna\"\n       let num=$num+1\ndone\ncheckm lineage_wf -x fna -t 30 . PASS3-checkm> PASS3-checkm_out\ncheckm_analysis -checkM PASS3-checkm_out\nfor file in low_completion\/*.fna; do cat \"$file\" >>high_redundancy\/low_completion.fna; done\nmv strain*\/*.fna high_redundancy\nrm -r strain*\nrm -r low_completion\ncd high_redundancy\nfor file in *.fna; do Binsanity-refine -c ..\/..\/*lognorm -f . -l \"$file\" -p -25 -o ..\/..\/PASS3-refine;done\nmv *.txt ..\/..\/PASS3-refine\ncd ..\/..\/PASS3-refine\nmv *.txt PASS3-refine-log.txt\nfind . -size 0 -delete\nnum=1\nfor file in *.fna; do\n       mv \"$file\" \"$(printf \"PASS3-refine-%u\" $num).fna\"\n       let num=$num+1\ndone\ncheckm lineage_wf -x fna -t 30 . PASS3-refine-checkm> PASS3-refine-checkm_out\ncheckm_analysis -checkM PASS3-refine-checkm_out\nfor file in low_completion\/*.fna; do cat \"$file\" >>high_redundancy\/low_completion.fna; done\nmv strain*\/*.fna high_redundancy\nrm -r strain*\nrm -r low_completion\ncd high_redundancy\nfor file in *.fna; do Binsanity -c ..\/..\/*lognorm -f . -l \"$file\" -p -3 -o ..\/..\/PASS4;done\n####\nmv *.txt ..\/..\/PASS4\ncd ..\/..\/PASS4\nmv *.txt PASS4-log.txt\nfind . -size 0 -delete\nnum=1\nfor file in *.fna; do\n       mv \"$file\" \"$(printf \"PASS4-%u\" $num).fna\"\n       let num=$num+1\ndone\ncheckm lineage_wf -x fna -t 30 . PASS4-checkm> PASS4-checkm_out\ncheckm_analysis -checkM PASS4-checkm_out\nfor file in low_completion\/*.fna; do cat \"$file\" >>high_redundancy\/low_completion.fna; done\nmv strain*\/*.fna high_redundancy\nrm -r strain*\nrm -r low_completion\ncd high_redundancy\nfor file in *.fna; do Binsanity-refine -c ..\/..\/*lognorm -f . -l \"$file\" -p -25 -o ..\/..\/PASS4-refine;done\nmv *.txt ..\/..\/PASS4-refine\ncd ..\/..\/PASS4-refine\nmv *.txt PASS4-refine-log.txt\nfind . -size 0 -delete\nnum=1\nfor file in *.fna; do\n       mv \"$file\" \"$(printf \"PASS4-refine-%u\" $num).fna\"\n       let num=$num+1\ndone\ncheckm lineage_wf -x fna -t 30 . PASS4-refine-checkm> PASS4-refine-checkm_out\ncheckm_analysis -checkM PASS4-refine-checkm_out\nfor file in low_completion\/*.fna; do cat \"$file\" >>high_redundancy\/low_completion.fna; done\nmv strain*\/*.fna high_redundancy\nrm -r strain*\nrm -r low_completion\ncd high_redundancy\nfor file in *.fna; do Binsanity -c ..\/..\/*lognorm -f . -l \"$file\" -p -3 -o ..\/..\/PASS5;done\n###\nmv *.txt ..\/..\/PASS5\ncd ..\/..\/PASS5\nmv *.txt PASS5-log.txt\nfind . -size 0 -delete\nnum=1\nfor file in *.fna; do\n       mv \"$file\" \"$(printf \"PASS5-%u\" $num).fna\"\n       let num=$num+1\ndone\ncheckm lineage_wf -x fna -t 30 . PASS5-checkm> PASS5-checkm_out\ncheckm_analysis -checkM PASS5-checkm_out\nfor file in low_completion\/*.fna; do cat \"$file\" >>high_redundancy\/low_completion.fna; done\nmv strain*\/*.fna high_redundancy\nrm -r strain*\nrm -r low_completion\ncd high_redundancy\nfor file in *.fna; do Binsanity-refine -c ..\/..\/*lognorm -f . -l \"$file\" -p -25 -o ..\/..\/PASS5-refine;done\nmv *.txt ..\/..\/PASS5-refine\ncd ..\/..\/PASS5-refine\nmv *.txt PASS5-refine-log.txt\nfind . -size 0 -delete\nnum=1\nfor file in *.fna; do\n       mv \"$file\" \"$(printf \"PASS5-refine-%u\" $num).fna\"\n       let num=$num+1\ndone\ncheckm lineage_wf -x fna -t 30 . PASS5-refine-checkm> PASS5-refine-checkm_out\ncheckm_analysis -checkM PASS5-refine-checkm_out\nfor file in low_completion\/*.fna; do cat \"$file\" >>high_redundancy\/low_completion.fna; done\nmv strain*\/*.fna high_redundancy\nrm -r strain*\nrm -r low_completion\ncd high_redundancy\nfor file in *.fna; do Binsanity -c ..\/..\/*lognorm -f . -l \"$file\" -p -3 -o ..\/..\/PASS6;done\nmv *.txt ..\/..\/PASS6\ncd ..\/..\/PASS6\nfind . -size 0 -delete\nnum=1\nfor file in *.fna; do\n       mv \"$file\" \"$(printf \"PASS6-%u\" $num).fna\"\n       let num=$num+1\ndone\ncheckm lineage_wf -x fna -t 30 . PASS6-checkm > PASS6-checkm_out\ncheckm_analysis_final -checkM PASS6-checkm_out\ncd high_redundancy\nfor file in *.fna; do Binsanity-refine -f . -l \"$file\" -p -10 -c ..\/..\/*lognorm -o ..\/..\/PASS6-refine-redundant-pref10; done\nmv *.txt ..\/..\/PASS6-refine-redundant-pref10\ncd ..\/..\/PASS6-refine-redundant-pref10\nmv *.txt PASS6-refine-redundant-pref10-log.txt\nfind . -size 0 -delete\nnum=1\nfor file in *.fna; do\n       mv \"$file\" \"$(printf \"PASS6-refine-redundant-%u\" $num).fna\"\n       let num=$num+1\ndone\ncheckm lineage_wf -x fna -t 30 . PASS6-refine-redundant-checkm > PASS6-refine-redundant-checkm_out\ncheckm_analysis_final -checkM PASS6-refine-redundant-checkm_out\ncd high_redundancy\nfor file in *.fna; do Binsanity-refine -f . -l \"$file\" -p -3 -c ..\/..\/*lognorm -o ..\/..\/PASS6-refine-2-redundant-pref3; done\nmv *.txt ..\/..\/PASS6-refine-2-redundant-pref3\ncd ..\/..\/PASS6-refine-2-redundant-pref3\nmv *.txt PASS6-refine-redundant-2-pref3-log.txt\nfind . -size 0 -delete\nnum=1\nfor file in *.fna; do\n       mv \"$file\" \"$(printf \"PASS6-refine-redundant-2-%u\" $num).fna\"\n       let num=$num+1\ndone\ncheckm lineage_wf -x fna -t 30 . PASS6-refine-redundant-2-checkm > PASS6-refine-redundant-2-checkm_out\ncheckm_analysis_final -checkM PASS6-refine-redundant -checkM PASS6-refine-redundant-2-checkm_out\ncd ..\/\nmkdir FINAL-HIGH-COMPLETION FINAL-LOW-COMPLETION FINAL-HIGH-REDUNDANCY\ncp PASS*\/high_completion\/*.fna FINAL-HIGH-COMPLETION\ncp PASS6-refine-redundant-pref10\/low_completion FINAL-LOW-COMPLETION\ncp PASS6-refine-2-redundant-pref3\/low_completion FINAL-LOW-COMPLETION\ncp PASS6-refine2-redundancy-pref3\/high_redundancy FINAL-HIGH-REDUNDANCY","description":"","os_name":"","os_version":"","can_edit":"0"},"is_project":0}]}]}