{"id":32724,"title":"Bioflux Analyses: Image Preprocessing","title_html":"<p>Bioflux Analyses: Image Preprocessing<\/p>","image":{"source":"https:\/\/protocols-files.s3.amazonaws.com\/private\/40242a8afacdec91e823540962334878ee79175d9206d3caefbdb35b8cb49603\/byagbatvp.png?X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAJYFAX46LHRVQMGOA%2F20200205%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200205T131436Z&X-Amz-SignedHeaders=host&X-Amz-Expires=604800&X-Amz-Signature=ecf99642f5938380ce647515127e1ef182bf185ae28e8a1908ef33921b75c297","placeholder":"https:\/\/protocols-files.s3.amazonaws.com\/private\/40242a8afacdec91e823540962334878ee79175d9206d3caefbdb35b8cb49603\/byagbatvp.png?X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAJYFAX46LHRVQMGOA%2F20200205%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200205T131436Z&X-Amz-SignedHeaders=host&X-Amz-Expires=604800&X-Amz-Signature=ecf99642f5938380ce647515127e1ef182bf185ae28e8a1908ef33921b75c297"},"doi":"dx.doi.org\/10.17504\/protocols.io.bb7uirnw","doi_status":2,"uri":"bioflux-analyses-image-preprocessing-bb7uirnw","type_id":1,"published_on":1580977481,"parent_protocols":[],"parent_collections":[],"version_id":1,"created_on":1580908474,"categories":null,"creator":{"name":"Tobias Weise","affiliation":"BioControl Jena GmbH","affiliations":[{"affiliation":"BioControl Jena GmbH","url":"https:\/\/www.biocontrol-jena.com\/","is_default":1}],"username":"tobias-weise","link":null,"image":{"source":"\/img\/avatars\/003.png","placeholder":"\/img\/avatars\/003.png"},"badges":[{"id":2,"image":{"source":"\/img\/badges\/bronze.svg","placeholder":"\/img\/badges\/bronze.svg"},"name":"Author"}],"research_interests":null,"blocked_by_you":false,"blocked_you":false,"hide_following":false},"journal":null,"journal_name":null,"journal_link":null,"article_citation":null,"public":1,"has_versions":false,"link":null,"total_collections":1,"number_of_steps":20,"authors":[{"name":"Tobias Weise","affiliation":"BioControl Jena GmbH, Jena, Germany","affiliations":[],"username":"tobias-weise","link":null,"image":{"source":"\/img\/avatars\/003.png","placeholder":"\/img\/avatars\/003.png"},"badges":[],"research_interests":null,"blocked_by_you":false,"blocked_you":false,"hide_following":false},{"name":"Bettina Boettcher","affiliation":"Septomics Research Center, Friedrich Schiller University and Leibniz Institute for Natural Product Research and Infection Biology \u2013 Hans Kn\u00f6ll Institute, Jena, Germany","affiliations":[],"username":"bettina-boettcher","link":null,"image":{"source":"\/img\/avatars\/013.png","placeholder":"\/img\/avatars\/013.png"},"badges":[],"research_interests":null,"blocked_by_you":false,"blocked_you":false,"hide_following":false},{"name":"Slavena Vylkova","affiliation":"Septomics Research Center, Friedrich Schiller University and Leibniz Institute for Natural Product Research and Infection Biology \u2013 Hans Kn\u00f6ll Institute, Jena, Germany","affiliations":[],"username":null,"link":null,"image":{"source":null,"placeholder":null},"badges":[],"research_interests":null,"blocked_by_you":false,"blocked_you":false,"hide_following":false}],"versions":[],"groups":[],"has_subprotocols":0,"is_subprotocol":0,"is_bookmarked":0,"can_be_copied":1,"can_remove_fork":1,"forks_count":{"private":0,"public":0},"access":{"can_view":1,"can_remove":0,"can_add":0,"can_edit":0,"can_publish":0,"can_get_doi":0,"can_share":1,"can_move":1,"can_move_outside":1,"can_transfer":1,"can_download":1,"is_locked":0},"guid":"148C65FE19EB489C9EBD43F69AE95C30","state_version_id":7,"steps":[{"id":878551,"guid":"FABA8AD4E00644DE9B14EA84F38D31CD","previous_id":null,"previous_guid":null,"modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"EA8C05EA3B484EFB8C1508F0544E0F7B","order_id":1,"type_id":6,"title":"Section","source":{"title":"Video File to Frames"}},{"id":1054724,"guid":"3E2F0DA81C8F4CD28059BD143BC51BD4","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\"><span style = \"font-weight:bold;\">Convert video file into single images<\/span><\/div><div class = \"text-block\"><span>The source material provided as .AVI file is converted into single .TIFF images using <\/span><span style = \"font-style:italic;\">opencv-python. <\/span><span>Additional, a data frame containing meta data annotations is created.<\/span><\/div><\/div>"}}],"cases":[],"data":null,"section":null,"section_color":"#A492FF","section_duration":0,"critical":null,"critical_id":null,"duration":0},{"id":878552,"guid":"13707B0C4A4D403EA5EA090281533A0A","previous_id":878551,"previous_guid":"FABA8AD4E00644DE9B14EA84F38D31CD","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"AD3F47BD4E20482D89EFC97B0A6A3643","order_id":1,"type_id":6,"title":"Section","source":{"title":"Video File to Frames"}},{"id":1054724,"guid":"E91B254C23254AD7A38E4AD0953311D6","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">Import of the required packages.<\/div><div class = \"text-block\"><pre><code><div class = \"text-blocks\"><div class = \"text-block\">import numpy as np<\/div><div class = \"text-block\">import pandas as pd<\/div><div class = \"text-block\">import cv2<\/div><\/div><\/code><\/pre><\/div><\/div>"}}],"cases":[],"data":null,"section":null,"section_color":"#A492FF","section_duration":0,"critical":null,"critical_id":null,"duration":0},{"id":878553,"guid":"4F68DCD11F114DC9AD8812DD4A5D047A","previous_id":878552,"previous_guid":"13707B0C4A4D403EA5EA090281533A0A","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"8A3C1C2535FB491EA2EB1FF03B992020","order_id":1,"type_id":6,"title":"Section","source":{"title":"Video File to Frames"}},{"id":1054724,"guid":"0AE34301EE904DC4BE2CF6289240E2E2","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">Example code for reading the video file from source path and saving the individual images to target path.<\/div><div class = \"text-block\"><pre><code><div class = \"text-blocks\"><div class = \"text-block\">cap = cv2.VideoCapture(source_path\/video_file.AVI)<\/div><div class = \"text-block\">i = 0<\/div><div class = \"text-block\"># read frames from video file<\/div><div class = \"text-block\">while(cap.isOpened()):<\/div><div class = \"text-block\">    ret,frame = cap.read()<\/div><div class = \"text-block\">    if ret == False:<\/div><div class = \"text-block\">        break<\/div><div class = \"text-block\">    # convert to greyscale image<\/div><div class = \"text-block\">    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)<\/div><div class = \"text-block\">    # save to file<\/div><div class = \"text-block\">    cv2.imwrite((target_path + 'frame_%s.TIFF'%i), frame)<\/div><div class = \"text-block\">    i += 1<\/div><div class = \"text-block\">cap.release()<\/div><div class = \"text-block\">cv2.destroyAllWindows()<\/div><\/div><\/code><\/pre><\/div><\/div>"}}],"cases":[],"data":null,"section":null,"section_color":"#A492FF","section_duration":0,"critical":null,"critical_id":null,"duration":0},{"id":878554,"guid":"319722D3882C4D51A69E060D186809B3","previous_id":878553,"previous_guid":"4F68DCD11F114DC9AD8812DD4A5D047A","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"5731380355B14FD99FE8372A361724DE","order_id":1,"type_id":6,"title":"Section","source":{"title":"Video File to Frames"}},{"id":1054724,"guid":"C24B8BBDC95949D2A84E2F4A350835EA","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">Example output of individual image (2D array) .<\/div><div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/protocols-files.s3.amazonaws.com\/private\/40242a8afacdec91e823540962334878ee79175d9206d3caefbdb35b8cb49603\/byahbatvp.png?X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAJYFAX46LHRVQMGOA%2F20200205%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200205T131450Z&X-Amz-SignedHeaders=host&X-Amz-Expires=604800&X-Amz-Signature=c63debcdc171aeede21d8f89f7244b3e85ab967af7f476945d55a7cddc72aede\" \/><\/div><\/div>"}},{"id":1054725,"guid":"CAA981879E354007989D9B37E318CFE7","order_id":2,"type_id":1,"title":"description","source":{"description":"<div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/protocols-files.s3.amazonaws.com\/private\/40242a8afacdec91e823540962334878ee79175d9206d3caefbdb35b8cb49603\/byahbatvp.png?X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAJYFAX46LHRVQMGOA%2F20200205%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200205T131450Z&X-Amz-SignedHeaders=host&X-Amz-Expires=604800&X-Amz-Signature=c63debcdc171aeede21d8f89f7244b3e85ab967af7f476945d55a7cddc72aede\" \/><\/div>"}}],"cases":[],"data":null,"section":null,"section_color":"#A492FF","section_duration":0,"critical":null,"critical_id":null,"duration":0},{"id":878555,"guid":"2F8195C59331427F953253CB45D05E57","previous_id":878554,"previous_guid":"319722D3882C4D51A69E060D186809B3","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"27663750D71B49EB9C904425AAABA73A","order_id":1,"type_id":6,"title":"Section","source":{"title":"Image Processing"}},{"id":1054724,"guid":"32BCF466926744AB953B697424988879","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\"><span style = \"font-weight:bold;\">Automated Image Rotation<\/span><\/div><div class = \"text-block\">Image processing required vertical aligned chamber edges (Fig. 2.1-A). Unaligned video frames would result in peak values scattered in X-direction (conferring to Fig. 2.1-C and D). In order to gain vertical alignment, the rotation angle is estimated by minimising the peak width in X-direction by using a basin-hopping algorithm (scipy.optimize.basinhopping). Standard settings of the package are applied with respect to the convergence criteria. Initial rotation angle is set to 0\u00b0 for all frames.<\/div><\/div>"}}],"cases":[],"data":null,"section":null,"section_color":"#94EBFF","section_duration":0,"critical":null,"critical_id":null,"duration":0},{"id":878556,"guid":"CA29D27D6E05411AAB368D69B8E55973","previous_id":878555,"previous_guid":"2F8195C59331427F953253CB45D05E57","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"77C0A3FA801A45D9A45B72E4312A1608","order_id":1,"type_id":6,"title":"Section","source":{"title":"Image Processing"}},{"id":1054724,"guid":"312DCA2B28D7409D870088A1ABE35CB2","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">Import of the required packages.<\/div><div class = \"text-block\"><pre><code><div class = \"text-blocks\"><div class = \"text-block\">import numpy as np<\/div><div class = \"text-block\">import pandas as pd<\/div><div class = \"text-block\">import cv2<\/div><div class = \"text-block\">import skimage<\/div><div class = \"text-block\">import scipy<\/div><\/div><\/code><\/pre><\/div><\/div>"}}],"cases":[],"data":null,"section":null,"section_color":"#94EBFF","section_duration":0,"critical":null,"critical_id":null,"duration":0},{"id":878557,"guid":"F5FC4697794045439F7A855B59F13D11","previous_id":878556,"previous_guid":"CA29D27D6E05411AAB368D69B8E55973","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"E49EE303431A4142835480C7AA02231F","order_id":1,"type_id":6,"title":"Section","source":{"title":"Image Processing"}},{"id":1054724,"guid":"DCF810ED6EDC4DB9BAEB80B1CB691537","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">Example code of the Automated Image Rotation definition.<\/div><div class = \"text-block\">Strategy:<\/div><div class = \"text-block\"><ol style = \"list-style-type: decimal;\"><li style = \"counter-reset:ol0;\">calculate the median pixel intensity along the y-axis of image<\/li><li style = \"counter-reset:ol0;\">create derivative of median values (absolute values) to find the change in median pixel intensity along y-axis of image<\/li><li style = \"counter-reset:ol0;\">select peak values (representing position of chamber lines \/ peak width correlates to slope of chamber line)<\/li><li style = \"counter-reset:ol0;\">rotate image to minimise the peak width<\/li><\/ol><\/div><div class = \"text-block\"><pre><code><div class = \"text-blocks\"><div class = \"text-block\">def score(a):<\/div><div class = \"text-block\">    # rotate image by given angle 'a'<\/div><div class = \"text-block\">    img_rot = skimage.transform.rotate(img,a,resize=True)<\/div><div class = \"text-block\">    # calculate median of pixel intensity along the y-axis of image<\/div><div class = \"text-block\">    xmedian = np.zeros(len(img_rot))<\/div><div class = \"text-block\">    for i in range(len(img_rot)):<\/div><div class = \"text-block\">        xmedian[i] = np.median(img_rot[i])<\/div><div class = \"text-block\">    # add median values to data frame <\/div><div class = \"text-block\">    df = pd.DataFrame(data={'xmedian':xmedian})<\/div><div class = \"text-block\">    # create derivative along the median values (absolute values)<\/div><div class = \"text-block\">    # 'xdiff' represents change in median pixel intensity along y-axis of image<\/div><div class = \"text-block\">    df['xdiff'] = pd.DataFrame.diff(df.xmedian, periods=1, axis=0).abs()<\/div><div class = \"text-block\">    # select 'xdiff' values >= 98% percentile  to new data frame<\/div><div class = \"text-block\">    qdf = df[df.xdiff >= np.nanpercentile(df.xdiff,98)]<\/div><div class = \"text-block\">    qdf = qdf.reset_index()<\/div><div class = \"text-block\">    qdf.rename(columns={'index':'imgdex'},inplace=True)<\/div><div class = \"text-block\">    # cluster selected xdiff values into 4 clusters <\/div><div class = \"text-block\">    # (representing the position of camber lines in y-direction)<\/div><div class = \"text-block\">    qdf['cluster'] = pd.cut(qdf.imgdex,4,right=True,labels=[0,1,2,3])<\/div><div class = \"text-block\">    # calculating the width of cluster <\/div><div class = \"text-block\">    imgdex = np.zeros(4)<\/div><div class = \"text-block\">    for i in range(4):<\/div><div class = \"text-block\">        imgdex[i] = qdf.imgdex[qdf.cluster == i].max() - \\<\/div><div class = \"text-block\">                    qdf.imgdex[qdf.cluster == i].min()<\/div><div class = \"text-block\">    imgdex = np.array(imgdex, dtype='float')<\/div><div class = \"text-block\">    # returning sum of cluster width    <\/div><div class = \"text-block\">    return imgdex.sum()<\/div><\/div><\/code><\/pre><\/div><\/div>"}}],"cases":[],"data":null,"section":null,"section_color":"#94EBFF","section_duration":0,"critical":null,"critical_id":null,"duration":0},{"id":878558,"guid":"B1CCC4FC9A1B46C7A17618C55514A80E","previous_id":878557,"previous_guid":"F5FC4697794045439F7A855B59F13D11","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"F8C9ECFD981F4A76B1F330D4DDA2A07A","order_id":1,"type_id":6,"title":"Section","source":{"title":"Image Processing"}},{"id":1054724,"guid":"3B1486AE7CA54CEC975CAB145A15454E","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">Example code of Automated Image Rotation execution.<\/div><div class = \"text-block\"><pre><code><div class = \"text-blocks\"><div class = \"text-block\"># load meta data frame<\/div><div class = \"text-block\">data = pd.read_pickle((data_path + 'data.pkl'))<\/div><div class = \"text-block\"># loop over all images<\/div><div class = \"text-block\">angle = np.zeros(len(data))<\/div><div class = \"text-block\">for i in range(len(data)):<\/div><div class = \"text-block\">    # read respective image and invert<\/div><div class = \"text-block\">    img =  255 - skimage.io.imread((source_path + 'frame_%s.TIF'%i))<\/div><div class = \"text-block\">    # estimate rotation angle using basinhopping initial rotation angle = 0\u00b0<\/div><div class = \"text-block\">    answ = scipy.optimize.basinhopping(score,0,niter=200)<\/div><div class = \"text-block\">    angle[i] = answ.x[0]<\/div><div class = \"text-block\"># append angles to meta data frame + save data frame to file<\/div><div class = \"text-block\">data['angle'] = angle<\/div><div class = \"text-block\">data.to_pickle((data_path + 'data.pkl'))<\/div><\/div><\/code><\/pre><\/div><\/div>"}}],"cases":[],"data":null,"section":null,"section_color":"#94EBFF","section_duration":0,"critical":null,"critical_id":null,"duration":0},{"id":878559,"guid":"1EAD3EF179764916A5D3133B618337E5","previous_id":878558,"previous_guid":"B1CCC4FC9A1B46C7A17618C55514A80E","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"EFB5534D2831405F8FD919443125ADD2","order_id":1,"type_id":6,"title":"Section","source":{"title":"Image Processing"}},{"id":1054724,"guid":"D59632E82C2E4C37B663EBDE42C94467","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\"><span style = \"font-weight:bold;\">Chamber Edge Determination<\/span><\/div><div class = \"text-block\">The individual image contains two growth chambers separated by four edge lines (Fig. 2.1-A). Median pixel intensity (in Y-direction) is calculated for each position in X-direction (Fig 2.1-B), and subsequently derived into the absolute difference in median pixel intensity (Fig. 2.1-C). Values greater or equal to the 98 % percentile of the respective data set (peak values) are assigned into four equidistant clusters (Fig. 2.1-D). The maximum peak value of the respective cluster returns the X-position of the respective chamber edge.<\/div><div class = \"text-block\">Visualisation of Chamber Edge Determination.<\/div><div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/protocols-files.s3.amazonaws.com\/private\/40242a8afacdec91e823540962334878ee79175d9206d3caefbdb35b8cb49603\/byaibatvp.png?X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAJYFAX46LHRVQMGOA%2F20200205%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200205T131450Z&X-Amz-SignedHeaders=host&X-Amz-Expires=604800&X-Amz-Signature=71c6b29fec53c2707dd8e8cdc6c8558e6ad175d0d8f837fbdae1f18068d58bbb\" \/><\/div><\/div>"}},{"id":1054725,"guid":"9A3898C8A58641DFA0C230FB62546CF0","order_id":2,"type_id":1,"title":"description","source":{"description":"<div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/protocols-files.s3.amazonaws.com\/private\/40242a8afacdec91e823540962334878ee79175d9206d3caefbdb35b8cb49603\/byaibatvp.png?X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAJYFAX46LHRVQMGOA%2F20200205%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200205T131450Z&X-Amz-SignedHeaders=host&X-Amz-Expires=604800&X-Amz-Signature=71c6b29fec53c2707dd8e8cdc6c8558e6ad175d0d8f837fbdae1f18068d58bbb\" \/><\/div>"}}],"cases":[],"data":null,"section":null,"section_color":"#94EBFF","section_duration":0,"critical":null,"critical_id":null,"duration":0},{"id":878560,"guid":"15B4C29136EE4B248CA9205988673343","previous_id":878559,"previous_guid":"1EAD3EF179764916A5D3133B618337E5","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"FECB166E8D05456792E87F2D271C549C","order_id":1,"type_id":6,"title":"Section","source":{"title":"Image Processing"}},{"id":1054724,"guid":"0DE3E278010D44E091ECAEDC5025B92C","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">Import of the required packages.<\/div><div class = \"text-block\"><pre><code><div class = \"text-blocks\"><div class = \"text-block\">import numpy as np<\/div><div class = \"text-block\">import pandas as pd<\/div><div class = \"text-block\">import skimage<\/div><\/div><\/code><\/pre><\/div><\/div>"}}],"cases":[],"data":null,"section":null,"section_color":"#94EBFF","section_duration":0,"critical":null,"critical_id":null,"duration":0},{"id":878561,"guid":"197044C9F7F54C6DB0A32A6094180C96","previous_id":878560,"previous_guid":"15B4C29136EE4B248CA9205988673343","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"4A72EAB0858F44FB921AEEA4AF08613E","order_id":1,"type_id":6,"title":"Section","source":{"title":"Image Processing"}},{"id":1054724,"guid":"F0F85BB751A449138297E2EB713F8EAB","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">Example code of the Chamber Edge Determination definition.<\/div><div class = \"text-block\">Strategy:     <\/div><div class = \"text-block\"><ol style = \"list-style-type: decimal;\"><li style = \"counter-reset:ol0;\">calculate the median pixel intensity along the y-axis of image<\/li><li style = \"counter-reset:ol0;\">create derivative of median values (absolute values) to find the change in median pixel intensity along x-axis of image     <\/li><li style = \"counter-reset:ol0;\">select peak values (representing position of chamber lines)<\/li><li style = \"counter-reset:ol0;\">calculation of 6 positions (left chamber (2 lines), inner space (2 lines), right chamber (2 lines))<\/li><\/ol><\/div><div class = \"text-block\"><pre><code><div class = \"text-blocks\"><div class = \"text-block\">def find_lines(img):<\/div><div class = \"text-block\">    #invert image<\/div><div class = \"text-block\">    img_bin = 255 - img<\/div><div class = \"text-block\">    # calculate median intensity row-wise<\/div><div class = \"text-block\">    xmedian = np.zeros(len(img_bin))<\/div><div class = \"text-block\">    for i in range(len(img_bin)):<\/div><div class = \"text-block\">        xmedian[i] = np.median(img_bin[i])<\/div><div class = \"text-block\">    # median values to DataFrame<\/div><div class = \"text-block\">    df = pd.DataFrame(data={'xmedian':xmedian})<\/div><div class = \"text-block\">    # calculate absolutes of differences of pixels row-wise<\/div><div class = \"text-block\">    df['xdiff'] = pd.DataFrame.diff(df.xmedian, periods=1, axis=0).abs()<\/div><div class = \"text-block\">    # calculate 98% percentile & pic values above this threshold<\/div><div class = \"text-block\">    qdf = df[df.xdiff >= np.nanpercentile(df.xdiff,98)].copy()<\/div><div class = \"text-block\">    qdf.reset_index(inplace=True)<\/div><div class = \"text-block\">    qdf.rename(columns={'index':'imgdex'},inplace=True)<\/div><div class = \"text-block\">    # assign imgdex to four clusters <\/div><div class = \"text-block\">    qdf['cluster'] = pd.cut(qdf.imgdex,4,right=True,labels=[0,1,2,3])<\/div><div class = \"text-block\">    # assign 6 lines (using 5 pixels safety distance)<\/div><div class = \"text-block\">    imgdex = np.zeros(6)<\/div><div class = \"text-block\">    imgdex[0] = qdf.imgdex[(qdf.cluster == 0) & \\<\/div><div class = \"text-block\">    (qdf.xdiff == qdf.xdiff[(qdf.cluster == 0)].max())].max() + 5<\/div><div class = \"text-block\">    imgdex[1] = qdf.imgdex[(qdf.cluster == 1) & \\<\/div><div class = \"text-block\">    (qdf.xdiff == qdf.xdiff[(qdf.cluster == 1)].max())].min() - 5<\/div><div class = \"text-block\">    imgdex[2] = qdf.imgdex[(qdf.cluster == 1) & \\<\/div><div class = \"text-block\">    (qdf.xdiff == qdf.xdiff[(qdf.cluster == 1)].max())].max() + 5<\/div><div class = \"text-block\">    imgdex[3] = qdf.imgdex[(qdf.cluster == 2) & \\<\/div><div class = \"text-block\">    (qdf.xdiff == qdf.xdiff[(qdf.cluster == 2)].max())].min() - 5<\/div><div class = \"text-block\">    imgdex[4] = qdf.imgdex[(qdf.cluster == 2) & \\<\/div><div class = \"text-block\">    (qdf.xdiff == qdf.xdiff[(qdf.cluster == 2)].max())].max() + 5<\/div><div class = \"text-block\">    imgdex[5] = qdf.imgdex[(qdf.cluster == 3) & \\<\/div><div class = \"text-block\">    (qdf.xdiff == qdf.xdiff[(qdf.cluster == 3)].max())].min() - 5<\/div><div class = \"text-block\">    imgdex = np.array(imgdex, dtype='int')<\/div><div class = \"text-block\">    # return lines as integer array<\/div><div class = \"text-block\">    return imgdex<\/div><\/div><\/code><\/pre><\/div><\/div>"}}],"cases":[],"data":null,"section":null,"section_color":"#94EBFF","section_duration":0,"critical":null,"critical_id":null,"duration":0},{"id":878562,"guid":"9DC53AECD2684B87B7CA24C2D6371FAF","previous_id":878561,"previous_guid":"197044C9F7F54C6DB0A32A6094180C96","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"BD9471252C95432BBAB57FAAD54B2B7C","order_id":1,"type_id":6,"title":"Section","source":{"title":"Image Processing"}},{"id":1054724,"guid":"91A8FC7D9DD841FBB4EA48A91CB50E27","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">Example code of the Chamber Edge Determination execution.<\/div><div class = \"text-block\"><pre><code><div class = \"text-blocks\"><div class = \"text-block\"># load meta data frame<\/div><div class = \"text-block\">data = pd.read_pickle((data_path + 'data.pkl'))<\/div><div class = \"text-block\"># loop over all images<\/div><div class = \"text-block\">line1, line2, line3, line4, line5, line6 = [np.zeros(len(data)) for i in range(6)]<\/div><div class = \"text-block\">for i in range(len(data)):<\/div><div class = \"text-block\">    clear_output()<\/div><div class = \"text-block\">    # read respective image<\/div><div class = \"text-block\">    img = skimage.io.imread((source_path + 'frame_%s.TIFF'%i))<\/div><div class = \"text-block\">    # rotate image <\/div><div class = \"text-block\">    img = skimage.transform.rotate(img,data.angle.median(),\\<\/div><div class = \"text-block\">                                   resize=True,mode='constant',cval=1)<\/div><div class = \"text-block\">    # find lines<\/div><div class = \"text-block\">    lines = find_lines(img)<\/div><div class = \"text-block\">    line1[i], line2[i], line3[i], line4[i], line5[i], line6[i] = lines<\/div><div class = \"text-block\"># append positions to meta data frame<\/div><div class = \"text-block\">data['line1'] = line1<\/div><div class = \"text-block\">data['line2'] = line2<\/div><div class = \"text-block\">data['line3'] = line3<\/div><div class = \"text-block\">data['line4'] = line4<\/div><div class = \"text-block\">data['line5'] = line5<\/div><div class = \"text-block\">data['line6'] = line6<\/div><div class = \"text-block\"># convert values into integers<\/div><div class = \"text-block\">data.line1 = pd.to_numeric(data.line1, errors='raise', downcast='integer')<\/div><div class = \"text-block\">data.line2 = pd.to_numeric(data.line2, errors='raise', downcast='integer')<\/div><div class = \"text-block\">data.line3 = pd.to_numeric(data.line3, errors='raise', downcast='integer')<\/div><div class = \"text-block\">data.line4 = pd.to_numeric(data.line4, errors='raise', downcast='integer')<\/div><div class = \"text-block\">data.line5 = pd.to_numeric(data.line5, errors='raise', downcast='integer')<\/div><div class = \"text-block\">data.line6 = pd.to_numeric(data.line6, errors='raise', downcast='integer')<\/div><div class = \"text-block\">save meta data frame to file<\/div><div class = \"text-block\">data.to_pickle((data_path + 'data.pkl'))<\/div><\/div><\/code><\/pre><\/div><\/div>"}}],"cases":[],"data":null,"section":null,"section_color":"#94EBFF","section_duration":0,"critical":null,"critical_id":null,"duration":0},{"id":878563,"guid":"BD64D5DD413C40039B8DEFFFD13AAA6B","previous_id":878562,"previous_guid":"9DC53AECD2684B87B7CA24C2D6371FAF","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"1BA5534CE283496E938C9741F148E50D","order_id":1,"type_id":6,"title":"Section","source":{"title":"Image Processing"}},{"id":1054724,"guid":"8746215E1C9641C98AE7E0181FA96781","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\"><span style = \"font-weight:bold;\">Chamber Selection and Background Removal<\/span><\/div><div class = \"text-block\">Chambers were selected from the respective video frame between the determined chamber edges (according to Fig. 2.1-D). In order to exclude the chamber edge itself, a safety distance of 5 pixels in X-direction is applied. Also, a background removal was performed by subtracting the median intensity of the reference space resolved in Y-direction. Reference was selected as a 100 pixel wide strip next to cluster 1 (Fig. 2.1-D).<\/div><\/div>"}}],"cases":[],"data":null,"section":null,"section_color":"#94EBFF","section_duration":0,"critical":null,"critical_id":null,"duration":0},{"id":878564,"guid":"33BE32FBBDFB426DBDC0A9C38F874773","previous_id":878563,"previous_guid":"BD64D5DD413C40039B8DEFFFD13AAA6B","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"4E1FC310911046CCA7D041CE59C2490E","order_id":1,"type_id":6,"title":"Section","source":{"title":"Image Processing"}},{"id":1054724,"guid":"1930D0686D0D47A68E579B3305D3FC3B","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">Import of the required packages.<\/div><div class = \"text-block\"><pre><code><div class = \"text-blocks\"><div class = \"text-block\">import numpy as np<\/div><div class = \"text-block\">import pandas as pd<\/div><div class = \"text-block\">import skimage<\/div><div class = \"text-block\">from skimage import img_as_uint<\/div><div class = \"text-block\">import cv2<\/div><\/div><\/code><\/pre><\/div><\/div>"}}],"cases":[],"data":null,"section":null,"section_color":"#94EBFF","section_duration":0,"critical":null,"critical_id":null,"duration":0},{"id":878565,"guid":"D1ECF79C6AB04BD39F0AB5C93AD38DC8","previous_id":878564,"previous_guid":"33BE32FBBDFB426DBDC0A9C38F874773","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"295270A34CD248BCAA8B6C0796DE2D09","order_id":1,"type_id":6,"title":"Section","source":{"title":"Image Processing"}},{"id":1054724,"guid":"7C4A426174714AAE87EB9A0B6E68D927","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">Example code of image rotation and chamber cutting execution.<\/div><div class = \"text-block\"><pre><code><div class = \"text-blocks\"><div class = \"text-block\"># load meta data frame from file<\/div><div class = \"text-block\">data = pd.read_pickle((data_path + 'data.pkl'))<\/div><div class = \"text-block\"># loop over all images <\/div><div class = \"text-block\">for i in range(len(data)):<\/div><div class = \"text-block\">    clear_output()<\/div><div class = \"text-block\">    print('processing file ',i+1,' of ',len(data))<\/div><div class = \"text-block\">    # read respective image<\/div><div class = \"text-block\">    img = skimage.io.imread((source_path + 'frame_%s.TIFF'%i))<\/div><div class = \"text-block\">    # rotate image<\/div><div class = \"text-block\">    img = skimage.transform.rotate(img,data.angle.median(),resize=False)<\/div><div class = \"text-block\">    # cut image into desired cambers<\/div><div class = \"text-block\">    # applying 10 pixels as safety distance in x-direction<\/div><div class = \"text-block\">    img_cham_A = img[data.line1[i]:data.line2[i], 10:len(img[0])-10]<\/div><div class = \"text-block\">    img_cham_B = img[data.line5[i]:data.line6[i], 10:len(img[0])-10]<\/div><div class = \"text-block\">    # save images to folder<\/div><div class = \"text-block\">    skimage.io.imsave((target_path + '00_WT\/frame_%s_WT.TIFF'%i), \\<\/div><div class = \"text-block\">                       img_as_uint(img_cham_A))<\/div><div class = \"text-block\">    skimage.io.imsave((target_path + '01_MT\/frame_%s_MT.TIFF'%i), \\<\/div><div class = \"text-block\">                       img_as_uint(img_cham_B))<\/div><\/div><\/code><\/pre><\/div><\/div>"}}],"cases":[],"data":null,"section":null,"section_color":"#94EBFF","section_duration":0,"critical":null,"critical_id":null,"duration":0},{"id":878566,"guid":"ADD0F10B748742C59F376D36F08A9922","previous_id":878565,"previous_guid":"D1ECF79C6AB04BD39F0AB5C93AD38DC8","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"16625940B8134B86AD83B66733A9166A","order_id":1,"type_id":6,"title":"Section","source":{"title":"Image Processing"}},{"id":1054724,"guid":"57868C5CBCDE4447AA5445DCFD0C7B8B","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">Example code of background removal execution.\n<\/div><div class = \"text-block\"><pre><code><div class = \"text-blocks\"><div class = \"text-block\"># load meta data frame from file<\/div><div class = \"text-block\">data = pd.read_pickle((data_path + 'data.pkl'))<\/div><div class = \"text-block\"># loop over all images <\/div><div class = \"text-block\">for i in range(len(data)):<\/div><div class = \"text-block\">    clear_output()<\/div><div class = \"text-block\">    print('sample',k+1,'processing file ',i+1,' of ',len(data))<\/div><div class = \"text-block\">    # read respective image<\/div><div class = \"text-block\">    # read + rotate original image<\/div><div class = \"text-block\">    img = cv2.imread((source_path + 'frame_%s.TIFF'%i),0)<\/div><div class = \"text-block\">    img = skimage.transform.rotate(img,data.angle.median(),resize=False)<\/div><div class = \"text-block\">    img = img_as_ubyte(img)<\/div><div class = \"text-block\">    # invert image <\/div><div class = \"text-block\">    img = 255 - img<\/div><div class = \"text-block\">    # read chamber images<\/div><div class = \"text-block\">    img_cham_A = cv2.imread((source_path + '00_WT\/frame_%s_WT.TIFF'%i),0)<\/div><div class = \"text-block\">    img_cham_B = cv2.imread((source_path + '01_MT\/frame_%s_MT.TIFF'%i),0)<\/div><div class = \"text-block\">    # invert chamber images<\/div><div class = \"text-block\">    img_cham_A = 255 - img_cham_A<\/div><div class = \"text-block\">    img_cham_B = 255 - img_cham_B<\/div><div class = \"text-block\">    # rotate chamber images 90\u00b0<\/div><div class = \"text-block\">    img_cham_A = np.array([list(i) for i in zip(*img_cham_A)], dtype=np.int16)<\/div><div class = \"text-block\">    img_cham_B = np.array([list(i) for i in zip(*img_cham_B)], dtype=np.int16)<\/div><div class = \"text-block\">    # cut reference space (+ invert)<\/div><div class = \"text-block\">    refspace = img[data.line3[i]:data.line3[i]+100, 10:len(img[0])-10]<\/div><div class = \"text-block\">    # rotate refspace 90\u00b0<\/div><div class = \"text-block\">    refspace90 = np.array([list(i) for i in zip(*refspace)], dtype=np.int16)<\/div><div class = \"text-block\">    # calculate median intensity of background<\/div><div class = \"text-block\">    background = np.zeros(len(refspace90))<\/div><div class = \"text-block\">    for j in range(len(refspace90)):<\/div><div class = \"text-block\">        background[j] = np.median(refspace90[j])<\/div><div class = \"text-block\">    background = np.array(background,dtype=np.int16)<\/div><div class = \"text-block\">    # create new empty image<\/div><div class = \"text-block\">    cham_A_new = np.zeros(img_cham_A.shape, dtype=np.int16)<\/div><div class = \"text-block\">    cham_B_new = np.zeros(img_cham_B.shape, dtype=np.int16)<\/div><div class = \"text-block\">    # subtract background<\/div><div class = \"text-block\">    for l in range(len(background)):<\/div><div class = \"text-block\">        cham_A_new[l] = img_cham_A[l] - background[l]<\/div><div class = \"text-block\">        cham_B_new[l] = img_cham_B[l] - background[l]<\/div><div class = \"text-block\">    # rotate and invert new images back to 0\u00b0<\/div><div class = \"text-block\">    cham_A_new = 255 - np.array([list(i) for i in zip(*cham_A_new)], \\     <\/div><div class = \"text-block\">                                dtype=np.int16).clip(0, 255)<\/div><div class = \"text-block\">    cham_B_new = 255 - np.array([list(i) for i in zip(*cham_B_new)], \\<\/div><div class = \"text-block\">                                dtype=np.int16).clip(0, 255)<\/div><div class = \"text-block\">    # save images to folder<\/div><div class = \"text-block\">    cv2.imwrite((target_path[k] + '00_WT\/frame_%s_WT.TIFF'%i),cham_A_new)<\/div><div class = \"text-block\">    cv2.imwrite((target_path[k] + '01_MT\/frame_%s_MT.TIFF'%i),cham_B_new)<\/div><\/div><\/code><\/pre><\/div><\/div>"}}],"cases":[],"data":null,"section":null,"section_color":"#94EBFF","section_duration":0,"critical":null,"critical_id":null,"duration":0},{"id":878567,"guid":"D745FC76B7C844D9B5EF3C04473375AE","previous_id":878566,"previous_guid":"ADD0F10B748742C59F376D36F08A9922","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"384C68529BA341ADA0B2F8E4F4D0AB06","order_id":1,"type_id":6,"title":"Section","source":{"title":"Calculation of Pixel Intensity"}},{"id":1054724,"guid":"33CC8C8ECA404F77AFCAEFB3463A4CDE","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\"><span>The mean pixel intensity I<\/span><span style = \"vertical-align:sub;\">pix<\/span><span> (i. e. gray scale value; reflecting cell density) for each of the two chambers is calculated. The values are added into the respective data frame. Growth rates \u00b5 are derived from I<\/span><span style = \"vertical-align:sub;\">pix<\/span><span> using the central difference approximation below.<\/span><\/div><div style = \"text-align :; float : ;\"><span style = \"\">\\mu(t_{\\rm i}) = \\frac{I_{\\rm pix}(t_{\\rm i+1}) - I_{\\rm pix}(t_{\\rm i-1})}{\\left(t_{\\rm i+1}-t_{\\rm i-1}\\right)\\cdot I_{\\rm pix}(t_{\\rm i})}<\/span><\/div><div class = \"text-block\"><span>Legend: \u00b5(t<\/span><span style = \"vertical-align:sub;\">i<\/span><span>) - growth rate \u00b5 at time point t<\/span><span style = \"vertical-align:sub;\">i, <\/span><span style = \"vertical-align:sub;vertical-align:sub;\">I<\/span><span style = \"vertical-align:sub;\">pix<\/span><span>(t<\/span><span style = \"vertical-align:sub;\">i<\/span><span>) - mean pixel intensity at time point t<\/span><span style = \"vertical-align:sub;\">i<\/span><span>, i - i<\/span><span style = \"vertical-align:super;\">th<\/span><span> measurement<\/span><\/div><\/div>"}}],"cases":[],"data":null,"section":null,"section_color":"#84CE84","section_duration":0,"critical":null,"critical_id":null,"duration":0},{"id":878568,"guid":"730F00A6F1094E3393FF7F90EFC6CBDB","previous_id":878567,"previous_guid":"D745FC76B7C844D9B5EF3C04473375AE","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"828DE85EA19540F59ACFA5FCF757E83C","order_id":1,"type_id":6,"title":"Section","source":{"title":"Calculation of Pixel Intensity"}},{"id":1054724,"guid":"945ED05CD38249D09FFCA97DEE77D4F7","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">Import of the required packages.<\/div><div class = \"text-block\"><pre><code><div class = \"text-blocks\"><div class = \"text-block\">import numpy as np<\/div><div class = \"text-block\">import pandas as pd<\/div><div class = \"text-block\">import skimage<\/div><div class = \"text-block\">from skimage import img_as_float<\/div><\/div><\/code><\/pre><\/div><\/div>"}}],"cases":[],"data":null,"section":null,"section_color":"#84CE84","section_duration":0,"critical":null,"critical_id":null,"duration":0},{"id":878569,"guid":"4C279CDD0A634202AAB670905D314649","previous_id":878568,"previous_guid":"730F00A6F1094E3393FF7F90EFC6CBDB","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"9A2C634CAE754F5D959D72AB7C8835F4","order_id":1,"type_id":6,"title":"Section","source":{"title":"Calculation of Pixel Intensity"}},{"id":1054724,"guid":"F0988E84B6AE486191015706201DE57A","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">Example code of Mean Pixel Intensity Calculation.<\/div><div class = \"text-block\"><pre><code><div class = \"text-blocks\"><div class = \"text-block\">data = pd.read_pickle((data_path + 'data.pkl'))<\/div><div class = \"text-block\"># create time column (within this batch: measurements every 20min -> index \/ 3)<\/div><div class = \"text-block\">data['time'] = data.index \/ 3 # [h]<\/div><div class = \"text-block\">meanGrayWT, meanGrayMT, \\<\/div><div class = \"text-block\">varGrayWT, varGrayMT = [np.zeros(len(data)) for i in range(4)]<\/div><div class = \"text-block\">for k in range(len(data)):<\/div><div class = \"text-block\">    imgWT = 1 - img_as_float(skimage.io.imread((source_path + \\<\/div><div class = \"text-block\">                                                '00_WT\/frame_%s_WT.TIF'%k)))<\/div><div class = \"text-block\">    imgMT = 1 - img_as_float(skimage.io.imread((source_path + \\<\/div><div class = \"text-block\">                                                '01_MT\/frame_%s_MT.TIF'%k)))<\/div><div class = \"text-block\">    meanGrayWT[k] = np.mean(imgWT)<\/div><div class = \"text-block\">    meanGrayMT[k] = np.mean(imgMT)<\/div><div class = \"text-block\">data['greyWTint'] = meanGrayWT<\/div><div class = \"text-block\">data['greyMTint'] = meanGrayMT<\/div><div class = \"text-block\">data['greyWTmu'] = np.gradient(data.greyWTint) \/ data.greyWTint * 3<\/div><div class = \"text-block\">data['greyMTmu'] = np.gradient(data.greyMTint) \/ data.greyMTint * 3<\/div><div class = \"text-block\">data.to_pickle((data_path + 'data.pkl'))<\/div><\/div><\/code><\/pre><\/div><\/div>"}}],"cases":[],"data":null,"section":null,"section_color":"#84CE84","section_duration":0,"critical":null,"critical_id":null,"duration":0},{"id":878570,"guid":"C5F76D0089D44F63BDD8DB57C840A85E","previous_id":878569,"previous_guid":"4C279CDD0A634202AAB670905D314649","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"AC9A1402F3824DC1870CE11B3C52DDE3","order_id":1,"type_id":6,"title":"Section","source":{"title":"Calculation of Pixel Intensity"}},{"id":1054724,"guid":"A68C487CD4904E839CC47C2EFB31A1F8","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">Visualisation of the calculated data.<\/div><div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/protocols-files.s3.amazonaws.com\/private\/40242a8afacdec91e823540962334878ee79175d9206d3caefbdb35b8cb49603\/byajbatvp.png?X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAJYFAX46LHRVQMGOA%2F20200205%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200205T131450Z&X-Amz-SignedHeaders=host&X-Amz-Expires=604800&X-Amz-Signature=6e78c2f43acfc2e6c5a733c8a236886c9ec7ffad548563b7a6282d3068807d28\" \/><\/div><\/div>"}},{"id":1054725,"guid":"060D3B92191E483793E181C0525DA77E","order_id":2,"type_id":1,"title":"description","source":{"description":"<div style = \"text-align :; float : ;\"><img style = \"\" src = \"https:\/\/protocols-files.s3.amazonaws.com\/private\/40242a8afacdec91e823540962334878ee79175d9206d3caefbdb35b8cb49603\/byajbatvp.png?X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAJYFAX46LHRVQMGOA%2F20200205%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200205T131450Z&X-Amz-SignedHeaders=host&X-Amz-Expires=604800&X-Amz-Signature=6e78c2f43acfc2e6c5a733c8a236886c9ec7ffad548563b7a6282d3068807d28\" \/><\/div>"}}],"cases":[],"data":null,"section":null,"section_color":"#84CE84","section_duration":0,"critical":null,"critical_id":null,"duration":0}],"document":null,"materials":[],"description":"<div class = \"text-blocks\"><div class = \"text-block\">Biofilm formation under shear flow conditions was monitored using the Bioflux1000 device (Fluxion Biosciences, Inc.). In short, Candida albicans overnight cultures were washed in pre-warmed RPMI medium. Cells were seeded for 2-5 sec from the outlet well into the channels of Bioflux1000 flow chambers, which were primed before with warm medium. The cells were allowed to adhere to the channels for 90 min without any flow, followed by removal of non-adherent cells by flowing fresh, pre-warmed RPMI medium for 5 sec. Shear flow was set for time series experiments over 24 h biofilm formation and images were captured every 20 min. Two channels were investigated in parallel having a 10 \u00d7 magnification to allow a direct comparison between a mutant and a reference (wild-type) strain. Image capturing and stacks to movies was performed using the MetaMorph\u00ae Software (Molecular Devices).<\/div><div class = \"text-block\">Source material provided as AVI files was converted into single TIFF images as well as data frames containing meta data annotations. The individual image contains two growth chambers (wild type and mutant) separated by four edge lines. Images were rotated automatically to vertical alignment in order to carry out an automated chamber detection and analysis. The mean pixel intensity (i. e. grey scale value; reflecting cell density) of the individual chamber was calculated and added into the respective data frame. <\/div><div class = \"text-block\">All computations were performed using the programming language python (version 3.6.9) and the additional packages numpy (version 1.16.2), opencv-python (version 4.1.1.26), pandas (version 0.25.0) and scikit-image (version 0.15.0).<\/div><\/div>","changed_on":1580977481}