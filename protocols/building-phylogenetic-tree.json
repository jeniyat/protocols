{"uri":"building-phylogenetic-tree-mp5c5q6","version_id":"0","protocol_name":"Building  Phylogenetic Tree","protocol_name_html":"Building  Phylogenetic Tree","is_prepublished":"0","can_edit":"0","parent_id":null,"api_version":"1","is_new_mode":"0","last_modified":"1523409063","type_id":"1","link":null,"fork_id":"","public_fork_note":"","number_of_steps":"8","has_versions":"0","first_published_date":"1523409063","publish_date":"2018-04-11 01:11:03","documents":null,"have_protocol_in_step":"0","is_protocol_in_step":"0","vendor_name":"Contributed by users","vendor_link":"https:\/\/www.protocols.io","vendor_logo":"\/img\/vendors\/1.png","mod_mins":"-45","mod_secs":"1","description":"<p><em><strong>Making a Phylogenetic Tree<\/strong><\/em><\/p>\n<p>\u00a0<\/p>\n<p>In this procedure we are going to build a phylogenetic tree! Throughout I'll refer to scripts available on my github here. We will be using the 16 ribosomal proteins used in Hug et al. 2016. The HMM models for these are available on my github in a file called `hug_ribosomalmarkers.hmm`. We will be running this tutorial using the genomes and files found in the folder `Example`.<\/p>\n<p>\u00a0<\/p>\n<p>As an overview I will be explaining<\/p>\n<p>1. How to generate gene predictions using prodigal for genomes of interest<\/p>\n<p>2. How to identify ribosomal proteins using an hmm model<\/p>\n<p>3. How to align, trim, and concatenate proteins for a phylogenetic tree<\/p>\n<p>4. building a phylogenetic tree<\/p>","is_bookmarked":"0","can_reassign":"1","before_start":"<p>Before Starting Be sure you have all the required Pre-Requisites.\u00a0<\/p>\n<p>\u00a0<\/p>\n<p>Python2.7<\/p>\n<p>BioPython<\/p>\n<p>HMMER<\/p>\n<p>Prodigal<\/p>\n<p>BinSanity<\/p>\n<p>Muscle<\/p>\n<p>TrimAL<\/p>\n<p>FastTree<\/p>\n<p>\u00a0<\/p>\n<p>See <a href=\"https:\/\/github.com\/edgraham\/PhylogenomicsWorkflow\/tree\/master\" target=\"_blank\" rel=\"noopener noreferrer\">this github page<\/a> for links to all dependencies.<\/p>","has_guidelines":"0","materials":[],"warning":null,"version_class":"9693","public":"1","is_owner":"1","is_original_owner":"1","created_on":"1516224195","protocol_affiliation":"University of Southern California,Center for Dark Energy Biosphere Investigations","affiliation":"University of Southern California","doi":"dx.doi.org\/10.17504\/protocols.io.mp5c5q6","doi_status":"2","changed_fork_steps":null,"profile_url":"Elaina-w213b4v2v2","protocol_img":"https:\/\/www.protocols.io\/img\/default_protocol.png","profile_image":"\/img\/avatars\/011.png","full_name":"Elaina Graham","created_by":"Elaina Graham","private_link":"9DD6E75AE1D0240AF37A9901315E8C20","original_img":"1","username":"elaina-graham","is_retracted":"0","retraction_reason":null,"plos_id":null,"manuscript_citation":null,"journal_name":null,"is_donations_disabled":"0","is_donations_disabled_by_user":"9","item_record_id":232651,"fork_info":[],"compare_forks":[],"protocols":[],"groups":[],"number_of_shared_runs":[],"ownership_history":[],"keywords":"","transfer_to_user":[],"sub_transfer":false,"is_transfer_pending":false,"number_of_bookmarks":"0","collections":[],"tags":[],"archived":0,"sub_authors":[],"sub_protocols_number":0,"can_edit_shared":0,"shared_runs":[],"is_shared_run":0,"is_shared":1,"banner":null,"contact_badges":[{"badge_id":"2","badge_image":"\/img\/badges\/bronze.svg","badge_description":"Author!"},{"badge_id":"5","badge_image":"\/img\/badges\/earlyadopter.svg","badge_description":"Early adopter"}],"number_of_comments":0,"is_locked":0,"is_locked_by":false,"authors":"Elaina Graham,Benjamin Tully","authors_list":[{"name":"Elaina Graham","affiliation":"University of Southern California","username":"elaina-graham","profile_image":"\/img\/avatars\/011.png"},{"name":"Benjamin Tully","affiliation":"Center for Dark Energy Biosphere Investigations","username":"benjamin-tully","profile_image":"https:\/\/s3.amazonaws.com\/pr-journal\/bufdabw.jpg"}],"user":{"profile_image":"\/img\/avatars\/011.png","username":"elaina-graham","full_name":"Elaina Graham","created_by":"Elaina Graham"},"access":{"can_view":"1","can_remove":"0","can_add":"0","can_edit":0,"can_publish":0,"can_get_doi":0,"can_share":"0","can_move":"1","can_transfer":"1","can_download":"1","is_locked":"0"},"is_contact_suspended":0,"guidelines":null,"status_id":"2","is_research":"1","status_info":"We are still developing and optimizing this protocol","steps":[{"id":"603607","is_changed":"0","original_id":"0","is_skipped":"0","is_checked":"0","guid":"C8012F98E8644A878709B654EE7311E9","previous_guid":null,"previous_id":"0","last_modified":"1522264833","components":[{"component_id":"1044412","previous_id":0,"original_id":"0","guid":"90B1D00B5EC846779B618E4E5B21E23E","previous_guid":null,"component_type_id":"6","data_id":"0","data":"Gathering the right files","order_id":"0","name":"Section","data_by_id":"0","type_id":"6","source_data":{"section":"Gathering the right files"},"is_project":0},{"component_id":"1044411","previous_id":"1044412","original_id":"0","guid":"59C343AF7EA34A6680BF76D5F9D29FAD","previous_guid":"90B1D00B5EC846779B618E4E5B21E23E","component_type_id":"1","data_id":null,"data":"<p>\u00a0<\/p>\n<p>\u00a0<\/p>\n<p>Now to get all of the scripts and files do the command below to download the git repository.<\/p>\n<p>\u00a0<\/p>\n<p>The cd into `PhylogenomicsWorkflow\/Example`<\/p>\n<p>\u00a0<\/p>","order_id":"1","name":"Description","data_by_id":"0","type_id":"1","source_data":{"description":"<p>\u00a0<\/p>\n<p>\u00a0<\/p>\n<p>Now to get all of the scripts and files do the command below to download the git repository.<\/p>\n<p>\u00a0<\/p>\n<p>The cd into `PhylogenomicsWorkflow\/Example`<\/p>\n<p>\u00a0<\/p>"},"is_project":0},{"component_id":"1044618","previous_id":"1044411","original_id":"0","guid":"5BB2796A0DFD4719B934F24AF3E6EEB8","previous_guid":"59C343AF7EA34A6680BF76D5F9D29FAD","component_type_id":"15","data_id":"3058","data":"","order_id":"2","name":"Command","data_by_id":"1","type_id":"15","source_data":{"name":"$ git clone https:\/\/github.com\/edgraham\/PhylogenomicsWorkflow.git\n$ cd PhylogenomicsWorkflow\/Example","description":"This will clone the github repositiory to your local machine","os_name":"","os_version":"","can_edit":"1"},"is_project":0},{"component_id":"1044627","previous_id":"1044618","original_id":"0","guid":"C0CBB7CF79584059A3ADA0EF41E371AB","previous_guid":"5BB2796A0DFD4719B934F24AF3E6EEB8","component_type_id":"15","data_id":"3059","data":"","order_id":"3","name":"Command","data_by_id":"1","type_id":"15","source_data":{"name":"$ ls Genomes\n\nunknown1.fna  unknown2.fna  unknown3.fna  unknown4.fna  unknown5.fna\n\n$ ls HugRef\n\nExampleRefSet.RpL14.faa  ExampleRefSet.RpL22.faa  ExampleRefSet.RpL4.faa   ExampleRefSet.RpS17.faa\nExampleRefSet.RpL15.faa  ExampleRefSet.RpL24.faa  ExampleRefSet.RpL5.faa   ExampleRefSet.RpS19.faa\nExampleRefSet.RpL16.faa  ExampleRefSet.RpL2.faa   ExampleRefSet.RpL6.faa   ExampleRefSet.RpS3.faa\nExampleRefSet.RpL18.faa  ExampleRefSet.RpL3.faa   ExampleRefSet.RpS10.faa  ExampleRefSet.RpS8.faa\n\n..","description":"You should now be in the PhylogenomicsWorkflow\/Example directory which contains Genomes of interest and a small set of reference ribosomal proteins pulled from genomes on NCBI","os_name":"","os_version":"","can_edit":"1"},"is_project":0}]},{"id":"603610","is_changed":"0","original_id":"0","is_skipped":"0","is_checked":"0","guid":"1FEC151E127D42E6920FA7E3715F63B2","previous_guid":"C8012F98E8644A878709B654EE7311E9","previous_id":"603607","last_modified":"1523408943","components":[{"component_id":"1044417","previous_id":0,"original_id":"0","guid":"5C5153C836004982A272ACF1CC70C5FA","previous_guid":null,"component_type_id":"1","data_id":null,"data":"<p>\u00a0<\/p>\n<p>The primary script in this workflow in `identifyHMM`. The script relies on the user providing the location of a file containing Hidden Markov Models (HMMs) for their genes of interest. Here we have provided you with a file called `hug_ribosomalmarkers.hmm`. This contains HMM models for 16 Ribosomal proteins: RpL14, RpL15, RpL16 ,RpL18, RpL22, RpL24 ,RpL2, RpL3, RpL4, RpL5, RpL6, RpS10, RpS17, RpS19, RpS3, RpS8.\u00a0<\/p>\n<p>\u00a0<\/p>\n<p>\u00a0<\/p>\n<p>Now you should enter the directory containing your genomes (in our case \/PhylogenomicsWorkflow\/Example\/Genomes)<\/p>\n<p>\u00a0<\/p>\n<p>The help message for `identifyHMM` is given below.\u00a0<\/p>\n<p>\u00a0<\/p>\n<p>\u00a0<\/p>\n<pre class=\"language-markup\"><code>\nusage: identifyHMM [-h] [--markerdb MARKERDB] [--performProdigal] [--cut_tc]\n                   [--outPrefix OUTPREFIX] [--Num NUM] [-E E]\n                   Input\n\nIdentify marker genes in in protein sequences of genomes.\n\npositional arguments:\n  Input                 Target file(s). Provide unifying text of desired\n                        genome(s). Ext must be 'fna' or 'faa'.\n\noptional arguments:\n  -h, --help            show this help message and exit\n  --markerdb MARKERDB   Provide HMM file of markers. Markers should have a\n                        descriptive ID name.\n  --performProdigal     Run Prodigal on input genome nucleotide FASTA file\n  --cut_tc              use hmm profiles TC trusted cutoffs to set all\n                        thresholding\n  --outPrefix OUTPREFIX\n                        Provide prefix of names for marker output files.\n  -E E                  Set E-Value to be used in hmmsearch. Default: 1E-5<\/code><\/pre>\n<p>\u00a0<\/p>\n<p>**Note** When using `identifyHMM` on your own data you need to remember that you should be in the directory containing your MAGs when you run the program and ensure that the only genomes in this directory are the genomes of interest. The program will parse through every file with the suffix given as the [input]. So in this case our input is `.fna`. Second, if you want to run identifyHMM with your own gene calls you will want to exclude the `--performProdigal` flag and be sure that your gene calls end with the suffix `.faa` and are in the same directory as the genomes of interest.<\/p>\n<p>\u00a0<\/p>\n<p>The HMM file that we will be using is found in `\/PhylogenomicsWorkflow\/hug_ribosomalmarkers.hmm` on the github. The HMM Models in this file were pulled from PFAM and represent 16 ribosomal proteins that tend to be syntenic\/co-located (<a href=\"10.1038\/nmicrobiol.2016.48\" target=\"_blank\" rel=\"noopener noreferrer\">Hug et al. 2016<\/a>)<\/p>\n<p>\u00a0<\/p>\n<p>Once in the `Genomes` directory run `identifyHMM` as Follows:<\/p>\n<p>\u00a0<\/p>\n<pre class=\"language-markup\"><code> identifyHMM --markerdb ..\/..\/hug_ribosomalmarkers.hmm --performProdigal --cut_tc --outPrefix HUG .fna\n<\/code><\/pre>\n<p>\u00a0<\/p>\n<p>The output of this will be 16 `.faa` files appended with the prefix spefied by `--outPrefix` (in this case we used `HUG`), five `.faa` files corresponding to the prodigal gene calls, and\u00a0five\u00a0hmm reports (Stored in the `.tbl` files). So the files that look like `HUG_RpL14.faa` are ribosomal proteins pulled from your genomes of interest.<\/p>\n<p>\u00a0<\/p>\n<pre class=\"language-markup\"><code>hmmsearhc-log.txt  HUG_RpL16.faa  HUG_RpL24.faa  HUG_RpL4.faa  \nHUG_RpS10.faa      HUG_RpS3.faa   unknown1.fna   unknown2.fna             \nunknown3.fna       unknown4.fna   unknown5.fna   HUG_RpL14.faa      \nHUG_RpL18.faa      HUG_RpL2.faa   HUG_RpL5.faa   HUG_RpS17.faa  \nHUG_RpS8.faa       HUG_RpL15.faa  HUG_RpL22.faa  HUG_RpL3.faa   \nHUG_RpL6.faa       HUG_RpS19.faa  unknown1.faa   unknown2.faa              \nunknown3.faa       unknown4.faa   unknown5.faaunknown1.ribomarkers.tbl \nunknown2.ribomarkers.tbl  unknown3.ribomarkers.tbl  unknown4.ribomarkers.tbl  \nunknown5.ribomarkers.tbl<\/code><\/pre>","order_id":"0","name":"Description","data_by_id":"0","type_id":"1","source_data":{"description":"<p>\u00a0<\/p>\n<p>The primary script in this workflow in `identifyHMM`. The script relies on the user providing the location of a file containing Hidden Markov Models (HMMs) for their genes of interest. Here we have provided you with a file called `hug_ribosomalmarkers.hmm`. This contains HMM models for 16 Ribosomal proteins: RpL14, RpL15, RpL16 ,RpL18, RpL22, RpL24 ,RpL2, RpL3, RpL4, RpL5, RpL6, RpS10, RpS17, RpS19, RpS3, RpS8.\u00a0<\/p>\n<p>\u00a0<\/p>\n<p>\u00a0<\/p>\n<p>Now you should enter the directory containing your genomes (in our case \/PhylogenomicsWorkflow\/Example\/Genomes)<\/p>\n<p>\u00a0<\/p>\n<p>The help message for `identifyHMM` is given below.\u00a0<\/p>\n<p>\u00a0<\/p>\n<p>\u00a0<\/p>\n<pre class=\"language-markup\"><code>\nusage: identifyHMM [-h] [--markerdb MARKERDB] [--performProdigal] [--cut_tc]\n                   [--outPrefix OUTPREFIX] [--Num NUM] [-E E]\n                   Input\n\nIdentify marker genes in in protein sequences of genomes.\n\npositional arguments:\n  Input                 Target file(s). Provide unifying text of desired\n                        genome(s). Ext must be 'fna' or 'faa'.\n\noptional arguments:\n  -h, --help            show this help message and exit\n  --markerdb MARKERDB   Provide HMM file of markers. Markers should have a\n                        descriptive ID name.\n  --performProdigal     Run Prodigal on input genome nucleotide FASTA file\n  --cut_tc              use hmm profiles TC trusted cutoffs to set all\n                        thresholding\n  --outPrefix OUTPREFIX\n                        Provide prefix of names for marker output files.\n  -E E                  Set E-Value to be used in hmmsearch. Default: 1E-5<\/code><\/pre>\n<p>\u00a0<\/p>\n<p>**Note** When using `identifyHMM` on your own data you need to remember that you should be in the directory containing your MAGs when you run the program and ensure that the only genomes in this directory are the genomes of interest. The program will parse through every file with the suffix given as the [input]. So in this case our input is `.fna`. Second, if you want to run identifyHMM with your own gene calls you will want to exclude the `--performProdigal` flag and be sure that your gene calls end with the suffix `.faa` and are in the same directory as the genomes of interest.<\/p>\n<p>\u00a0<\/p>\n<p>The HMM file that we will be using is found in `\/PhylogenomicsWorkflow\/hug_ribosomalmarkers.hmm` on the github. The HMM Models in this file were pulled from PFAM and represent 16 ribosomal proteins that tend to be syntenic\/co-located (<a href=\"10.1038\/nmicrobiol.2016.48\" target=\"_blank\" rel=\"noopener noreferrer\">Hug et al. 2016<\/a>)<\/p>\n<p>\u00a0<\/p>\n<p>Once in the `Genomes` directory run `identifyHMM` as Follows:<\/p>\n<p>\u00a0<\/p>\n<pre class=\"language-markup\"><code> identifyHMM --markerdb ..\/..\/hug_ribosomalmarkers.hmm --performProdigal --cut_tc --outPrefix HUG .fna\n<\/code><\/pre>\n<p>\u00a0<\/p>\n<p>The output of this will be 16 `.faa` files appended with the prefix spefied by `--outPrefix` (in this case we used `HUG`), five `.faa` files corresponding to the prodigal gene calls, and\u00a0five\u00a0hmm reports (Stored in the `.tbl` files). So the files that look like `HUG_RpL14.faa` are ribosomal proteins pulled from your genomes of interest.<\/p>\n<p>\u00a0<\/p>\n<pre class=\"language-markup\"><code>hmmsearhc-log.txt  HUG_RpL16.faa  HUG_RpL24.faa  HUG_RpL4.faa  \nHUG_RpS10.faa      HUG_RpS3.faa   unknown1.fna   unknown2.fna             \nunknown3.fna       unknown4.fna   unknown5.fna   HUG_RpL14.faa      \nHUG_RpL18.faa      HUG_RpL2.faa   HUG_RpL5.faa   HUG_RpS17.faa  \nHUG_RpS8.faa       HUG_RpL15.faa  HUG_RpL22.faa  HUG_RpL3.faa   \nHUG_RpL6.faa       HUG_RpS19.faa  unknown1.faa   unknown2.faa              \nunknown3.faa       unknown4.faa   unknown5.faaunknown1.ribomarkers.tbl \nunknown2.ribomarkers.tbl  unknown3.ribomarkers.tbl  unknown4.ribomarkers.tbl  \nunknown5.ribomarkers.tbl<\/code><\/pre>"},"is_project":0},{"component_id":"1044418","previous_id":"1044417","original_id":"0","guid":"801236FAEE634157A9AE3E35C53EB8BF","previous_guid":"5C5153C836004982A272ACF1CC70C5FA","component_type_id":"6","data_id":"0","data":"Generate Gene Calls and Extract Ribosomal Proteins from Genomes Of Interest","order_id":"1","name":"Section","data_by_id":"0","type_id":"6","source_data":{"section":"Generate Gene Calls and Extract Ribosomal Proteins from Genomes Of Interest"},"is_project":0},{"component_id":"1044651","previous_id":"1044418","original_id":"0","guid":"2076CAC470BD4A4FAEC1D93C2EFC82C5","previous_guid":"801236FAEE634157A9AE3E35C53EB8BF","component_type_id":"15","data_id":"3063","data":"","order_id":"2","name":"Command","data_by_id":"1","type_id":"15","source_data":{"name":" identifyHMM --markerdb ..\/..\/hug_ribosomalmarkers.hmm --performProdigal --cut_tc --outPrefix HUG --Num 16 .fna","description":"The output of this will be 16 `.faa` files appended with the prefix spefied by `--outPrefix`, 5 `.faa` files corresponding to the prodigal gene calls, and 5 hmm reports (Stored in the `.tbl` files). So the files that look like `HUG_RpL14.faa` are ribosomal proteins pulled from your genomes of interest.","os_name":"","os_version":"","can_edit":"1"},"is_project":0}]},{"id":"603612","is_changed":"0","original_id":"0","is_skipped":"0","is_checked":"0","guid":"3415EF5D84F3476CBB6DD6219568FC78","previous_guid":"1FEC151E127D42E6920FA7E3715F63B2","previous_id":"603610","last_modified":"1522359336","components":[{"component_id":"1044421","previous_id":0,"original_id":"0","guid":"720B619CA65F4323A60B352379A5192B","previous_guid":null,"component_type_id":"1","data_id":null,"data":"<p>Now that we have extracted marker genes from our genomes of interest we can merge together the Ribosomal Protein calls we just made on our genomes of interest with those in the folder <code>'\/PhylogenomicsWorkflow\/Example\/HugRef'<\/code> accordingly.<\/p>\n<p>\u00a0<\/p>\n<p>To do this we will use a quick bash trick that uses the text file `hug_marker_list.txt` which contains a list of the marker proteins we are searching for. Use the following Bash command:<\/p>\n<p>\u00a0<\/p>\n<p>\u00a0<\/p>\n<p>\u00a0<\/p>","order_id":"0","name":"Description","data_by_id":"0","type_id":"1","source_data":{"description":"<p>Now that we have extracted marker genes from our genomes of interest we can merge together the Ribosomal Protein calls we just made on our genomes of interest with those in the folder <code>'\/PhylogenomicsWorkflow\/Example\/HugRef'<\/code> accordingly.<\/p>\n<p>\u00a0<\/p>\n<p>To do this we will use a quick bash trick that uses the text file `hug_marker_list.txt` which contains a list of the marker proteins we are searching for. Use the following Bash command:<\/p>\n<p>\u00a0<\/p>\n<p>\u00a0<\/p>\n<p>\u00a0<\/p>"},"is_project":0},{"component_id":"1044422","previous_id":"1044421","original_id":"0","guid":"F9F0BFA68B024DF5A55D3D93FE385DCA","previous_guid":"720B619CA65F4323A60B352379A5192B","component_type_id":"6","data_id":"0","data":"Merge Reference Proteins with Yours","order_id":"1","name":"Section","data_by_id":"0","type_id":"6","source_data":{"section":"Merge Reference Proteins with Yours"},"is_project":0},{"component_id":"1044653","previous_id":"1044422","original_id":"0","guid":"411E0BB75D62400790617864AD9A4782","previous_guid":"F9F0BFA68B024DF5A55D3D93FE385DCA","component_type_id":"15","data_id":"3065","data":"","order_id":"2","name":"Command","data_by_id":"1","type_id":"15","source_data":{"name":"while read p\n                 do cat ..\/HugRef\/ExampleRefSet.\"$p\".faa HUG_\"$p\".faa > Dataset1_\"$p\".faa\ndone < ..\/..\/hug_marker_list.txt","description":"This bash script is iterating through the list given in `hug_marker_list.txt` and concatenate appropriate reference and experimental protein sets. So for example it would concatenate `ExampleRefSet.RpL6.faa` and `Hug_RpL6.faa` into `Dataset1_RpL6.faa`. \n","os_name":"","os_version":"","can_edit":"1"},"is_project":0}]},{"id":"603613","is_changed":"0","original_id":"0","is_skipped":"0","is_checked":"0","guid":"317598C748894564B3863801115CB52E","previous_guid":"3415EF5D84F3476CBB6DD6219568FC78","previous_id":"603612","last_modified":"1523407412","components":[{"component_id":"1044423","previous_id":0,"original_id":"0","guid":"0AADA252A14746C69B210D9C888D1481","previous_guid":null,"component_type_id":"1","data_id":null,"data":"<p><br \/>Now that we have 16 files containing Ribosomal proteins from our 5 unknown genomes and 100 references we can move on to aligning our proteins.<\/p>\n<p>To align our proteins we can use muscle (You could also alternatively use <a href=\"https:\/\/mafft.cbrc.jp\/alignment\/software\/algorithms\/algorithms.html\" target=\"_blank\" rel=\"noopener noreferrer\">MAFFT<\/a>).\u00a0<\/p>\n<p>\u00a0<\/p>\n<pre class=\"language-markup\"><code>Dataset1_RpL14.faa  Dataset1_RpL24.faa\tDataset1_RpL6.faa\tDataset1_RpS8.faa\nDataset1_RpL15.faa  Dataset1_RpL2.faa\tDataset1_RpS10.faa\thmmsearhc-log.txt\nDataset1_RpL16.faa  Dataset1_RpL3.faa\tDataset1_RpS17.faa\tHUG_RpL14.faa\nDataset1_RpL18.faa  Dataset1_RpL4.faa\tDataset1_RpS19.faa\tHUG_RpL15.faa\nDataset1_RpL22.faa  Dataset1_RpL5.faa\tDataset1_RpS3.faa\tHUG_RpL16.faa\nHUG_RpL18.faa\t    HUG_RpL4.faa\tHUG_RpS19.faa\t        unknown1.ribomarkers.tbl\nHUG_RpL22.faa\t    HUG_RpL5.faa\tHUG_RpS3.faa\t        unknown2.faa\nHUG_RpL24.faa\t    HUG_RpL6.faa\tHUG_RpS8.faa\t        unknown2.fna\nHUG_RpL2.faa\t    HUG_RpS10.faa\tunknown1.faa\t        unknown2.ribomarkers.tbl\nHUG_RpL3.faa\t    HUG_RpS17.faa\tunknown1.fna\t        unknown3.faa\nunknown5.faa\t    unknown5.fna\tunknown5.ribomarkers.tbl\t\n<\/code><\/pre>\n<p>\u00a0<\/p>\n<p>We will use the same trick as above where we feed the list of ribosomal markers in `hug_marker_list.txt` into a bash loop thar runs muscle on head of the protein fasta files we generated. This will end in 16 alignment (`.aln`) files.<\/p>","order_id":"0","name":"Description","data_by_id":"0","type_id":"1","source_data":{"description":"<p><br \/>Now that we have 16 files containing Ribosomal proteins from our 5 unknown genomes and 100 references we can move on to aligning our proteins.<\/p>\n<p>To align our proteins we can use muscle (You could also alternatively use <a href=\"https:\/\/mafft.cbrc.jp\/alignment\/software\/algorithms\/algorithms.html\" target=\"_blank\" rel=\"noopener noreferrer\">MAFFT<\/a>).\u00a0<\/p>\n<p>\u00a0<\/p>\n<pre class=\"language-markup\"><code>Dataset1_RpL14.faa  Dataset1_RpL24.faa\tDataset1_RpL6.faa\tDataset1_RpS8.faa\nDataset1_RpL15.faa  Dataset1_RpL2.faa\tDataset1_RpS10.faa\thmmsearhc-log.txt\nDataset1_RpL16.faa  Dataset1_RpL3.faa\tDataset1_RpS17.faa\tHUG_RpL14.faa\nDataset1_RpL18.faa  Dataset1_RpL4.faa\tDataset1_RpS19.faa\tHUG_RpL15.faa\nDataset1_RpL22.faa  Dataset1_RpL5.faa\tDataset1_RpS3.faa\tHUG_RpL16.faa\nHUG_RpL18.faa\t    HUG_RpL4.faa\tHUG_RpS19.faa\t        unknown1.ribomarkers.tbl\nHUG_RpL22.faa\t    HUG_RpL5.faa\tHUG_RpS3.faa\t        unknown2.faa\nHUG_RpL24.faa\t    HUG_RpL6.faa\tHUG_RpS8.faa\t        unknown2.fna\nHUG_RpL2.faa\t    HUG_RpS10.faa\tunknown1.faa\t        unknown2.ribomarkers.tbl\nHUG_RpL3.faa\t    HUG_RpS17.faa\tunknown1.fna\t        unknown3.faa\nunknown5.faa\t    unknown5.fna\tunknown5.ribomarkers.tbl\t\n<\/code><\/pre>\n<p>\u00a0<\/p>\n<p>We will use the same trick as above where we feed the list of ribosomal markers in `hug_marker_list.txt` into a bash loop thar runs muscle on head of the protein fasta files we generated. This will end in 16 alignment (`.aln`) files.<\/p>"},"is_project":0},{"component_id":"1044424","previous_id":"1044423","original_id":"0","guid":"4A02C419716B4CF19DAA2F4D5A810587","previous_guid":"0AADA252A14746C69B210D9C888D1481","component_type_id":"6","data_id":"0","data":"Align","order_id":"1","name":"Section","data_by_id":"0","type_id":"6","source_data":{"section":"Align"},"is_project":0},{"component_id":"1044654","previous_id":"1044424","original_id":"0","guid":"10B7EDCE7FC34D088F37B0ABEBC5A466","previous_guid":"4A02C419716B4CF19DAA2F4D5A810587","component_type_id":"15","data_id":"3066","data":"","order_id":"2","name":"Command","data_by_id":"1","type_id":"15","source_data":{"name":"\nwhile read p\n                  do muscle -maxiters 16 -in Dataset1_\"$p\".faa -out Dataset1_\"$p\".aln\ndone < ..\/..\/hug_marker_list.txt","description":"","os_name":"","os_version":"","can_edit":"1"},"is_project":0}]},{"id":"603614","is_changed":"0","original_id":"0","is_skipped":"0","is_checked":"0","guid":"2DDE067F9BE84655A9338440379C8D96","previous_guid":"317598C748894564B3863801115CB52E","previous_id":"603613","last_modified":"1522359165","components":[{"component_id":"1044425","previous_id":0,"original_id":"0","guid":"B3FDF4949C954C7D9B8BC874BC7DB000","previous_guid":null,"component_type_id":"1","data_id":null,"data":"<p>Now that we have our alignments we need to trim those alignments. There are many programs that do this and I implore you to try a couple and see how different ones work, or even try manual trimming. Here we will use Trimal because its automated and works quickly when running alignments with lots of sequences.<\/p>\n<p>\u00a0<\/p>\n<p>You can run the following to trim your alignments:<\/p>\n<p>\u00a0<\/p>","order_id":"0","name":"Description","data_by_id":"0","type_id":"1","source_data":{"description":"<p>Now that we have our alignments we need to trim those alignments. There are many programs that do this and I implore you to try a couple and see how different ones work, or even try manual trimming. Here we will use Trimal because its automated and works quickly when running alignments with lots of sequences.<\/p>\n<p>\u00a0<\/p>\n<p>You can run the following to trim your alignments:<\/p>\n<p>\u00a0<\/p>"},"is_project":0},{"component_id":"1044426","previous_id":"1044425","original_id":"0","guid":"3FF156102DF545E6AEC18FD852FE566D","previous_guid":"B3FDF4949C954C7D9B8BC874BC7DB000","component_type_id":"6","data_id":"0","data":"Trim","order_id":"1","name":"Section","data_by_id":"0","type_id":"6","source_data":{"section":"Trim"},"is_project":0},{"component_id":"1044655","previous_id":"1044426","original_id":"0","guid":"6B28157F74564148A13FC546575A1021","previous_guid":"3FF156102DF545E6AEC18FD852FE566D","component_type_id":"15","data_id":"3067","data":"","order_id":"2","name":"Command","data_by_id":"1","type_id":"15","source_data":{"name":"while read p\n                 do trimal -automated1 -in Dataset1_\"$p\".aln -out Dataset1_\"$p\".trimmed.aln\ndone < ..\/..\/hug_marker_list.txt","description":"","os_name":"","os_version":"","can_edit":"1"},"is_project":0}]},{"id":"603615","is_changed":"0","original_id":"0","is_skipped":"0","is_checked":"0","guid":"E42CC393060B41748224B706908357E3","previous_guid":"2DDE067F9BE84655A9338440379C8D96","previous_id":"603614","last_modified":"1522358800","components":[{"component_id":"1044427","previous_id":0,"original_id":"0","guid":"5C0A804FA6F846C69E7495EF54846FA2","previous_guid":null,"component_type_id":"1","data_id":null,"data":"<p>Now that you have the trimmed and aligned sequences you can concatenate these 16 files. To do this we will use the concat script packaged with <a href=\"https:\/\/github.com\/edgraham\/BinSanity\" target=\"_blank\" rel=\"noopener noreferrer\">BinSanity<\/a>.\u00a0<\/p>\n<p>\u00a0<\/p>\n<p>\u00a0Usage is shown below:<\/p>\n<p>\u00a0<\/p>\n<pre class=\"language-markup\"><code>usage: concat -f directory -e Alignment Extension --Prefix file linker -o output\n\n    *****************************************************************************\n    *********************************BinSanity***********************************\n    **     The `concat` script is used to concatenate multiple sequence        **\n    **     alignments for conducting a phylogenomic analysis. Note that you    **\n    **     receive an error if there are any duplicate sequence ids in an      **\n    **     alignment.\n    *****************************************************************************\n\noptional arguments:\n  -h, --help  show this help message and exit\n  -f          Specify directory where alignments are\n  -e          Specify the extension for your alignments (must be in Fasta format)\n  --Prefix    Specify the prefix that links your alignments (ex: if you have two alignments TOBG_RpL10, TOBG_RpL24, the --Prefix would be TOBG\n  -o          Specify output file\n  -N          Specify the minimum number of sequences needed to be included in concatenation<\/code><\/pre>","order_id":"0","name":"Description","data_by_id":"0","type_id":"1","source_data":{"description":"<p>Now that you have the trimmed and aligned sequences you can concatenate these 16 files. To do this we will use the concat script packaged with <a href=\"https:\/\/github.com\/edgraham\/BinSanity\" target=\"_blank\" rel=\"noopener noreferrer\">BinSanity<\/a>.\u00a0<\/p>\n<p>\u00a0<\/p>\n<p>\u00a0Usage is shown below:<\/p>\n<p>\u00a0<\/p>\n<pre class=\"language-markup\"><code>usage: concat -f directory -e Alignment Extension --Prefix file linker -o output\n\n    *****************************************************************************\n    *********************************BinSanity***********************************\n    **     The `concat` script is used to concatenate multiple sequence        **\n    **     alignments for conducting a phylogenomic analysis. Note that you    **\n    **     receive an error if there are any duplicate sequence ids in an      **\n    **     alignment.\n    *****************************************************************************\n\noptional arguments:\n  -h, --help  show this help message and exit\n  -f          Specify directory where alignments are\n  -e          Specify the extension for your alignments (must be in Fasta format)\n  --Prefix    Specify the prefix that links your alignments (ex: if you have two alignments TOBG_RpL10, TOBG_RpL24, the --Prefix would be TOBG\n  -o          Specify output file\n  -N          Specify the minimum number of sequences needed to be included in concatenation<\/code><\/pre>"},"is_project":0},{"component_id":"1044428","previous_id":"1044427","original_id":"0","guid":"A0DC6A466A004B8A83BC8B17D6F1F9D0","previous_guid":"5C0A804FA6F846C69E7495EF54846FA2","component_type_id":"6","data_id":"0","data":"Concatenate Proteins","order_id":"1","name":"Section","data_by_id":"0","type_id":"6","source_data":{"section":"Concatenate Proteins"},"is_project":0},{"component_id":"1044656","previous_id":"1044428","original_id":"0","guid":"CFCD19D0B8594B0C83D2BDF40632A66E","previous_guid":"A0DC6A466A004B8A83BC8B17D6F1F9D0","component_type_id":"15","data_id":"3068","data":"","order_id":"2","name":"Command","data_by_id":"1","type_id":"15","source_data":{"name":"concat -f . -e .trimmed.aln --Prefix Dataset1 -o Dataset1.HugRibosomal.trimmed.concat.aln -N 8","description":"","os_name":"","os_version":"","can_edit":"1"},"is_project":0}]},{"id":"603617","is_changed":"0","original_id":"0","is_skipped":"0","is_checked":"0","guid":"8A6AFFCB339D44B0854901D41D32E378","previous_guid":"E42CC393060B41748224B706908357E3","previous_id":"603615","last_modified":"1522359130","components":[{"component_id":"1044431","previous_id":0,"original_id":"0","guid":"44B8D2C667F24A5ABCA73FF3B594F9D5","previous_guid":null,"component_type_id":"1","data_id":null,"data":"<p>You now have a concatenated alignment 'Dataset1.HugRibosomal.trimmed.concat.aln' which can be used to build a phylogenetic tree.<\/p>\n<p><br \/>We will be using FastTree with the `-gamma` and `-lg` parameters. These parameters are optional and just indicate what models we would like to use for branch length calculation and amino acid evolution respectively. Feel free to adjust these for your own purposes.<\/p>\n<p>\u00a0<\/p>\n<p>\u00a0<\/p>","order_id":"0","name":"Description","data_by_id":"0","type_id":"1","source_data":{"description":"<p>You now have a concatenated alignment 'Dataset1.HugRibosomal.trimmed.concat.aln' which can be used to build a phylogenetic tree.<\/p>\n<p><br \/>We will be using FastTree with the `-gamma` and `-lg` parameters. These parameters are optional and just indicate what models we would like to use for branch length calculation and amino acid evolution respectively. Feel free to adjust these for your own purposes.<\/p>\n<p>\u00a0<\/p>\n<p>\u00a0<\/p>"},"is_project":0},{"component_id":"1044432","previous_id":"1044431","original_id":"0","guid":"3A99577B8C9340699B37DCF4DFE84B76","previous_guid":"44B8D2C667F24A5ABCA73FF3B594F9D5","component_type_id":"6","data_id":"0","data":"Build the Tree","order_id":"1","name":"Section","data_by_id":"0","type_id":"6","source_data":{"section":"Build the Tree"},"is_project":0},{"component_id":"1044663","previous_id":"1044432","original_id":"0","guid":"2C04D20DCFF24C1A9585CF0E22AC5890","previous_guid":"3A99577B8C9340699B37DCF4DFE84B76","component_type_id":"15","data_id":"3069","data":"","order_id":"2","name":"Command","data_by_id":"1","type_id":"15","source_data":{"name":"FastTree -gamma -lg Dataset1.HugRibosomal.trimmed.concat.aln > Dataset1.HugRibosomal.trimmed.concat.newick\n","description":"","os_name":"","os_version":"","can_edit":"1"},"is_project":0}]},{"id":"603618","is_changed":"0","original_id":"0","is_skipped":"0","is_checked":"0","guid":"7C89D390B77E4CABB53EFBEA3B8BDD01","previous_guid":"8A6AFFCB339D44B0854901D41D32E378","previous_id":"603617","last_modified":"1521846421","components":[{"component_id":"1044433","previous_id":0,"original_id":"0","guid":"19018E8B29BA4D5CB8E128EF3E08AE60","previous_guid":null,"component_type_id":"1","data_id":null,"data":"<p>\u00a0<\/p>\n<p>Now you have a newick file which can be viewed in a variety of tree views and edited. One of my favorite tools for making publication quality trees is\u00a0<a href=\"https:\/\/itol.embl.de\/\" target=\"_blank\" rel=\"noopener noreferrer\">ITOL<\/a>!<\/p>","order_id":"0","name":"Description","data_by_id":"0","type_id":"1","source_data":{"description":"<p>\u00a0<\/p>\n<p>Now you have a newick file which can be viewed in a variety of tree views and edited. One of my favorite tools for making publication quality trees is\u00a0<a href=\"https:\/\/itol.embl.de\/\" target=\"_blank\" rel=\"noopener noreferrer\">ITOL<\/a>!<\/p>"},"is_project":0},{"component_id":"1044434","previous_id":"1044433","original_id":"0","guid":"98EF11E72ED44BF981CD66533D9CEBD1","previous_guid":"19018E8B29BA4D5CB8E128EF3E08AE60","component_type_id":"6","data_id":"0","data":"View Tree!","order_id":"1","name":"Section","data_by_id":"0","type_id":"6","source_data":{"section":"View Tree!"},"is_project":0}]}]}