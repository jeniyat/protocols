{"uri":"ant-genera-identification-using-an-ensemble-of-con-kzpcx5n","version_id":"0","protocol_name":"Ant Genera Identification Using an Ensemble of Convolutional Neural Networks","protocol_name_html":"Ant Genera Identification Using an Ensemble of Convolutional Neural Networks","is_prepublished":"0","can_edit":"0","parent_id":null,"api_version":"1","is_new_mode":"0","last_modified":"1522231932","type_id":"1","link":"https:\/\/doi.org\/10.1371\/journal.pone.0192011","fork_id":"7278","public_fork_note":null,"number_of_steps":"8","has_versions":"0","first_published_date":"1515029519","publish_date":"2018-02-01 18:07:18","documents":"","have_protocol_in_step":"0","is_protocol_in_step":"0","vendor_name":"Contributed by users","vendor_link":"https:\/\/www.protocols.io","vendor_logo":"\/img\/vendors\/1.png","mod_mins":"-45","mod_secs":"1","description":"<p>Works requiring taxonomic knowledge face several challenges, such as arduous identification of many taxa and an insufficient number of taxonomists to identify a great deal of collected organisms. Machine learning tools, particularly convolutional neural networks (CNNs), are then welcome to automatically generate high-performance classifiers from available data.<\/p>\n<p>We propose an ensemble of CNNs to identify ant genera directly from the head, profile and dorsal perspectives of ant images.<\/p>\n<p>Transfer learning is also considered to improve the individual performance of the CNN classifiers.<\/p>","is_bookmarked":"0","can_reassign":"1","before_start":null,"has_guidelines":"0","materials":[],"warning":null,"version_class":"8975","public":"1","is_owner":"1","is_original_owner":"1","created_on":"1511744300","protocol_affiliation":"School of Electrical and Computer Engineering, University of Campinas (UNICAMP),Graduate Program in Ecology, Institute of Biology, University of Campinas (UNICAMP)","affiliation":null,"doi":"dx.doi.org\/10.17504\/protocols.io.kzpcx5n","doi_status":"2","changed_fork_steps":null,"profile_url":"y2w25403x2","protocol_img":"https:\/\/www.protocols.io\/img\/default_protocol.png","profile_image":"\/img\/avatars\/018.png","full_name":"Marcos M. Raimundo","created_by":"Marcos M. Raimundo","private_link":"4998413859A77283BAA081EE96DE02EC","original_img":"1","username":"marcos-m-raimundo","is_retracted":"0","retraction_reason":null,"plos_id":"10.1371\/journal.pone.0192011","manuscript_citation":"Marques ACR,  Raimundo MM,  Cavalheiro EMB,  Salles LFP,  Lyra C,  Zuben FJV (2018) Ant genera identification using an ensemble of convolutional neural networks. PLoS ONE  13(1): e0192011. doi: <a target=\"_blank\" href=\"https:\/\/dx.doi.org\/10.1371\/journal.pone.0192011\">10.1371\/journal.pone.0192011<\/a> ","journal_name":"PLOS One","is_donations_disabled":"0","is_donations_disabled_by_user":"9","item_record_id":275964,"fork_info":[{"protocol_id":"7278","protocol_name":"Deep Learning for Plant Phenotyping","protocol_name_html":"Deep Learning for Plant Phenotyping","uri":"deep-learning-for-plant-phenotyping-jcncive","first_name":"Michael","last_name":"Pound","affiliation":null,"affiliation_url":null,"username":"michael-pound","is_public":"1"}],"compare_forks":[],"protocols":[],"groups":[],"number_of_shared_runs":[],"ownership_history":[],"keywords":"machine learning, convolutional neural networks, ensemble, multiview","transfer_to_user":[],"sub_transfer":false,"is_transfer_pending":false,"number_of_bookmarks":"2","collections":[],"tags":[{"tag_id":"182","tag_name":"taxonomy"},{"tag_id":"818","tag_name":"machine learning"},{"tag_id":"819","tag_name":" deep learning"},{"tag_id":"822","tag_name":" caffe"},{"tag_id":"823","tag_name":" python"},{"tag_id":"1398","tag_name":"convolutional neural networks"},{"tag_id":"1399","tag_name":"ant"}],"archived":0,"sub_authors":[],"sub_protocols_number":0,"can_edit_shared":0,"shared_runs":[],"is_shared_run":0,"is_shared":1,"is_original_available":1,"banner":null,"contact_badges":[{"badge_id":"2","badge_image":"\/img\/badges\/bronze.svg","badge_description":"Author!"}],"number_of_comments":0,"is_locked":0,"is_locked_by":false,"authors":"Alan Caio R. Marques,Marcos M. Raimundo,Ellen M. B. Cavalheiro,Luis F. P. Salles,Christiano Lyra,Fernando J. Von Zuben.","authors_list":[{"name":"Alan Caio R. Marques","affiliation":"School of Electrical and Computer Engineering, University of Campinas (UNICAMP)","username":null,"profile_image":null},{"name":"Marcos M. Raimundo","affiliation":"School of Electrical and Computer Engineering, University of Campinas (UNICAMP)","username":null,"profile_image":null},{"name":"Ellen M. B. Cavalheiro","affiliation":"School of Electrical and Computer Engineering, University of Campinas (UNICAMP)","username":null,"profile_image":null},{"name":"Luis F. P. Salles","affiliation":"Graduate Program in Ecology, Institute of Biology, University of Campinas (UNICAMP)","username":null,"profile_image":null},{"name":"Christiano Lyra","affiliation":"School of Electrical and Computer Engineering, University of Campinas (UNICAMP)","username":null,"profile_image":null},{"name":"Fernando J. Von Zuben.","affiliation":"School of Electrical and Computer Engineering, University of Campinas (UNICAMP)","username":null,"profile_image":null}],"user":{"profile_image":"\/img\/avatars\/018.png","username":"marcos-m-raimundo","full_name":"Marcos M. Raimundo","created_by":"Marcos M. Raimundo"},"access":{"can_view":"1","can_remove":"0","can_add":"0","can_edit":0,"can_publish":0,"can_get_doi":0,"can_share":"0","can_move":"1","can_transfer":"1","can_download":"1","is_locked":"0"},"is_contact_suspended":0,"guidelines":null,"status_id":"1","is_research":null,"status_info":null,"steps":[{"id":"596802","is_changed":"0","original_id":"0","is_skipped":"0","is_checked":"0","guid":"AC7889A77583446889899D2DCC9D19B7","previous_guid":"34045A4C55F844119910F577FF624F3F","previous_id":"600418","last_modified":"1514989599","components":[{"component_id":"1027140","previous_id":0,"original_id":"0","guid":"975FB1FB26E34102B121E8602FDA74CF","previous_guid":null,"component_type_id":"1","data_id":null,"data":"<p>To download the dataset with images available in www.antweb.org, use the code in Zenodo (Can be\u00a0reached by DOI: <a href=\"http:\/\/doi.org\/10.5281\/zenodo.1134690\" target=\"_blank\">http:\/\/doi.org\/10.5281\/zenodo.1134690<\/a>).<\/p>\n<p>\u00a0<\/p>\n<p>In Linux run the commands:\u00a0\u00a0<\/p>\n<p>\u00a0<\/p>\n<pre class=\"language-markup\"><code>$ wget https:\/\/zenodo.org\/record\/1134690\/files\/marcosmrai\/antweb_crawler-v0.1.zip\n$ unzip antweb_crawler-v0.1.zip \n$ cd marcosmrai-antweb_crawler-526379e\/\n$ python crawler.py<\/code><\/pre>\n<p>\u00a0<\/p>\n<p>Set project and image folders (you can leave it in blank to choose the default), and choose option 2. It will download all images from antweb.org.<\/p>","order_id":"0","name":"Description","data_by_id":"0","type_id":"1","source_data":{"description":"<p>To download the dataset with images available in www.antweb.org, use the code in Zenodo (Can be\u00a0reached by DOI: <a href=\"http:\/\/doi.org\/10.5281\/zenodo.1134690\" target=\"_blank\">http:\/\/doi.org\/10.5281\/zenodo.1134690<\/a>).<\/p>\n<p>\u00a0<\/p>\n<p>In Linux run the commands:\u00a0\u00a0<\/p>\n<p>\u00a0<\/p>\n<pre class=\"language-markup\"><code>$ wget https:\/\/zenodo.org\/record\/1134690\/files\/marcosmrai\/antweb_crawler-v0.1.zip\n$ unzip antweb_crawler-v0.1.zip \n$ cd marcosmrai-antweb_crawler-526379e\/\n$ python crawler.py<\/code><\/pre>\n<p>\u00a0<\/p>\n<p>Set project and image folders (you can leave it in blank to choose the default), and choose option 2. It will download all images from antweb.org.<\/p>"},"is_project":0},{"component_id":"1027141","previous_id":"1027140","original_id":"0","guid":"4476509D5CBB49A9861FCC7CA60C3AFA","previous_guid":"975FB1FB26E34102B121E8602FDA74CF","component_type_id":"6","data_id":"0","data":"Run the script for dataset gathering","order_id":"1","name":"Section","data_by_id":"0","type_id":"6","source_data":{"section":"Run the script for dataset gathering"},"is_project":0},{"component_id":"1037865","previous_id":"1027141","original_id":"0","guid":"C52BDB3542D74A14847D0C4E904C3812","previous_guid":"4476509D5CBB49A9861FCC7CA60C3AFA","component_type_id":"17","data_id":"1324","data":"<p>Download all ant images from antweb.org.<\/p>\n<p>Some images might be corrupted. If that happens, you might have to download another version direct from the site.<\/p>","order_id":"2","name":"Expected result","data_by_id":"1","type_id":"17","source_data":{"result":"<p>Download all ant images from antweb.org.<\/p>\n<p>Some images might be corrupted. If that happens, you might have to download another version direct from the site.<\/p>"},"is_project":0}]},{"id":"596803","is_changed":"0","original_id":"0","is_skipped":"0","is_checked":"0","guid":"EC379E07D9EC48E5A26E628F9799029C","previous_guid":"AC7889A77583446889899D2DCC9D19B7","previous_id":"596802","last_modified":"1515003651","components":[{"component_id":"1027144","previous_id":0,"original_id":"0","guid":"86E1554FB1C64F44B3EF2C675479FB79","previous_guid":null,"component_type_id":"6","data_id":"0","data":"Manage data split","order_id":"0","name":"Section","data_by_id":"0","type_id":"6","source_data":{"section":"Manage data split"},"is_project":0},{"component_id":"1027143","previous_id":"1027144","original_id":"0","guid":"1EB43B10A1B4489DA9EAE87CDC697184","previous_guid":"86E1554FB1C64F44B3EF2C675479FB79","component_type_id":"1","data_id":null,"data":"<p>\u00a0<\/p>\n<p>Run the command (in Linux) below (keeping the same folders selected previously) and select option 3 to split the dataset.<\/p>\n<pre class=\"language-markup\"><code>$ python crawler.py<\/code><\/pre>\n<p>\u00a0<\/p>\n<p>Running the command below, in Linux, it's poss\u00edble see the generated folder and files.<\/p>\n<p>\u00a0<\/p>\n<pre class=\"language-markup\"><code>$ tree testing<\/code><\/pre>\n<p>\u00a0<\/p>\n<p>You will see the following result.<\/p>\n<p>\u00a0<\/p>\n<p>\u00a0<img src=\"https:\/\/s3.amazonaws.com\/pr-journal\/qpdid4w.png\" data-src=\"https:\/\/s3.amazonaws.com\/pr-journal\/qpdid4w.png\" data-ofn=\"testing2.png\" \/><\/p>\n<p>\u00a0<\/p>\n<p>\u00a0<\/p>\n<p>The files inside the paste 'split' are the dataset split required by Caffe.<\/p>\n<p>\u00a0<\/p>\n<p>Inside the dataset57 folder are the files used in our experiment, if you want to use the same data split and download the same images.<\/p>\n<p><strong>\u00a0<\/strong><\/p>\n<p>\u00a0Image Example (Leptogenys\/casent0095124\/casent0095124_p_1_high.jpg)<\/p>\n<p>\u00a0<\/p>\n<p><img src=\"https:\/\/s3.amazonaws.com\/pr-journal\/rq6ijyn.png\" data-src=\"https:\/\/s3.amazonaws.com\/pr-journal\/rq5ijyn.png\" data-ofn=\"antExample.png\" \/><\/p>\n<p>\u00a0<\/p>\n<p>\u00a0<\/p>","order_id":"1","name":"Description","data_by_id":"0","type_id":"1","source_data":{"description":"<p>\u00a0<\/p>\n<p>Run the command (in Linux) below (keeping the same folders selected previously) and select option 3 to split the dataset.<\/p>\n<pre class=\"language-markup\"><code>$ python crawler.py<\/code><\/pre>\n<p>\u00a0<\/p>\n<p>Running the command below, in Linux, it's poss\u00edble see the generated folder and files.<\/p>\n<p>\u00a0<\/p>\n<pre class=\"language-markup\"><code>$ tree testing<\/code><\/pre>\n<p>\u00a0<\/p>\n<p>You will see the following result.<\/p>\n<p>\u00a0<\/p>\n<p>\u00a0<img src=\"https:\/\/s3.amazonaws.com\/pr-journal\/qpdid4w.png\" data-src=\"https:\/\/s3.amazonaws.com\/pr-journal\/qpdid4w.png\" data-ofn=\"testing2.png\" \/><\/p>\n<p>\u00a0<\/p>\n<p>\u00a0<\/p>\n<p>The files inside the paste 'split' are the dataset split required by Caffe.<\/p>\n<p>\u00a0<\/p>\n<p>Inside the dataset57 folder are the files used in our experiment, if you want to use the same data split and download the same images.<\/p>\n<p><strong>\u00a0<\/strong><\/p>\n<p>\u00a0Image Example (Leptogenys\/casent0095124\/casent0095124_p_1_high.jpg)<\/p>\n<p>\u00a0<\/p>\n<p><img src=\"https:\/\/s3.amazonaws.com\/pr-journal\/rq6ijyn.png\" data-src=\"https:\/\/s3.amazonaws.com\/pr-journal\/rq5ijyn.png\" data-ofn=\"antExample.png\" \/><\/p>\n<p>\u00a0<\/p>\n<p>\u00a0<\/p>"},"is_project":0},{"component_id":"1028116","previous_id":"1027143","original_id":"0","guid":"C1249A4BCCE9458B84D593DEF70B8701","previous_guid":"1EB43B10A1B4489DA9EAE87CDC697184","component_type_id":"17","data_id":"1271","data":"<p>Construct a dataset split needed by caffe.<\/p>","order_id":"2","name":"Expected result","data_by_id":"1","type_id":"17","source_data":{"result":"<p>Construct a dataset split needed by caffe.<\/p>"},"is_project":0}]},{"id":"600418","is_changed":"0","original_id":"0","is_skipped":"0","is_checked":"0","guid":"34045A4C55F844119910F577FF624F3F","previous_guid":null,"previous_id":"0","last_modified":"1515003593","components":[{"component_id":"1036149","previous_id":0,"original_id":"0","guid":"07FF5DECD098403FA7299692EE2EFB84","previous_guid":null,"component_type_id":"6","data_id":"0","data":"Install Prerequisite Softwares and Libraries","order_id":"0","name":"Section","data_by_id":"0","type_id":"6","source_data":{"section":"Install Prerequisite Softwares and Libraries"},"is_project":0},{"component_id":"1036148","previous_id":"1036149","original_id":"0","guid":"32CE9F46B4A54C8BBF0A49B0A9D30502","previous_guid":"07FF5DECD098403FA7299692EE2EFB84","component_type_id":"1","data_id":null,"data":"<p>This protocol requires:<\/p>\n<ul>\n<li>python (https:\/\/www.python.org\/)\u00a0<\/li>\n<li>Numpy (http:\/\/www.numpy.org\/)<\/li>\n<li>Jupyter Notebook (http:\/\/jupyter.org\/)<\/li>\n<li>Caffe - Deep learning framework (http:\/\/caffe.berkeleyvision.org\/)<\/li>\n<\/ul>\n<p>Each instruction can be verified on property websites.<\/p>\n<p>\u00a0<\/p>\n<p>The main steps are the following: dataset preparation,\u00a0CNN training (using text terminal),\u00a0CNN output gathering (using Jupyter notebook) and a phase to create an Ensemble (Ensemble building and output gathering).<\/p>\n<p>\u00a0<\/p>","order_id":"1","name":"Description","data_by_id":"0","type_id":"1","source_data":{"description":"<p>This protocol requires:<\/p>\n<ul>\n<li>python (https:\/\/www.python.org\/)\u00a0<\/li>\n<li>Numpy (http:\/\/www.numpy.org\/)<\/li>\n<li>Jupyter Notebook (http:\/\/jupyter.org\/)<\/li>\n<li>Caffe - Deep learning framework (http:\/\/caffe.berkeleyvision.org\/)<\/li>\n<\/ul>\n<p>Each instruction can be verified on property websites.<\/p>\n<p>\u00a0<\/p>\n<p>The main steps are the following: dataset preparation,\u00a0CNN training (using text terminal),\u00a0CNN output gathering (using Jupyter notebook) and a phase to create an Ensemble (Ensemble building and output gathering).<\/p>\n<p>\u00a0<\/p>"},"is_project":0},{"component_id":"1036424","previous_id":"1036148","original_id":"0","guid":"83A773C6914945339CE256CF505D7903","previous_guid":"32CE9F46B4A54C8BBF0A49B0A9D30502","component_type_id":"17","data_id":"1320","data":"<p>Install prerequisites (Python, Caffe, Notebook, Numpy)<\/p>","order_id":"2","name":"Expected result","data_by_id":"1","type_id":"17","source_data":{"result":"<p>Install prerequisites (Python, Caffe, Notebook, Numpy)<\/p>"},"is_project":0}]},{"id":"600421","is_changed":"0","original_id":"0","is_skipped":"0","is_checked":"0","guid":"F3F0FBA8024444AE848405B28966936F","previous_guid":"EC379E07D9EC48E5A26E628F9799029C","previous_id":"596803","last_modified":"1515003708","components":[{"component_id":"1036155","previous_id":0,"original_id":"0","guid":"7E0218E0338E414B8B7AF2E5599534D1","previous_guid":null,"component_type_id":"6","data_id":"0","data":"Preparing Data to Caffe","order_id":"0","name":"Section","data_by_id":"0","type_id":"6","source_data":{"section":"Preparing Data to Caffe"},"is_project":0},{"component_id":"1036154","previous_id":"1036155","original_id":"0","guid":"FFC0BCB87D9C4C1A87951668C28D9631","previous_guid":"7E0218E0338E414B8B7AF2E5599534D1","component_type_id":"1","data_id":null,"data":"<p>Caffe uses database .mdb to make the training.<\/p>\n<p>\u00a0<\/p>\n<p>The file <strong>examples\/imagenet\/create_imagenet.sh\u00a0<\/strong>was used to\u00a0create this dataset. The file was modified to generate 2 datasets (training and validation) in order to test the different hypothesis.\u00a0<\/p>\n<p>\u00a0<\/p>\n<p>The generated files (data.mdb and lock.mdb) are inside the folders ants#PB_train_lmdb and ants#PB_val_lmbd, where # represents the code for each one of perspectives\u00a0(Head - H,\u00a0Profile - P, Dorsal - D, all perspectives - null)\u00a0<\/p>\n<p>\u00a0<\/p>\n<p>All files generated can be seen with the\u00a0command 'tree testing'; with the following results:<\/p>\n<p>\u00a0<\/p>\n<p><img id=\"s-mce-img\" class=\"s-mce-img\" src=\"https:\/\/s3.amazonaws.com\/pr-journal\/rqhijyn.png\" data-src=\"https:\/\/s3.amazonaws.com\/pr-journal\/rqhijyn.png\" data-ofn=\"Captura de tela de 2017-12-21 22-31-55.png\" \/><\/p>\n<p>\u00a0<\/p>\n<p>\u00a0<\/p>\n<p>The file with the average of the images was created to assist the training using the following command:<\/p>\n<p>\u00a0<\/p>\n<pre class=\"language-markup\"><code>$ \/caffe\/install\/dir\/compute_image_mean .\/data\/antnet?_mean.binaryproto<\/code><\/pre>\n<pre>\u00a0<\/pre>\n<p>\u00a0<img src=\"https:\/\/s3.amazonaws.com\/pr-journal\/rqqijyn.png\" data-src=\"https:\/\/s3.amazonaws.com\/pr-journal\/rqqijyn.png\" data-ofn=\"means.png\" \/><\/p>","order_id":"1","name":"Description","data_by_id":"0","type_id":"1","source_data":{"description":"<p>Caffe uses database .mdb to make the training.<\/p>\n<p>\u00a0<\/p>\n<p>The file <strong>examples\/imagenet\/create_imagenet.sh\u00a0<\/strong>was used to\u00a0create this dataset. The file was modified to generate 2 datasets (training and validation) in order to test the different hypothesis.\u00a0<\/p>\n<p>\u00a0<\/p>\n<p>The generated files (data.mdb and lock.mdb) are inside the folders ants#PB_train_lmdb and ants#PB_val_lmbd, where # represents the code for each one of perspectives\u00a0(Head - H,\u00a0Profile - P, Dorsal - D, all perspectives - null)\u00a0<\/p>\n<p>\u00a0<\/p>\n<p>All files generated can be seen with the\u00a0command 'tree testing'; with the following results:<\/p>\n<p>\u00a0<\/p>\n<p><img id=\"s-mce-img\" class=\"s-mce-img\" src=\"https:\/\/s3.amazonaws.com\/pr-journal\/rqhijyn.png\" data-src=\"https:\/\/s3.amazonaws.com\/pr-journal\/rqhijyn.png\" data-ofn=\"Captura de tela de 2017-12-21 22-31-55.png\" \/><\/p>\n<p>\u00a0<\/p>\n<p>\u00a0<\/p>\n<p>The file with the average of the images was created to assist the training using the following command:<\/p>\n<p>\u00a0<\/p>\n<pre class=\"language-markup\"><code>$ \/caffe\/install\/dir\/compute_image_mean .\/data\/antnet?_mean.binaryproto<\/code><\/pre>\n<pre>\u00a0<\/pre>\n<p>\u00a0<img src=\"https:\/\/s3.amazonaws.com\/pr-journal\/rqqijyn.png\" data-src=\"https:\/\/s3.amazonaws.com\/pr-journal\/rqqijyn.png\" data-ofn=\"means.png\" \/><\/p>"},"is_project":0}]},{"id":"600427","is_changed":"0","original_id":"0","is_skipped":"0","is_checked":"0","guid":"854ED8A152204602A1B3854BE5679FA3","previous_guid":"44C08198CBCA4CB781F7A96B0DF4CC70","previous_id":"600520","last_modified":"1514900070","components":[{"component_id":"1036171","previous_id":0,"original_id":"0","guid":"332536BDAC1F4B79A39C16790F7F852C","previous_guid":null,"component_type_id":"6","data_id":"0","data":"Training models with Caffe","order_id":"0","name":"Section","data_by_id":"0","type_id":"6","source_data":{"section":"Training models with Caffe"},"is_project":0},{"component_id":"1036170","previous_id":"1036171","original_id":"0","guid":"5CFC9293BC794143BBBB2448D553F6BB","previous_guid":"332536BDAC1F4B79A39C16790F7F852C","component_type_id":"1","data_id":null,"data":"<p>The models were trained in Linux with Caffe.<\/p>\n<p>\u00a0<\/p>\n<p>To train one model with all perspective was used:<\/p>\n<p>\u00a0<\/p>\n<pre class=\"language-markup\"><code>$ \/caffe\/install\/dir\/caffe train --solver=models\/bvlc_general\/solver.prototxt<\/code><\/pre>\n<p>\u00a0\u00a0<\/p>\n<p>To train one model to each perspective was used:<\/p>\n<p>\u00a0<\/p>\n<pre class=\"language-markup\"><code>$ \/caffe\/install\/dir\/caffe train --solver=models\/bvlc_especific\/solverD.prototxt\n$ \/caffe\/install\/dir\/caffe train --solver=models\/bvlc_especific\/solverH.prototxt\n$ \/caffe\/install\/dir\/caffe train --solver=models\/bvlc_especific\/solverP.prototxt<\/code><\/pre>\n<p>\u00a0<\/p>\n<p>To train one model to each perspective with a feature extracted to the machine with all perspectives was used:<\/p>\n<p>\u00a0<\/p>\n<pre class=\"language-markup\"><code>$ \/caffe\/install\/dir\/caffe train --solver=models\/bvlc_transfer\/solverTD.prototxt--snapshot=models\/bvlc_antnet\/snapshot\/antsPB_train_iter_50000.solverstate\n$ \/caffe\/install\/dir\/caffe train --solver=models\/bvlc_transfer\/solverTH.prototxt--snapshot=models\/bvlc_antnet\/snapshot\/antsPB_train_iter_50000.solverstate\n$ \/caffe\/install\/dir\/caffe train --solver=models\/bvlc_transfer\/solverTP.prototxt--snapshot=models\/bvlc_antnet\/snapshot\/antsPB_train_iter_50000.solverstate<\/code><\/pre>\n<p>\u00a0<\/p>\n<p>\u00a0<\/p>\n<p>\u00a0The command 'tree testing' results in:<\/p>\n<p>\u00a0<\/p>\n<p><img id=\"s-mce-img\" class=\"s-mce-img\" src=\"https:\/\/s3.amazonaws.com\/pr-journal\/rqmijyn.png\" data-src=\"https:\/\/s3.amazonaws.com\/pr-journal\/rqmijyn.png\" data-ofn=\"prototxt.png\" \/><\/p>\n<p>\u00a0<\/p>\n<p>\u00a0<\/p>\n<p>\u00a0<\/p>","order_id":"1","name":"Description","data_by_id":"0","type_id":"1","source_data":{"description":"<p>The models were trained in Linux with Caffe.<\/p>\n<p>\u00a0<\/p>\n<p>To train one model with all perspective was used:<\/p>\n<p>\u00a0<\/p>\n<pre class=\"language-markup\"><code>$ \/caffe\/install\/dir\/caffe train --solver=models\/bvlc_general\/solver.prototxt<\/code><\/pre>\n<p>\u00a0\u00a0<\/p>\n<p>To train one model to each perspective was used:<\/p>\n<p>\u00a0<\/p>\n<pre class=\"language-markup\"><code>$ \/caffe\/install\/dir\/caffe train --solver=models\/bvlc_especific\/solverD.prototxt\n$ \/caffe\/install\/dir\/caffe train --solver=models\/bvlc_especific\/solverH.prototxt\n$ \/caffe\/install\/dir\/caffe train --solver=models\/bvlc_especific\/solverP.prototxt<\/code><\/pre>\n<p>\u00a0<\/p>\n<p>To train one model to each perspective with a feature extracted to the machine with all perspectives was used:<\/p>\n<p>\u00a0<\/p>\n<pre class=\"language-markup\"><code>$ \/caffe\/install\/dir\/caffe train --solver=models\/bvlc_transfer\/solverTD.prototxt--snapshot=models\/bvlc_antnet\/snapshot\/antsPB_train_iter_50000.solverstate\n$ \/caffe\/install\/dir\/caffe train --solver=models\/bvlc_transfer\/solverTH.prototxt--snapshot=models\/bvlc_antnet\/snapshot\/antsPB_train_iter_50000.solverstate\n$ \/caffe\/install\/dir\/caffe train --solver=models\/bvlc_transfer\/solverTP.prototxt--snapshot=models\/bvlc_antnet\/snapshot\/antsPB_train_iter_50000.solverstate<\/code><\/pre>\n<p>\u00a0<\/p>\n<p>\u00a0<\/p>\n<p>\u00a0The command 'tree testing' results in:<\/p>\n<p>\u00a0<\/p>\n<p><img id=\"s-mce-img\" class=\"s-mce-img\" src=\"https:\/\/s3.amazonaws.com\/pr-journal\/rqmijyn.png\" data-src=\"https:\/\/s3.amazonaws.com\/pr-journal\/rqmijyn.png\" data-ofn=\"prototxt.png\" \/><\/p>\n<p>\u00a0<\/p>\n<p>\u00a0<\/p>\n<p>\u00a0<\/p>"},"is_project":0},{"component_id":"1037653","previous_id":"1036170","original_id":"0","guid":"3054D6CE08C545739337B3FA0D61134C","previous_guid":"5CFC9293BC794143BBBB2448D553F6BB","component_type_id":"17","data_id":"1321","data":"<p>Train the different models using Caffe.<\/p>","order_id":"2","name":"Expected result","data_by_id":"1","type_id":"17","source_data":{"result":"<p>Train the different models using Caffe.<\/p>"},"is_project":0}]},{"id":"600433","is_changed":"0","original_id":"0","is_skipped":"0","is_checked":"0","guid":"CD5B647E7231482AB43FB82309CBEB7D","previous_guid":"854ED8A152204602A1B3854BE5679FA3","previous_id":"600427","last_modified":"1514989725","components":[{"component_id":"1036183","previous_id":0,"original_id":"0","guid":"AD90A7BDE8C24D0590BADEB3D3B9C299","previous_guid":null,"component_type_id":"6","data_id":"0","data":"Gathering the outputs from Caffe CNN","order_id":"0","name":"Section","data_by_id":"0","type_id":"6","source_data":{"section":"Gathering the outputs from Caffe CNN"},"is_project":0},{"component_id":"1036182","previous_id":"1036183","original_id":"0","guid":"150BFBE656934E15A444569BB3A15239","previous_guid":"AD90A7BDE8C24D0590BADEB3D3B9C299","component_type_id":"1","data_id":null,"data":"<p>The testing analysis was created using Jupyter Notebook.<\/p>\n<p>\u00a0<\/p>\n<p>#Necessary imports<\/p>\n<p>\u00a0<\/p>\n<pre class=\"language-markup\"><code>import numpy as np\nimport caffe<\/code><\/pre>\n<p>\u00a0<\/p>\n<p>#Prepare paths and files<\/p>\n<p>\u00a0<\/p>\n<pre class=\"language-markup\"><code>model_file = '\/module\/directory\/bvlc_my_model.caffemodel'\ndeploy_prototxt = '\/deploy\/directory\/deploy.prototxt'\nimagemean_file = np.load('\/image_mean\/directory\/antnet#_mean.npy').mean(1).mean(1)<\/code><\/pre>\n<p>\u00a0<\/p>\n<p>\u00a0<\/p>\n<p>#Use caffe.set_mode_cpu() to compute in CPU<\/p>\n<pre class=\"language-python\"><code>caffe.set_mode_gpu() <\/code><\/pre>\n<p>\u00a0<\/p>\n<p>#Prepare the module<\/p>\n<p>\u00a0<\/p>\n<pre class=\"language-markup\"><code>net = caffe.Net(deploy_prototxt, model_file, caffe.TEST)\n\ntransformer = caffe.io.Transformer({'data': net.blobs['data'].data.shape})\ntransformer.set_mean('data', imagemean_file)\ntransformer.set_transpose('data', (2,0,1))\ntransformer.set_raw_scale('data', 255.0)\n\nnet.blobs['data'].reshape(50,3,256,256) #batch size 50, 3 chanells but all grayscale, height 256, width 256<\/code><\/pre>\n<p>\u00a0<\/p>\n<p>#Loading one image\u00a0for test (the file test dataset_test.txt can be read in a loop)\u00a0<\/p>\n<p>\u00a0<\/p>\n<pre class=\"language-markup\"><code>img = caffe.io.load_image('\/image_example\/Leptogenys\/casent0095124\/casent0095124_p_1_high.jpg')\nforward(img, net, transformer)<\/code><\/pre>\n<p>\u00a0<\/p>\n<p>\u00a0<\/p>\n<pre class=\"language-markup\"><code>def forward(image, net, transformer):\n     net.blobs['data'].data[...] = transformer.preprocess('data', img)\n     output = net.forward()\n     output_prob = output['prob'][0]\n     return output_prob<\/code><\/pre>\n<p>\u00a0<\/p>\n<p>(Result to Example)<\/p>\n<p>\u00a0#9.96067882e-01 Leptogenys<\/p>\n<p>\u00a0\u00a0<\/p>\n<p>\u00a0<\/p>","order_id":"1","name":"Description","data_by_id":"0","type_id":"1","source_data":{"description":"<p>The testing analysis was created using Jupyter Notebook.<\/p>\n<p>\u00a0<\/p>\n<p>#Necessary imports<\/p>\n<p>\u00a0<\/p>\n<pre class=\"language-markup\"><code>import numpy as np\nimport caffe<\/code><\/pre>\n<p>\u00a0<\/p>\n<p>#Prepare paths and files<\/p>\n<p>\u00a0<\/p>\n<pre class=\"language-markup\"><code>model_file = '\/module\/directory\/bvlc_my_model.caffemodel'\ndeploy_prototxt = '\/deploy\/directory\/deploy.prototxt'\nimagemean_file = np.load('\/image_mean\/directory\/antnet#_mean.npy').mean(1).mean(1)<\/code><\/pre>\n<p>\u00a0<\/p>\n<p>\u00a0<\/p>\n<p>#Use caffe.set_mode_cpu() to compute in CPU<\/p>\n<pre class=\"language-python\"><code>caffe.set_mode_gpu() <\/code><\/pre>\n<p>\u00a0<\/p>\n<p>#Prepare the module<\/p>\n<p>\u00a0<\/p>\n<pre class=\"language-markup\"><code>net = caffe.Net(deploy_prototxt, model_file, caffe.TEST)\n\ntransformer = caffe.io.Transformer({'data': net.blobs['data'].data.shape})\ntransformer.set_mean('data', imagemean_file)\ntransformer.set_transpose('data', (2,0,1))\ntransformer.set_raw_scale('data', 255.0)\n\nnet.blobs['data'].reshape(50,3,256,256) #batch size 50, 3 chanells but all grayscale, height 256, width 256<\/code><\/pre>\n<p>\u00a0<\/p>\n<p>#Loading one image\u00a0for test (the file test dataset_test.txt can be read in a loop)\u00a0<\/p>\n<p>\u00a0<\/p>\n<pre class=\"language-markup\"><code>img = caffe.io.load_image('\/image_example\/Leptogenys\/casent0095124\/casent0095124_p_1_high.jpg')\nforward(img, net, transformer)<\/code><\/pre>\n<p>\u00a0<\/p>\n<p>\u00a0<\/p>\n<pre class=\"language-markup\"><code>def forward(image, net, transformer):\n     net.blobs['data'].data[...] = transformer.preprocess('data', img)\n     output = net.forward()\n     output_prob = output['prob'][0]\n     return output_prob<\/code><\/pre>\n<p>\u00a0<\/p>\n<p>(Result to Example)<\/p>\n<p>\u00a0#9.96067882e-01 Leptogenys<\/p>\n<p>\u00a0\u00a0<\/p>\n<p>\u00a0<\/p>"},"is_project":0},{"component_id":"1037866","previous_id":"1036182","original_id":"0","guid":"842D0BACB9BD4BD7A94366E987E6DB9A","previous_guid":"150BFBE656934E15A444569BB3A15239","component_type_id":"17","data_id":"1325","data":"<p>Gather the output from dataset using Jupyter Notebook. Save results for use in Ensemble.<\/p>","order_id":"2","name":"Expected result","data_by_id":"1","type_id":"17","source_data":{"result":"<p>Gather the output from dataset using Jupyter Notebook. Save results for use in Ensemble.<\/p>"},"is_project":0}]},{"id":"600520","is_changed":"0","original_id":"0","is_skipped":"0","is_checked":"0","guid":"44C08198CBCA4CB781F7A96B0DF4CC70","previous_guid":"F3F0FBA8024444AE848405B28966936F","previous_id":"600421","last_modified":"1514943320","components":[{"component_id":"1036414","previous_id":0,"original_id":"0","guid":"9BFDC43178B048D9B9902A2E8A710915","previous_guid":null,"component_type_id":"6","data_id":"0","data":"Transform mean.binaryproto in _mean.npy","order_id":"0","name":"Section","data_by_id":"0","type_id":"6","source_data":{"section":"Transform mean.binaryproto in _mean.npy"},"is_project":0},{"component_id":"1036413","previous_id":"1036414","original_id":"0","guid":"B4F63D47C13844F3A3D30455E99EBC63","previous_guid":"9BFDC43178B048D9B9902A2E8A710915","component_type_id":"1","data_id":null,"data":"<p>In order to use the mean.binaryproto in\u00a0the testing phase it is necessary to transform .binaryproto in to .npy. Using the following code in Python.<\/p>\n<p>\u00a0<\/p>\n<pre class=\"language-markup\"><code>import numpy\nimport caffe\nimport numpy as np\nimport sys<\/code><\/pre>\n<p>\u00a0<\/p>\n<p>\u00a0<\/p>\n<p>Prepare for changes<\/p>\n<pre class=\"language-markup\"><code>blob = caffe.proto.caffe_pb2.BlobProto()\ndata = open( '\/directory\/mean\/antnet?_mean.binaryproto' , 'rb').read()\nblob.ParseFromString(data)\narr = np.array( caffe.io.blobproto_to_array(blob)) \nout = arr[0]<\/code><\/pre>\n<p>\u00a0<\/p>\n<p>Save the new archive\u00a0<\/p>\n<pre class=\"language-markup\"><code>np.save('\/image_mean\/directory\/antnet?_mean.npy'' , out )<\/code><\/pre>\n<p>\u00a0<\/p>","order_id":"1","name":"Description","data_by_id":"0","type_id":"1","source_data":{"description":"<p>In order to use the mean.binaryproto in\u00a0the testing phase it is necessary to transform .binaryproto in to .npy. Using the following code in Python.<\/p>\n<p>\u00a0<\/p>\n<pre class=\"language-markup\"><code>import numpy\nimport caffe\nimport numpy as np\nimport sys<\/code><\/pre>\n<p>\u00a0<\/p>\n<p>\u00a0<\/p>\n<p>Prepare for changes<\/p>\n<pre class=\"language-markup\"><code>blob = caffe.proto.caffe_pb2.BlobProto()\ndata = open( '\/directory\/mean\/antnet?_mean.binaryproto' , 'rb').read()\nblob.ParseFromString(data)\narr = np.array( caffe.io.blobproto_to_array(blob)) \nout = arr[0]<\/code><\/pre>\n<p>\u00a0<\/p>\n<p>Save the new archive\u00a0<\/p>\n<pre class=\"language-markup\"><code>np.save('\/image_mean\/directory\/antnet?_mean.npy'' , out )<\/code><\/pre>\n<p>\u00a0<\/p>"},"is_project":0}]},{"id":"600523","is_changed":"0","original_id":"0","is_skipped":"0","is_checked":"0","guid":"279308AFB85B4ABCB7AE62B86259122C","previous_guid":"CD5B647E7231482AB43FB82309CBEB7D","previous_id":"600433","last_modified":"1515003788","components":[{"component_id":"1036420","previous_id":0,"original_id":"0","guid":"EBFE11B77C424C08B9300E1A9EAD1A11","previous_guid":null,"component_type_id":"6","data_id":"0","data":"Using Results in Ensemble","order_id":"0","name":"Section","data_by_id":"0","type_id":"6","source_data":{"section":"Using Results in Ensemble"},"is_project":0},{"component_id":"1036419","previous_id":"1036420","original_id":"0","guid":"028FDC5778B149A7BCCB141440D13029","previous_guid":"EBFE11B77C424C08B9300E1A9EAD1A11","component_type_id":"1","data_id":null,"data":"<p>Executing the commands on Step 7 but changing the command below you can load a different model:<\/p>\n<pre class=\"language-markup\"><code>model_file = '\/module\/directory\/bvlc_my_model.caffemodel'<\/code><\/pre>\n<p>\u00a0<\/p>\n<p>As a result, we can load the models:<\/p>\n<p>\u00a0<\/p>\n<pre class=\"language-markup\"><code>model_gen #general model\nmodel_spe_head #head specific model\nmodel_spe_profile #profile specific model\nmodel_spe_dorsum #dorsum specific model\nmodel_tra_head #head transfered model\nmodel_tra_profile #profile transfered model\nmodel_tra_dorsum #dorsum transfered model<\/code><\/pre>\n<p>\u00a0<\/p>\n<p>Next, build the following ensembles - the <code>forward(image, net, transformer) <\/code>python method\u00a0can be seen in step 7.<\/p>\n<p>\u00a0<\/p>\n<p>General Ensemble:<\/p>\n<p>\u00a0<\/p>\n<pre class=\"language-markup\"><code>img_gen_head = caffe.io.load_image('\/directory\/image_example\/Leptogenys\/casent0095124\/casent0095124_h_1_high.jpg')\nprob_gen_head = forward(img_gen_head, model_gen, transformer)\nimg_gen_profile = caffe.io.load_image('\/directory\/image_example\/Leptogenys\/casent0095124\/casent0095124_p_1_high.jpg')\nprob_gen_profile = forward(img_gen_head, model_gen, transformer)\nimg_gen_dorsum = caffe.io.load_image('\/directory\/image_example\/Leptogenys\/casent0095124\/casent0095124_d_1_high.jpg')\nprob_gen_dorsum = forward(img_gen_dorsum, model_gen, transformer)\n\nprob_gen_ensemble = prob_gen_head+prob_gen_profile+prob_gen_dorsum<\/code><\/pre>\n<p><br \/>Specific Ensemble:<\/p>\n<p>\u00a0<\/p>\n<p>\u00a0<\/p>\n<pre class=\"language-markup\"><code>img_spe_head = caffe.io.load_image('\/directory\/image_example\/Leptogenys\/casent0095124\/casent0095124_h_1_high.jpg')\nprob_spe_head = forward(img_gen_head, model_spe_head, transformer)\nimg_spe_profile = caffe.io.load_image('\/directory\/image_example\/Leptogenys\/casent0095124\/casent0095124_p_1_high.jpg')\nprob_spe_profile = forward(img_gen_head, model_spe_profile, transformer)\nimg_spe_dorsum = caffe.io.load_image('\/directory\/image_example\/Leptogenys\/casent0095124\/casent0095124_d_1_high.jpg')\nprob_spe_dorsum = forward(img_gen_dorsum, model_spe_dorsum, transformer)\n\nprob_spe_ensemble = prob_spe_head+prob_spe_profile+prob_spe_dorsum<\/code><\/pre>\n<p><br \/>Transfer ensemble:<\/p>\n<p>\u00a0<\/p>\n<p>\u00a0<\/p>\n<pre class=\"language-markup\"><code>img_tra_head = caffe.io.load_image('\/directory\/image_example\/Leptogenys\/casent0095124\/casent0095124_h_1_high.jpg')\nprob_tra_head = forward(img_tra_head, model_tra_head, transformer)\nimg_tra_profile = caffe.io.load_image('\/directory\/image_example\/Leptogenys\/casent0095124\/casent0095124_p_1_high.jpg')\nprob_tra_profile = forward(img_tra_head, model_tra_profile, transformer)\nimg_tra_dorsum = caffe.io.load_image('\/directory\/image_example\/Leptogenys\/casent0095124\/casent0095124_d_1_high.jpg')\nprob_tra_dorsum = forward(img_tra_dorsum, model_tra_dorsum, transformer)\n\nprob_tra_ensemble = prob_tra_head+prob_tra_profile+prob_tra_dorsum<\/code><\/pre>\n<p>\u00a0<\/p>\n<p>The Ensemble of all models (considering the models already loaded):<\/p>\n<p>\u00a0<\/p>\n<pre class=\"language-markup\"><code>prob_all_ensemble = prob_gen_head+prob_gen_profile+prob_gen_dorsum+\\\nprob_spe_head+prob_spe_profile+prob_spe_dorsum+\\\nprob_tra_head+prob_tra_profile+prob_tra_dorsum<\/code><\/pre>","order_id":"1","name":"Description","data_by_id":"0","type_id":"1","source_data":{"description":"<p>Executing the commands on Step 7 but changing the command below you can load a different model:<\/p>\n<pre class=\"language-markup\"><code>model_file = '\/module\/directory\/bvlc_my_model.caffemodel'<\/code><\/pre>\n<p>\u00a0<\/p>\n<p>As a result, we can load the models:<\/p>\n<p>\u00a0<\/p>\n<pre class=\"language-markup\"><code>model_gen #general model\nmodel_spe_head #head specific model\nmodel_spe_profile #profile specific model\nmodel_spe_dorsum #dorsum specific model\nmodel_tra_head #head transfered model\nmodel_tra_profile #profile transfered model\nmodel_tra_dorsum #dorsum transfered model<\/code><\/pre>\n<p>\u00a0<\/p>\n<p>Next, build the following ensembles - the <code>forward(image, net, transformer) <\/code>python method\u00a0can be seen in step 7.<\/p>\n<p>\u00a0<\/p>\n<p>General Ensemble:<\/p>\n<p>\u00a0<\/p>\n<pre class=\"language-markup\"><code>img_gen_head = caffe.io.load_image('\/directory\/image_example\/Leptogenys\/casent0095124\/casent0095124_h_1_high.jpg')\nprob_gen_head = forward(img_gen_head, model_gen, transformer)\nimg_gen_profile = caffe.io.load_image('\/directory\/image_example\/Leptogenys\/casent0095124\/casent0095124_p_1_high.jpg')\nprob_gen_profile = forward(img_gen_head, model_gen, transformer)\nimg_gen_dorsum = caffe.io.load_image('\/directory\/image_example\/Leptogenys\/casent0095124\/casent0095124_d_1_high.jpg')\nprob_gen_dorsum = forward(img_gen_dorsum, model_gen, transformer)\n\nprob_gen_ensemble = prob_gen_head+prob_gen_profile+prob_gen_dorsum<\/code><\/pre>\n<p><br \/>Specific Ensemble:<\/p>\n<p>\u00a0<\/p>\n<p>\u00a0<\/p>\n<pre class=\"language-markup\"><code>img_spe_head = caffe.io.load_image('\/directory\/image_example\/Leptogenys\/casent0095124\/casent0095124_h_1_high.jpg')\nprob_spe_head = forward(img_gen_head, model_spe_head, transformer)\nimg_spe_profile = caffe.io.load_image('\/directory\/image_example\/Leptogenys\/casent0095124\/casent0095124_p_1_high.jpg')\nprob_spe_profile = forward(img_gen_head, model_spe_profile, transformer)\nimg_spe_dorsum = caffe.io.load_image('\/directory\/image_example\/Leptogenys\/casent0095124\/casent0095124_d_1_high.jpg')\nprob_spe_dorsum = forward(img_gen_dorsum, model_spe_dorsum, transformer)\n\nprob_spe_ensemble = prob_spe_head+prob_spe_profile+prob_spe_dorsum<\/code><\/pre>\n<p><br \/>Transfer ensemble:<\/p>\n<p>\u00a0<\/p>\n<p>\u00a0<\/p>\n<pre class=\"language-markup\"><code>img_tra_head = caffe.io.load_image('\/directory\/image_example\/Leptogenys\/casent0095124\/casent0095124_h_1_high.jpg')\nprob_tra_head = forward(img_tra_head, model_tra_head, transformer)\nimg_tra_profile = caffe.io.load_image('\/directory\/image_example\/Leptogenys\/casent0095124\/casent0095124_p_1_high.jpg')\nprob_tra_profile = forward(img_tra_head, model_tra_profile, transformer)\nimg_tra_dorsum = caffe.io.load_image('\/directory\/image_example\/Leptogenys\/casent0095124\/casent0095124_d_1_high.jpg')\nprob_tra_dorsum = forward(img_tra_dorsum, model_tra_dorsum, transformer)\n\nprob_tra_ensemble = prob_tra_head+prob_tra_profile+prob_tra_dorsum<\/code><\/pre>\n<p>\u00a0<\/p>\n<p>The Ensemble of all models (considering the models already loaded):<\/p>\n<p>\u00a0<\/p>\n<pre class=\"language-markup\"><code>prob_all_ensemble = prob_gen_head+prob_gen_profile+prob_gen_dorsum+\\\nprob_spe_head+prob_spe_profile+prob_spe_dorsum+\\\nprob_tra_head+prob_tra_profile+prob_tra_dorsum<\/code><\/pre>"},"is_project":0}]}]}