{"uri":"microbial-eukaryotic-18s-tag-sequence-processing-q-j9bcr2n","version_id":"1","protocol_name":"Microbial eukaryotic 18S tag-sequence processing\/QC - V4 region (automating)","protocol_name_html":"Microbial eukaryotic 18S tag-sequence processing\/QC - V4 region (automating)","is_prepublished":"0","can_edit":"0","parent_id":"4955","api_version":"1","is_new_mode":"0","last_modified":"1521180661","type_id":"1","link":"https:\/\/github.com\/shu251\/QC_steps_V4_tagsequencing","fork_id":"","public_fork_note":"","number_of_steps":"6","has_versions":"1","first_published_date":"1507693845","publish_date":"2017-10-11 03:50:45","documents":null,"have_protocol_in_step":"0","is_protocol_in_step":"0","vendor_name":"Contributed by users","vendor_link":"https:\/\/www.protocols.io","vendor_logo":"\/img\/vendors\/1.png","mod_mins":"-45","mod_secs":"1","description":"<p>This protocol provides step-by-step instructions for implementing a perl script to easily automate quality checking of raw tag sequences. This was specifically constructed for the numerous 18S diversity projects (which target the V4 hypervariable specific for evaluting protistan diversity).<\/p>\n<p>\u00a0<\/p>\n<p>It is highly recommended that you follow along this Github repo:\u00a0https:\/\/github.com\/shu251\/QC_steps_V4_tagsequencing<\/p>\n<p>\u00a0<\/p>","is_bookmarked":"0","can_reassign":"1","before_start":"<p>Required programs:<\/p>\n<ul>\n<li>Database (preferrably with associated taxa list) to align sequences to. A version of the PR2 database formatted for QIIME can be found\u00a0<a href=\"https:\/\/drive.google.com\/drive\/folders\/0Bxzw_UrYS4IAaEQ0b0lMQ0ZiUkU?usp=sharing\" target=\"_blank\">here<\/a><\/li>\n<li><a href=\"http:\/\/qiime.org\/install\/install.html\" target=\"_blank\">QIIME<\/a>\u00a0- v.1.9.1 or higher. Note as of Jan 2018 QIIME1 will not be supported. Future iterations of this protocol will use QIIME2.<\/li>\n<li>fastqjoin - this should install with QIIME. Alternatively you can use\u00a0<a href=\"https:\/\/sco.h-its.org\/exelixis\/web\/software\/pear\/doc.html#installing\" target=\"_blank\">PEAR<\/a>\u00a0to merge PE sequences.<\/li>\n<li><a href=\"http:\/\/www.usadellab.org\/cms\/?page=trimmomatic\" target=\"_blank\">Trimmomatic<\/a>\u00a0- v.0.32<\/li>\n<li><a href=\"https:\/\/github.com\/torognes\/vsearch\" target=\"_blank\">vsearch<\/a>\u00a0- v1.11.1<\/li>\n<li>Make sure you know your primer sequences and generate a fasta file: 'trimPE_V4primer.fasta'. In the below example I'm using\u00a0<a href=\"http:\/\/onlinelibrary.wiley.com.libproxy1.usc.edu\/doi\/10.1111\/j.1365-294X.2009.04480.x\/full\/\" target=\"_blank\">V4 Stoeck et al. 2010 primers<\/a><\/li>\n<\/ul>","has_guidelines":"1","materials":[],"warning":"","version_class":"4955","public":"1","is_owner":"1","is_original_owner":"1","created_on":"1507690903","protocol_affiliation":"University of Southern California","affiliation":"University of Southern California","doi":"dx.doi.org\/10.17504\/protocols.io.j9bcr2n","doi_status":"2","changed_fork_steps":null,"profile_url":"Sarah-w2x2b4w2v2","protocol_img":"https:\/\/s3.amazonaws.com\/pr-journal\/pbgdv2e.png","profile_image":"https:\/\/s3.amazonaws.com\/pr-journal\/i9rdv2e.jpg","full_name":"Sarah  Hu","created_by":"Sarah  Hu","private_link":"4C1CEBB2B19760673F21D2B5FF375AED","original_img":"1","username":"sarah-hu","is_retracted":"0","retraction_reason":null,"plos_id":null,"manuscript_citation":"<div title=\"Page 2\">\n<div>\n<div>\n<p>Sarah K. Hu, Victoria Campbell, Paige Connell, Alyssa Gellene, Zhenfeng Liu, Ramon Terrado, &amp; David A. Caron. Protistan diversity and activity inferred from RNA and DNA at a coastal ocean site in the eastern North Pacific. (2016). FEMS Microbiol Ecol. 92(4) doi: 10.1093\/femsec\/fiw050.<\/p>\n<p>\u00a0<\/p>\n<p>Sarah K. Hu, Zhenfeng Liu, Alle A. Y. Lie, Peter D. Countway, Diane Y. Kim, Adriane C. Jones, Rebecca J. Gast, S. Craig Cary, Evelyn B. Sherr, Barry F. Sherr, &amp; David A. Caron. (2015). Estimating Protistan Diversity using High-throughput Sequencing. J Eukaryot Microbiol. 62(5): 688-693.<\/p>\n<\/div>\n<\/div>\n<\/div>","journal_name":null,"is_donations_disabled":"0","is_donations_disabled_by_user":"9","item_record_id":226108,"fork_info":[],"compare_forks":[],"protocols":[],"groups":[{"group_id":"165","group_uri":"caron-lab-protistan-ecology","group_name":"Caron Lab - Protistan Ecology","group_logo":"https:\/\/s3.amazonaws.com\/pr-journal\/pbmdv2e.jpg","requested_uid":null,"request_flag":null,"my_request":"1"}],"number_of_shared_runs":[],"ownership_history":[],"keywords":"","transfer_to_user":[],"sub_transfer":false,"is_transfer_pending":false,"number_of_bookmarks":"0","collections":[],"tags":[{"tag_id":"854","tag_name":"18S rRNA gene"},{"tag_id":"855","tag_name":" Protistan diversity"},{"tag_id":"856","tag_name":" microbial eukaryotes"},{"tag_id":"857","tag_name":" microbial ecology"},{"tag_id":"858","tag_name":" tag sequencing"}],"archived":0,"sub_authors":[],"sub_protocols_number":0,"can_edit_shared":0,"shared_runs":[],"is_shared_run":0,"is_shared":1,"banner":null,"contact_badges":[{"badge_id":"1","badge_image":"\/img\/ambassador.svg","badge_description":"Ambassador"},{"badge_id":"2","badge_image":"\/img\/badges\/bronze.svg","badge_description":"Author!"},{"badge_id":"5","badge_image":"\/img\/badges\/earlyadopter.svg","badge_description":"Early adopter"}],"number_of_comments":0,"big_protocol_img":"https:\/\/s3.amazonaws.com\/pr-journal\/pbfdv2e.png","big_protocol_img_ofn":"dna.png","is_locked":0,"is_locked_by":false,"authors":"Sarah  Hu","authors_list":[{"name":"Sarah  Hu","affiliation":"University of Southern California","username":"sarah-hu","profile_image":"https:\/\/s3.amazonaws.com\/pr-journal\/i9rdv2e.jpg"}],"user":{"profile_image":"https:\/\/s3.amazonaws.com\/pr-journal\/i9rdv2e.jpg","username":"sarah-hu","full_name":"Sarah  Hu","created_by":"Sarah  Hu"},"access":{"can_view":"1","can_remove":"0","can_add":"0","can_edit":0,"can_publish":0,"can_get_doi":0,"can_share":"0","can_move":"1","can_transfer":"1","can_download":"1","is_locked":"0"},"is_contact_suspended":0,"guidelines":"<p>Protocol describes quality checking process for raw fastq sequences. Includes some discussion for alternate approaches. End product is ready for OTU clustering. I've also included suggestions for OTU clustering at the end (specific for 18S data). Much of this pipeline can be applied for any tag sequencing analysis, but keep in mind this was specifically constructed to analyze single-celled microbial eukaryotic communities.<\/p>\n<p>\u00a0<\/p>\n<p>This protocol (and my preferred method) is to perform as much quality checking on each individual sample before combining for downstream OTU clustering (or other analysis). This way, I can track any samples that may be not ideal for downstream analysis.<\/p>\n<p>\u00a0<\/p>\n<p>Full github repo:\u00a0https:\/\/github.com\/shu251\/QC_steps_V4_tagsequencing<\/p>","status_id":"1","is_research":"1","status_info":null,"steps":[{"id":"590287","is_changed":"0","original_id":"291959","is_skipped":"0","is_checked":"0","guid":"F4AED36462EE4CA8966785DB990BB244","previous_guid":null,"previous_id":null,"last_modified":"1507693071","components":[{"component_id":"1011216","previous_id":0,"original_id":"421883","guid":"C15763A5E14645FF9B8CCCB36B6F3FC7","previous_guid":null,"component_type_id":"1","data_id":null,"data":"<p>Input raw fastq files that are already demultiplexed. This tutorial uses V4 primers (Stoeck et al. 2010) for microbial eukaryotes<\/p>\n<p>\u00a0<\/p>\n<p>First create\u00a0a text file with a list of file prefixes (prefix.txt).<\/p>\n<p><strong>Example:<\/strong><\/p>\n<p>Test01_L001_R1_001.fastq<\/p>\n<p>Test01_L001_R2_001.fastq<\/p>\n<p>Test02_L001_R1_001.fastq<\/p>\n<p>Test02_L001_R2_001.fastq<\/p>\n<p>\u00a0<\/p>\n<p><strong>Associated prefixes:<\/strong><\/p>\n<p>Test01<\/p>\n<p>Test02<\/p>\n<p>\u00a0<\/p>\n<p><strong>Programs required:<\/strong><\/p>\n<ul>\n<li>Database (preferrably with associated taxa list) to align sequences to. A version of the PR2 database formatted for QIIME can be found\u00a0<a href=\"https:\/\/drive.google.com\/drive\/folders\/0Bxzw_UrYS4IAaEQ0b0lMQ0ZiUkU?usp=sharing\" target=\"_blank\">here<\/a><\/li>\n<li><a href=\"http:\/\/qiime.org\/install\/install.html\" target=\"_blank\">QIIME<\/a>\u00a0- v.1.9.1 or higher. Note as of Jan 2018 QIIME1 will not be supported. Future iterations of this protocol will use QIIME2.<\/li>\n<li>fastqjoin - this should install with QIIME. Alternatively you can use\u00a0<a href=\"https:\/\/sco.h-its.org\/exelixis\/web\/software\/pear\/doc.html#installing\" target=\"_blank\">PEAR<\/a>\u00a0to merge PE sequences.<\/li>\n<li><a href=\"http:\/\/www.usadellab.org\/cms\/?page=trimmomatic\" target=\"_blank\">Trimmomatic<\/a>\u00a0- v.0.32<\/li>\n<li><a href=\"https:\/\/github.com\/torognes\/vsearch\" target=\"_blank\">vsearch<\/a>\u00a0- v1.11.1<\/li>\n<li>Make sure you know your primer sequences and generate a fasta file: 'trimPE_V4primer.fasta'. In the below example I'm using\u00a0<a href=\"http:\/\/onlinelibrary.wiley.com.libproxy1.usc.edu\/doi\/10.1111\/j.1365-294X.2009.04480.x\/full\/\" target=\"_blank\">V4 Stoeck et al. 2010 primers<\/a><\/li>\n<li>Create a 'prefix.txt' file to index sample fastq files.<\/li>\n<li>Run 'create.map.pl'<\/li>\n<\/ul>\n<p>\u00a0<\/p>","order_id":"0","name":"Description","data_by_id":"0","type_id":"1","source_data":{"description":"<p>Input raw fastq files that are already demultiplexed. This tutorial uses V4 primers (Stoeck et al. 2010) for microbial eukaryotes<\/p>\n<p>\u00a0<\/p>\n<p>First create\u00a0a text file with a list of file prefixes (prefix.txt).<\/p>\n<p><strong>Example:<\/strong><\/p>\n<p>Test01_L001_R1_001.fastq<\/p>\n<p>Test01_L001_R2_001.fastq<\/p>\n<p>Test02_L001_R1_001.fastq<\/p>\n<p>Test02_L001_R2_001.fastq<\/p>\n<p>\u00a0<\/p>\n<p><strong>Associated prefixes:<\/strong><\/p>\n<p>Test01<\/p>\n<p>Test02<\/p>\n<p>\u00a0<\/p>\n<p><strong>Programs required:<\/strong><\/p>\n<ul>\n<li>Database (preferrably with associated taxa list) to align sequences to. A version of the PR2 database formatted for QIIME can be found\u00a0<a href=\"https:\/\/drive.google.com\/drive\/folders\/0Bxzw_UrYS4IAaEQ0b0lMQ0ZiUkU?usp=sharing\" target=\"_blank\">here<\/a><\/li>\n<li><a href=\"http:\/\/qiime.org\/install\/install.html\" target=\"_blank\">QIIME<\/a>\u00a0- v.1.9.1 or higher. Note as of Jan 2018 QIIME1 will not be supported. Future iterations of this protocol will use QIIME2.<\/li>\n<li>fastqjoin - this should install with QIIME. Alternatively you can use\u00a0<a href=\"https:\/\/sco.h-its.org\/exelixis\/web\/software\/pear\/doc.html#installing\" target=\"_blank\">PEAR<\/a>\u00a0to merge PE sequences.<\/li>\n<li><a href=\"http:\/\/www.usadellab.org\/cms\/?page=trimmomatic\" target=\"_blank\">Trimmomatic<\/a>\u00a0- v.0.32<\/li>\n<li><a href=\"https:\/\/github.com\/torognes\/vsearch\" target=\"_blank\">vsearch<\/a>\u00a0- v1.11.1<\/li>\n<li>Make sure you know your primer sequences and generate a fasta file: 'trimPE_V4primer.fasta'. In the below example I'm using\u00a0<a href=\"http:\/\/onlinelibrary.wiley.com.libproxy1.usc.edu\/doi\/10.1111\/j.1365-294X.2009.04480.x\/full\/\" target=\"_blank\">V4 Stoeck et al. 2010 primers<\/a><\/li>\n<li>Create a 'prefix.txt' file to index sample fastq files.<\/li>\n<li>Run 'create.map.pl'<\/li>\n<\/ul>\n<p>\u00a0<\/p>"},"is_project":0},{"component_id":"1011217","previous_id":"1011216","original_id":"421882","guid":"F5ACE02DD0FD464D818238E125C02FDF","previous_guid":"C15763A5E14645FF9B8CCCB36B6F3FC7","component_type_id":"6","data_id":null,"data":"Pre-processing","order_id":"1","name":"Section","data_by_id":"0","type_id":"6","source_data":{"section":"Pre-processing"},"is_project":0},{"component_id":"1011218","previous_id":"1011217","original_id":"996313","guid":"8FF0B96D73B64019AAE8CD4327A9C70C","previous_guid":"F5ACE02DD0FD464D818238E125C02FDF","component_type_id":"7","data_id":"1548","data":"https:\/\/github.com\/shu251\/QC_steps_V4_tagsequencing","order_id":"2","name":"External Link","data_by_id":"1","type_id":"7","source_data":{"link":"https:\/\/github.com\/shu251\/QC_steps_V4_tagsequencing"},"is_project":0},{"component_id":"1011235","previous_id":"1011218","original_id":"0","guid":"5C2EEC951894432297B2FBF1F614AA20","previous_guid":"8FF0B96D73B64019AAE8CD4327A9C70C","component_type_id":"15","data_id":"2312","data":"","order_id":"3","name":"Command","data_by_id":"1","type_id":"15","source_data":{"name":"git clone https:\/\/github.com\/shu251\/QC_steps_V4_tagsequencing","description":"Clone github repo","os_name":"","os_version":"","can_edit":"1"},"is_project":0}]},{"id":"590288","is_changed":"0","original_id":"291960","is_skipped":"0","is_checked":"0","guid":"4891A7B9A04941E8AADC85F739010E0B","previous_guid":"F4AED36462EE4CA8966785DB990BB244","previous_id":"590287","last_modified":"1507691975","components":[{"component_id":"1011219","previous_id":0,"original_id":"421885","guid":"FB24872518CB4CE6BDF7993A54A25B27","previous_guid":null,"component_type_id":"1","data_id":null,"data":"<p style=\"text-align: left;\">Map files in QIIME serve to de-multiplex reads (based on barcodes and indices) and are used in 'split_library' QIIME step. Here, I've split up the V4 forward primer to fulfill the necessary barcode \/ index space required in the QIIME mapping file. However, we aren't using this feature of the mapping file.\u00a0<\/p>\n<p style=\"text-align: left;\">\u00a0<\/p>\n<p style=\"text-align: left;\">Use this QIIME command to check mapping file:<\/p>\n<p style=\"text-align: left;\">http:\/\/qiime.org\/1.6.0\/scripts\/check_id_map.html<\/p>","order_id":"0","name":"Description","data_by_id":"0","type_id":"1","source_data":{"description":"<p style=\"text-align: left;\">Map files in QIIME serve to de-multiplex reads (based on barcodes and indices) and are used in 'split_library' QIIME step. Here, I've split up the V4 forward primer to fulfill the necessary barcode \/ index space required in the QIIME mapping file. However, we aren't using this feature of the mapping file.\u00a0<\/p>\n<p style=\"text-align: left;\">\u00a0<\/p>\n<p style=\"text-align: left;\">Use this QIIME command to check mapping file:<\/p>\n<p style=\"text-align: left;\">http:\/\/qiime.org\/1.6.0\/scripts\/check_id_map.html<\/p>"},"is_project":0},{"component_id":"1011220","previous_id":"1011219","original_id":"421884","guid":"0273106AD71E4B318BBF0FE87402DD4C","previous_guid":"FB24872518CB4CE6BDF7993A54A25B27","component_type_id":"6","data_id":null,"data":"Create map file (for use in QIIME)","order_id":"1","name":"Section","data_by_id":"0","type_id":"6","source_data":{"section":"Create map file (for use in QIIME)"},"is_project":0},{"component_id":"1011221","previous_id":"1011220","original_id":"421886","guid":"FCC144072EDA4E9EA4506B598CA68672","previous_guid":"0273106AD71E4B318BBF0FE87402DD4C","component_type_id":"15","data_id":"2308","data":"","order_id":"2","name":"Command","data_by_id":"1","type_id":"15","source_data":{"name":"#! \/usr\/bin\/perl -w\nopen INFILE, \"prefix.txt\";\n@prefix = ();\nwhile (<INFILE>)\n{ chomp;\n  push(@prefix, $_);\n}\nclose INFILE;\n\n#create map file\nfor $i(@prefix)\n{\n   $filename = $i.'_map.txt';\n   open OUTFILE, \">$filename\";\n   print OUTFILE '#',\"SampleID\\tBarcodeSequence\\tLinkerPrimerSequence\\tDescription\\n\";\n   $i =~ s\/_\/\/g;\n   print OUTFILE $i, \"\\tCCAG\\tCASCYGCGGTAATTCC\\t\", $i, \"\\n\";\n   close OUTFILE;\n}\n\n###seqlength_cutoff.pl \n#!\/usr\/bin\/perl\n\nuse warnings;\nuse strict;\nuse Bio::SeqIO;\n\n\nmy $file = $ARGV[0]; \nmy $min = $ARGV[1];\nmy $max = $ARGV[2];\nmy $out = $ARGV[3];\n\nopen (FILE, \">>$out\") or die (\"Error : Cannot open file $out for writing..!\\n\");\n\nmy $seq_in  = Bio::SeqIO->new( -format => 'fasta',-file => $file);\n\nwhile( my $seq1 = $seq_in->next_seq() ) {       \n        \n        my $id  = $seq1->primary_id;\n        chomp $id;\n        my $seq = $seq1->seq;\n        chomp $seq;\n        my $lseq = length($seq);\n        if($lseq>=$min && $lseq <=$max){\n                print FILE \">\",$id,\"\\n\",$seq,\"\\n\";      \n        }\n}","description":"Perl script that creates a map file (QIIME-formatted) based on prefix.txt. Second script to perform sequence length cutoff","os_name":"","os_version":"","can_edit":"1"},"is_project":0},{"component_id":"1011236","previous_id":"1011221","original_id":"0","guid":"D04E1C7B584F419B8056CF483B7789A4","previous_guid":"FCC144072EDA4E9EA4506B598CA68672","component_type_id":"15","data_id":"2313","data":"","order_id":"3","name":"Command","data_by_id":"1","type_id":"15","source_data":{"name":"#Required the prefix.txt file\n.\/create.map.pl","description":"","os_name":"","os_version":"","can_edit":"1"},"is_project":0}]},{"id":"590289","is_changed":"0","original_id":"292180","is_skipped":"0","is_checked":"0","guid":"3A0832AB12374D59AFB837D0A21D68A4","previous_guid":"4891A7B9A04941E8AADC85F739010E0B","previous_id":"590288","last_modified":"1507692291","components":[{"component_id":"1011222","previous_id":0,"original_id":"422493","guid":"23EE62A23D34411FA8C70CD329297015","previous_guid":null,"component_type_id":"1","data_id":null,"data":"<p>Steps of script noted here:<\/p>\n<p>(1) Import prefix file, named 'prefix.txt' and starting loop<\/p>\n<p>(2) Remove primers using Trimmomatic<\/p>\n<p>(3) Merge paired end (R1 and R2) reads with a 20 bp overlap<\/p>\n<p>(4) Perform split library command in QIIME, filter sequences with Q score 30 (-q 29)<\/p>\n<p>(5) Length filter: seqlength_cutoff.pl [input.fasta] [min] [max] [output.fasta]<\/p>\n<p>(6) Chimera check with vsearch (uchime) using a reference database<\/p>\n<p>- You will need to acquire reference database that is best for your sample type. I am using the PR2 database. <a href=\"https:\/\/drive.google.com\/open?id=0Bxzw_UrYS4IAaEQ0b0lMQ0ZiUkU\" target=\"_blank\">You can download a QIIME formatted version here.<\/a><\/p>\n<p>- Alternatively, you can change the command to run vsearch chimera checking de novo. This will take longer.<\/p>\n<p>(7) Repeat and combine QCed reads together<\/p>\n<p>\u00a0<\/p>\n<p>\u00a0<\/p>\n<p>\u00a0<\/p>\n<p>Required components:<\/p>\n<p>- Forward and reverse primer sequences, I'm using V4 Stoeck et al. 2010 primers\u00a0<\/p>\n<p>- reference database<\/p>\n<p>-\u00a0seqlength_cutoff.pl (see script abo)<\/p>","order_id":"0","name":"Description","data_by_id":"0","type_id":"1","source_data":{"description":"<p>Steps of script noted here:<\/p>\n<p>(1) Import prefix file, named 'prefix.txt' and starting loop<\/p>\n<p>(2) Remove primers using Trimmomatic<\/p>\n<p>(3) Merge paired end (R1 and R2) reads with a 20 bp overlap<\/p>\n<p>(4) Perform split library command in QIIME, filter sequences with Q score 30 (-q 29)<\/p>\n<p>(5) Length filter: seqlength_cutoff.pl [input.fasta] [min] [max] [output.fasta]<\/p>\n<p>(6) Chimera check with vsearch (uchime) using a reference database<\/p>\n<p>- You will need to acquire reference database that is best for your sample type. I am using the PR2 database. <a href=\"https:\/\/drive.google.com\/open?id=0Bxzw_UrYS4IAaEQ0b0lMQ0ZiUkU\" target=\"_blank\">You can download a QIIME formatted version here.<\/a><\/p>\n<p>- Alternatively, you can change the command to run vsearch chimera checking de novo. This will take longer.<\/p>\n<p>(7) Repeat and combine QCed reads together<\/p>\n<p>\u00a0<\/p>\n<p>\u00a0<\/p>\n<p>\u00a0<\/p>\n<p>Required components:<\/p>\n<p>- Forward and reverse primer sequences, I'm using V4 Stoeck et al. 2010 primers\u00a0<\/p>\n<p>- reference database<\/p>\n<p>-\u00a0seqlength_cutoff.pl (see script abo)<\/p>"},"is_project":0},{"component_id":"1011223","previous_id":"1011222","original_id":"422480","guid":"97C142D631AE482AA4046BD75F9508D3","previous_guid":"23EE62A23D34411FA8C70CD329297015","component_type_id":"6","data_id":null,"data":"Perl script to QC each fastq file","order_id":"1","name":"Section","data_by_id":"0","type_id":"6","source_data":{"section":"Perl script to QC each fastq file"},"is_project":0},{"component_id":"1011224","previous_id":"1011223","original_id":"487116","guid":"D2D634B770CB41BAB796C152DC0390DA","previous_guid":"97C142D631AE482AA4046BD75F9508D3","component_type_id":"15","data_id":"2309","data":"","order_id":"2","name":"Command","data_by_id":"1","type_id":"15","source_data":{"name":"#! \/usr\/bin\/perl -w\nopen INFILE, \"prefix.txt\";\n@prefix = ();\nwhile (<INFILE>)\n{ chomp;\n  push(@prefix, $_);\n}\nclose INFILE;\n\n\n#Perl script to automate V4 tag sequence QC process\n#last updated 09-29-2017, Sarah K. Hu\n\n\nfor $i(@prefix)\n{\n#(1) Trim primers with trimmomatic\nprint \"java -jar \/usr\/local\/bioinf\/Trimmomatic-0.32\/trimmomatic-0.32.jar PE \",$i,\"_L001_R1_001.fastq \",$i,\"_L001_R2_001.fastq \",$i,\"_trim_R1_PE.fastq \",$i,\"_trim_R1_orphan.fastq \",$i,\"_trim_R2_PE.fastq \",$i,\"_trim_R2_orphan.fastq LEADING:10 TRAILING:10 SLIDINGWINDOW:10:30 MINLEN:50 ILLUMINACLIP:trimPE_V4primer.fasta:2:30:10\\n\";\n\n#(2) Merge paired end (R1 and R2) reads with a 20 bp overlap\nprint \"join_paired_ends.py -f \",$i,\"_trim_R1_PE.fastq -r \",$i,\"_trim_R2_PE.fastq -o out_\",$i,\" -j 20\\n\"; \nprint \"mv out_\",$i,\"\/fastqjoin.join.fastq \",$i,\"_trim_merged.fastq\\n\";\n\n#(3) Perform split library command in QIIME, filter sequences with Q score 30 (-q 29)\nprint \"split_libraries_fastq.py -i \",$i,\"_trim_merged.fastq -m \",$i,\"_map.txt --barcode_type 'not-barcoded' --sample_ids \",$i,\" -q 29 -n 0 -o split_\",$i,\"\\n\";\nprint \"mv split_\",$i,\"\/seqs.fna \",$i,\"_trim_merged_Q30.fasta\\n\";\nprint \"mv split_\",$i,\"\/ out_\",$i,\"\/ \\n\";\n\n#(4) Length filter: seqlength_cutoff.pl [input.fasta] [min] [max] [output.fasta] \nprint \".\/seqlength_cutoff.pl \",$i,\"_trim_merged_Q30.fasta 150 500 \",$i,\"_trim_merged_Q30_len.fasta\\n\";\n\n#(5) Chimera check with vsearch (uchime) using a reference database\nprint \"vsearch --uchime_ref \",$i,\"_trim_merged_Q30_len.fasta --db \/galadriel\/sarah\/PR2\/pr2.qiime.fasta --uchimeout \",$i,\".uchimeinfo_ref --chimeras \",$i,\".chimeras_ref.fasta --strand plus --nonchimeras \",$i,\"_trim_merged_Q30_len_nc.fasta \\n\";\n\n#(9) Move excess files (chimeras) to split directories\nprint \"mv \",$i,\".chimeras_ref.fasta out_\",$i,\"\/ \\n\";\nprint \"mv \",$i,\".uchimeinfo_ref out_\",$i,\"\/ \\n\";\nprint \"mv \",$i,\"*orphan.fastq out_\",$i,\"\/ \\n\";\n\n#(10) Combine all reads together\nprint \"cat \",$i,\"_trim_merged_Q30_len_nc.fasta >> allseqs_test.fasta\\n\";\n\n}\n","description":"Perl script to automate running QC steps on paired end sequences. See step 4 directions for required components and programs.","os_name":"","os_version":"","can_edit":"1"},"is_project":0}]},{"id":"590291","is_changed":"0","original_id":"299324","is_skipped":"0","is_checked":"0","guid":"E6C3F0F3AD4E4B9EB4006FCE64A0EA0B","previous_guid":"3A0832AB12374D59AFB837D0A21D68A4","previous_id":"590289","last_modified":"1507693747","components":[{"component_id":"1011228","previous_id":0,"original_id":"436067","guid":"82BB5DD0215D413D894E6BB36588C844","previous_guid":null,"component_type_id":"1","data_id":null,"data":"<ul>\n<li>Run command below.<\/li>\n<li>Output will generate a fasta file for each step of the QC process.\u00a0This protocol (and my preferred method) is to perform as much quality checking on each individual sample before combining for downstream OTU clustering (or other analysis). This way, I can track any samples that may be not ideal for downstream analysis.<\/li>\n<li><strong>Note: <\/strong>for our lab, I see between 20-50% sequences lost per sample (from raw reads to post-chimera check). As long as the final sequence count is &gt; 10,000 I keep the sample. Our threshold of at least 10,000 sequences (typically more) is very conservative.<\/li>\n<li>Once this is done, you can clean up directory by removing any of these intermediate files.<\/li>\n<li><strong>Explanation of output<\/strong>: After running the count_seqs command (below),\u00a0the output will show you the number of sequences in each step. We started with 800 sequences, initial quality trimming and primer removal\/QC removed almost 200 sequences. Merging and additional QC removed 224 sequences, while length filtration removed no additional sequences. Finally, the chimera checking step only removed 69 sequences. We only kept around 40% of the total sequences.<\/li>\n<\/ul>\n<p>\u00a0<\/p>","order_id":"0","name":"Description","data_by_id":"0","type_id":"1","source_data":{"description":"<ul>\n<li>Run command below.<\/li>\n<li>Output will generate a fasta file for each step of the QC process.\u00a0This protocol (and my preferred method) is to perform as much quality checking on each individual sample before combining for downstream OTU clustering (or other analysis). This way, I can track any samples that may be not ideal for downstream analysis.<\/li>\n<li><strong>Note: <\/strong>for our lab, I see between 20-50% sequences lost per sample (from raw reads to post-chimera check). As long as the final sequence count is &gt; 10,000 I keep the sample. Our threshold of at least 10,000 sequences (typically more) is very conservative.<\/li>\n<li>Once this is done, you can clean up directory by removing any of these intermediate files.<\/li>\n<li><strong>Explanation of output<\/strong>: After running the count_seqs command (below),\u00a0the output will show you the number of sequences in each step. We started with 800 sequences, initial quality trimming and primer removal\/QC removed almost 200 sequences. Merging and additional QC removed 224 sequences, while length filtration removed no additional sequences. Finally, the chimera checking step only removed 69 sequences. We only kept around 40% of the total sequences.<\/li>\n<\/ul>\n<p>\u00a0<\/p>"},"is_project":0},{"component_id":"1011229","previous_id":"1011228","original_id":"436048","guid":"415724A65A3C43529920C282CF3DF040","previous_guid":"82BB5DD0215D413D894E6BB36588C844","component_type_id":"6","data_id":null,"data":"Check all steps","order_id":"1","name":"Section","data_by_id":"0","type_id":"6","source_data":{"section":"Check all steps"},"is_project":0},{"component_id":"1011230","previous_id":"1011229","original_id":"436063","guid":"E3B28A415E2B411D83174CE1525AAE0C","previous_guid":"415724A65A3C43529920C282CF3DF040","component_type_id":"15","data_id":"2311","data":"","order_id":"2","name":"Command","data_by_id":"1","type_id":"15","source_data":{"name":"count_seqs.py -i Test01_L001_R1_001.fastq,Test01_L001_R2_001.fastq,Test01_trim_R1_PE.fastq,Test01_trim_R2_PE.fastq,Test01_trim_merged.fastq,Test01_trim_merged_Q30.fasta,Test01_trim_merged_Q30_len.fasta,Test01_trim_merged_Q30_len_nc.fasta\n","description":"Example QIIME command to check number of sequences.","os_name":"","os_version":"","can_edit":"1"},"is_project":0}]},{"id":"590292","is_changed":"0","original_id":"299425","is_skipped":"0","is_checked":"0","guid":"67AF82DC940D46C78C137649107AB5E5","previous_guid":"E6C3F0F3AD4E4B9EB4006FCE64A0EA0B","previous_id":"590291","last_modified":"1507692491","components":[{"component_id":"1011231","previous_id":0,"original_id":"436319","guid":"4B0B2749099E4FECB57CD75F3F29E2A7","previous_guid":null,"component_type_id":"1","data_id":null,"data":"<p>Depending on the questions you want to ask your data, decide about what type of OTU clustering you want to do (both algorithm and percent similarity).<\/p>\n<p>\u00a0<\/p>\n<p>QIIME is a great resource\u00a0for tutorials on OTU clustering -\u00a0http:\/\/qiime.org\/tutorials\/otu_picking.html#running-the-otu-picking-workflows<\/p>","order_id":"0","name":"Description","data_by_id":"0","type_id":"1","source_data":{"description":"<p>Depending on the questions you want to ask your data, decide about what type of OTU clustering you want to do (both algorithm and percent similarity).<\/p>\n<p>\u00a0<\/p>\n<p>QIIME is a great resource\u00a0for tutorials on OTU clustering -\u00a0http:\/\/qiime.org\/tutorials\/otu_picking.html#running-the-otu-picking-workflows<\/p>"},"is_project":0},{"component_id":"1011232","previous_id":"1011231","original_id":"436314","guid":"507FF9A7E65646DDA702C071ACBAB47C","previous_guid":"4B0B2749099E4FECB57CD75F3F29E2A7","component_type_id":"6","data_id":null,"data":"OTU-clustering","order_id":"1","name":"Section","data_by_id":"0","type_id":"6","source_data":{"section":"OTU-clustering"},"is_project":0},{"component_id":"1011237","previous_id":"1011232","original_id":"0","guid":"3B1D3B7D8D1949F5B859E39970C1F45E","previous_guid":"507FF9A7E65646DDA702C071ACBAB47C","component_type_id":"15","data_id":"2314","data":"","order_id":"2","name":"Command","data_by_id":"1","type_id":"15","source_data":{"name":"#OTU clustering with uclust, will make a new directory (pick_open)\npick_open_reference_otus.py -i allseqs_test.fasta -o pick_open -m uclust -r \/galadriel\/sarah\/PR2\/pr2.qiime.fasta --suppress_step4 --suppress_taxonomy_assignment\ncd pick_open\n#assign taxonomy using PR2 database, creates a new directory (uclust_taxonomy)\nassign_taxonomy.py -i rep_set.fna -t \/galadriel\/db\/PR2\/ids.names.2.txt -r \/galadriel\/db\/PR2\/pr2.qiime.fasta -m uclust -o uclust_taxonomy\n#make an OTU table, and convert to txt\nmake_otu_table.py -i final_otu_map.txt -o V4_tagseq_test.biom -t uclust_taxonomy\/rep_set_tax_assignments.txt \nbiom convert -i V4_tagseq_test.biom -o V4_tagseq_test.txt --to-tsv --header-key=taxonomy","description":"","os_name":"","os_version":"","can_edit":"1"},"is_project":0}]},{"id":"590293","is_changed":"0","original_id":"584050","is_skipped":"0","is_checked":"0","guid":"5364DEBADD5E46B497AC08D0187649BD","previous_guid":"67AF82DC940D46C78C137649107AB5E5","previous_id":"590292","last_modified":"1507690903","components":[{"component_id":"1011233","previous_id":0,"original_id":"996322","guid":"8C91CD70D7AB48C59ED557806D230D67","previous_guid":null,"component_type_id":"6","data_id":null,"data":"Analysis","order_id":"0","name":"Section","data_by_id":"0","type_id":"6","source_data":{"section":"Analysis"},"is_project":0},{"component_id":"1011234","previous_id":"1011233","original_id":"996321","guid":"59C5DF613FE84E2FB81D426411A1FB68","previous_guid":"8C91CD70D7AB48C59ED557806D230D67","component_type_id":"1","data_id":null,"data":"<p>For examples of preliminary analyses and figure generation in R see: https:\/\/github.com\/shu251\/PreliminaryFigures_V4_tagseq<\/p>\n<p>\u00a0<\/p>\n<p>\u00a0<\/p>","order_id":"1","name":"Description","data_by_id":"0","type_id":"1","source_data":{"description":"<p>For examples of preliminary analyses and figure generation in R see: https:\/\/github.com\/shu251\/PreliminaryFigures_V4_tagseq<\/p>\n<p>\u00a0<\/p>\n<p>\u00a0<\/p>"},"is_project":0}]}]}