{"uri":"microbial-eukaryotic-18s-tag-sequence-processing-q-j5acq2e","version_id":"1","protocol_name":"Microbial eukaryotic 18S tag-sequence processing\/QC - V4 region (automating)","protocol_name_html":"Microbial eukaryotic 18S tag-sequence processing\/QC - V4 region (automating)","is_prepublished":"0","can_edit":"0","parent_id":"0","api_version":"1","is_new_mode":"0","last_modified":"1514578347","type_id":"1","link":"https:\/\/github.com\/shu251\/QC_steps_V4_tagsequencing","fork_id":"","public_fork_note":"","number_of_steps":"9","has_versions":"1","first_published_date":"1506799610","publish_date":"2017-09-30 19:26:50","documents":null,"have_protocol_in_step":"0","is_protocol_in_step":"0","vendor_name":"Contributed by users","vendor_link":"https:\/\/www.protocols.io","vendor_logo":"\/img\/vendors\/1.png","mod_mins":"-45","mod_secs":"1","description":"<p>This protocol provides step-by-step instructions for implementing a perl script to easily automate quality checking of raw tag sequences. This was specifically constructed for the numerous 18S diversity projects (which target the V4 hypervariable specific for evaluting protistan diversity).<\/p>\n<p>\u00a0<\/p>\n<p>It is highly recommended that you follow along this Github repo:\u00a0https:\/\/github.com\/shu251\/QC_steps_V4_tagsequencing<\/p>\n<p>\u00a0<\/p>\n<p>Last updated Sept 30th, 2017<\/p>\n<p>\u00a0<\/p>","is_bookmarked":"0","can_reassign":"1","before_start":"<p>See\u00a0https:\/\/github.com\/shu251\/QC_steps_V4_tagsequencing<\/p>\n<p>\u00a0<\/p>\n<p>Programs\/files required:<\/p>\n<p>* Database (preferrably with associated taxa list) to align sequences to. A version of the PR2 database formatted for QIIME can be found [here](https:\/\/drive.google.com\/drive\/folders\/0Bxzw_UrYS4IAaEQ0b0lMQ0ZiUkU?usp=sharing)<br \/>* [QIIME](http:\/\/qiime.org\/install\/install.html) - v.1.9.1 or higher. Note as of Jan 2018 QIIME1 will not be supported. Future iterations of this protocol will use QIIME2.<br \/>* fastqjoin - this should install with QIIME. Alternatively you can use [PEAR](https:\/\/sco.h-its.org\/exelixis\/web\/software\/pear\/doc.html#installing) to merge PE sequences.<br \/>* [Trimmomatic](http:\/\/www.usadellab.org\/cms\/?page=trimmomatic) - v.0.32<br \/>* [vsearch](https:\/\/github.com\/torognes\/vsearch) - v1.11.1<br \/>* abyss (optional) - see step 9<br \/>* Make sure you know your primer sequences and generate a fasta file: 'trimPE_V4primer.fasta'. In the below example I'm using [V4 Stoeck et al. 2010 primers](http:\/\/onlinelibrary.wiley.com.libproxy1.usc.edu\/doi\/10.1111\/j.1365-294X.2009.04480.x\/full\/) <br \/>* Create a \"prefix.txt\" file to index sample fastq files.<br \/>* Run 'create.map.pl'<\/p>","has_guidelines":"0","materials":[],"warning":"","version_class":"8066","public":"1","is_owner":"1","is_original_owner":"1","created_on":"1506797009","protocol_affiliation":"University of Southern California","affiliation":"protocols.io","doi":"dx.doi.org\/10.17504\/protocols.io.j5acq2e","doi_status":"2","changed_fork_steps":null,"profile_url":"VladimirFrolov-03v2a4w2","protocol_img":"https:\/\/www.protocols.io\/img\/default_protocol.png","profile_image":"https:\/\/s3.amazonaws.com\/pr-journal\/djqbjf6.jpg","full_name":"Vladimir Frolov","created_by":"Vladimir Frolov","private_link":"693CE12DFEB98A7C747A64D30E08ABEE","original_img":"1","username":"vladimir-frolov16","is_retracted":"1","retraction_reason":"This protocol was for testing purposes only","plos_id":null,"manuscript_citation":"<div title=\"Page 2\">\n<div>\n<div>\n<p>Sarah K. Hu, Victoria Campbell, Paige Connell, Alyssa Gellene, Zhenfeng Liu, Ramon Terrado, &amp; David A. Caron. Protistan diversity and activity inferred from RNA and DNA at a coastal ocean site in the eastern North Pacific. (2016). FEMS Microbiol Ecol. 92(4) doi: 10.1093\/femsec\/fiw050.<\/p>\n<p>\u00a0<\/p>\n<p>Sarah K. Hu, Zhenfeng Liu, Alle A. Y. Lie, Peter D. Countway, Diane Y. Kim, Adriane C. Jones, Rebecca J. Gast, S. Craig Cary, Evelyn B. Sherr, Barry F. Sherr, &amp; David A. Caron. (2015). Estimating Protistan Diversity using High-throughput Sequencing. J Eukaryot Microbiol. 62(5): 688-693.<\/p>\n<\/div>\n<\/div>\n<\/div>","journal_name":null,"is_donations_disabled":"0","is_donations_disabled_by_user":"9","item_record_id":0,"fork_info":[],"compare_forks":[],"protocols":[],"groups":[{"group_id":"108","group_uri":"protg","group_name":"Protist Research to Optimize Tools in Genetics (PROT-G)","group_logo":"https:\/\/s3.amazonaws.com\/pr-journal\/e3addmn.png","requested_uid":null,"request_flag":null,"my_request":"1"},{"group_id":"165","group_uri":"caron-lab-protistan-ecology","group_name":"Caron Lab - Protistan Ecology","group_logo":"https:\/\/s3.amazonaws.com\/pr-journal\/pbmdv2e.jpg","requested_uid":null,"request_flag":null,"my_request":"1"},{"group_id":"293","group_uri":"scope","group_name":"SCOPE","group_logo":"https:\/\/s3.amazonaws.com\/pr-journal\/g7rff3w.jpg","requested_uid":null,"request_flag":null,"my_request":"1"}],"number_of_shared_runs":[],"ownership_history":[],"keywords":"","transfer_to_user":[],"sub_transfer":false,"is_transfer_pending":false,"number_of_bookmarks":"0","collections":[],"tags":[{"tag_id":"854","tag_name":"18S rRNA gene"},{"tag_id":"855","tag_name":" Protistan diversity"},{"tag_id":"856","tag_name":" microbial eukaryotes"},{"tag_id":"857","tag_name":" microbial ecology"},{"tag_id":"858","tag_name":" tag sequencing"}],"archived":0,"sub_authors":[],"sub_protocols_number":0,"can_edit_shared":0,"shared_runs":[],"is_shared_run":0,"is_shared":1,"banner":null,"contact_badges":[{"badge_id":"5","badge_image":"\/img\/badges\/earlyadopter.svg","badge_description":"Early adopter"},{"badge_id":"6","badge_image":"\/img\/badges\/socialbutterfly.svg","badge_description":"Social butterfly"}],"number_of_comments":0,"is_locked":0,"is_locked_by":false,"authors":"Sarah  Hu","authors_list":[{"name":"Sarah  Hu","affiliation":"University of Southern California","username":"sarah-hu","profile_image":"https:\/\/s3.amazonaws.com\/pr-journal\/i9rdv2e.jpg"}],"user":{"profile_image":"https:\/\/s3.amazonaws.com\/pr-journal\/djqbjf6.jpg","username":"vladimir-frolov16","full_name":"Vladimir Frolov","created_by":"Vladimir Frolov"},"access":{"can_view":null,"can_remove":null,"can_add":null,"can_edit":0,"can_publish":0,"can_get_doi":0,"can_share":null,"can_move":null,"can_transfer":null,"can_download":null,"is_locked":null},"is_contact_suspended":0,"guidelines":"","status_id":"1","is_research":"1","status_info":null,"steps":[{"id":"589141","is_changed":"0","original_id":"291959","is_skipped":"0","is_checked":"0","guid":"4D9399FF213542D79DDDF1F09544AB2E","previous_guid":"45B424351479482F8A1570C5C91C747B","previous_id":"589148","last_modified":"1506797643","components":[{"component_id":"1008631","previous_id":0,"original_id":"421883","guid":"472FE88C78BF4242AC6BDA51093A06EC","previous_guid":null,"component_type_id":"1","data_id":null,"data":"<p>Input raw fastq files that are already demultiplexed.<\/p>\n<p>\u00a0<\/p>\n<p>This tutorial uses V4 primers (Stoeck et al. 2010) for microbial eukaryotes<\/p>\n<p>\u00a0<\/p>\n<p>First create\u00a0a text file with a list of file prefixes (prefix.txt). Example:<\/p>\n<p>\u00a0<\/p>\n<p>File lists:<\/p>\n<p>Test01_L001_R1_001.fastq<\/p>\n<p>Test01_L001_R2_001.fastq<\/p>\n<p>Test02_L001_R1_001.fastq<\/p>\n<p>Test02_L001_R2_001.fastq<\/p>\n<p>\u00a0<\/p>\n<p>Associated prefixes:<\/p>\n<p>Test01<\/p>\n<p>Test02<\/p>\n<p>\u00a0<\/p>","order_id":"0","name":"Description","data_by_id":"0","type_id":"1","source_data":{"description":"<p>Input raw fastq files that are already demultiplexed.<\/p>\n<p>\u00a0<\/p>\n<p>This tutorial uses V4 primers (Stoeck et al. 2010) for microbial eukaryotes<\/p>\n<p>\u00a0<\/p>\n<p>First create\u00a0a text file with a list of file prefixes (prefix.txt). Example:<\/p>\n<p>\u00a0<\/p>\n<p>File lists:<\/p>\n<p>Test01_L001_R1_001.fastq<\/p>\n<p>Test01_L001_R2_001.fastq<\/p>\n<p>Test02_L001_R1_001.fastq<\/p>\n<p>Test02_L001_R2_001.fastq<\/p>\n<p>\u00a0<\/p>\n<p>Associated prefixes:<\/p>\n<p>Test01<\/p>\n<p>Test02<\/p>\n<p>\u00a0<\/p>"},"is_project":0},{"component_id":"1008632","previous_id":"1008631","original_id":"421882","guid":"F241A62B76D54CFF96B4206D859DD480","previous_guid":"472FE88C78BF4242AC6BDA51093A06EC","component_type_id":"6","data_id":null,"data":"Pre-processing","order_id":"1","name":"Section","data_by_id":"0","type_id":"6","source_data":{"section":"Pre-processing"},"is_project":0},{"component_id":"1008633","previous_id":"1008632","original_id":"996313","guid":"D65C50B1413846C29D1EAF314FEB5393","previous_guid":"F241A62B76D54CFF96B4206D859DD480","component_type_id":"7","data_id":"1548","data":"https:\/\/github.com\/shu251\/QC_steps_V4_tagsequencing","order_id":"2","name":"External Link","data_by_id":"1","type_id":"7","source_data":{"link":"https:\/\/github.com\/shu251\/QC_steps_V4_tagsequencing"},"is_project":0}]},{"id":"589142","is_changed":"0","original_id":"291960","is_skipped":"0","is_checked":"0","guid":"86CEB279C3BF4B2096673CB42B35F63A","previous_guid":"4D9399FF213542D79DDDF1F09544AB2E","previous_id":"589141","last_modified":"1506797868","components":[{"component_id":"1008634","previous_id":0,"original_id":"421885","guid":"107CB62A1E95408B8B06B0D1FC92D793","previous_guid":null,"component_type_id":"1","data_id":null,"data":"<p style=\"text-align: left;\">Map files in QIIME serve to de-multiplex reads (based on barcodes and indices) and are used in 'split_library' QIIME step. Here, I've split up the V4 forward primer to fulfill the necessary barcode \/ index space required in the QIIME mapping file. However, we aren't using this feature of the mapping file.\u00a0<\/p>\n<p style=\"text-align: left;\">\u00a0<\/p>\n<p style=\"text-align: left;\">Use this QIIME command to check mapping file:<\/p>\n<p style=\"text-align: left;\">http:\/\/qiime.org\/1.6.0\/scripts\/check_id_map.html<\/p>\n<p style=\"text-align: left;\">\u00a0<\/p>\n<p style=\"text-align: left;\">Run create.map.pl script to generate map files based on your prefix file list.<\/p>\n<p style=\"text-align: left;\">\u00a0<\/p>","order_id":"0","name":"Description","data_by_id":"0","type_id":"1","source_data":{"description":"<p style=\"text-align: left;\">Map files in QIIME serve to de-multiplex reads (based on barcodes and indices) and are used in 'split_library' QIIME step. Here, I've split up the V4 forward primer to fulfill the necessary barcode \/ index space required in the QIIME mapping file. However, we aren't using this feature of the mapping file.\u00a0<\/p>\n<p style=\"text-align: left;\">\u00a0<\/p>\n<p style=\"text-align: left;\">Use this QIIME command to check mapping file:<\/p>\n<p style=\"text-align: left;\">http:\/\/qiime.org\/1.6.0\/scripts\/check_id_map.html<\/p>\n<p style=\"text-align: left;\">\u00a0<\/p>\n<p style=\"text-align: left;\">Run create.map.pl script to generate map files based on your prefix file list.<\/p>\n<p style=\"text-align: left;\">\u00a0<\/p>"},"is_project":0},{"component_id":"1008635","previous_id":"1008634","original_id":"421884","guid":"95908F9287554CE6AF17E813C929E41A","previous_guid":"107CB62A1E95408B8B06B0D1FC92D793","component_type_id":"6","data_id":null,"data":"Create map file (for use in QIIME)","order_id":"1","name":"Section","data_by_id":"0","type_id":"6","source_data":{"section":"Create map file (for use in QIIME)"},"is_project":0},{"component_id":"1008653","previous_id":"1008635","original_id":"0","guid":"F0F98E79840C4EE0846944B9971F4971","previous_guid":"95908F9287554CE6AF17E813C929E41A","component_type_id":"15","data_id":"2262","data":"","order_id":"2","name":"Command","data_by_id":"1","type_id":"15","source_data":{"name":".\/create.map.pl","description":"","os_name":"","os_version":"","can_edit":"0"},"is_project":0},{"component_id":"1008657","previous_id":"1008653","original_id":"0","guid":"28B863CEA3BC4D1083830CDD6B9423C3","previous_guid":"F0F98E79840C4EE0846944B9971F4971","component_type_id":"15","data_id":"2264","data":"","order_id":"3","name":"Command","data_by_id":"1","type_id":"15","source_data":{"name":"#!\/usr\/bin\/perl -w\nopen INFILE, \"prefix.txt\";\n@prefix = ();\nwhile (<INFILE>)\n{ chomp;\n  push(@prefix, $_);\n}\nclose INFILE;\n\n#create map file\n#specific only for V4 primers, Stoeck et al.\n\nfor $i(@prefix)\n{\n   $filename = $i.'_map.txt';\n   open OUTFILE, \">$filename\";\n   print OUTFILE '#',\"SampleID\\tBarcodeSequence\\tLinkerPrimerSequence\\tDescription\\n\";\n   $i =~ s\/_\/\/g;\n   print OUTFILE $i, \"\\tCCAG\\tCASCYGCGGTAATTCC\\t\", $i, \"\\n\";\n   close OUTFILE;\n}\n","description":"Contents of create.map.pl\n","os_name":"","os_version":"","can_edit":"0"},"is_project":0}]},{"id":"589143","is_changed":"0","original_id":"292180","is_skipped":"0","is_checked":"0","guid":"BE31A1512EDC4589BDD3BF1CEE148724","previous_guid":"2EDFE07A11BC4796865F1D15BBE5D467","previous_id":"589149","last_modified":"1506797952","components":[{"component_id":"1008637","previous_id":0,"original_id":"422493","guid":"C200A199023645FD908A75F8A76E18F7","previous_guid":null,"component_type_id":"1","data_id":null,"data":"<p>Steps of script noted here:<\/p>\n<p>(1) Import prefix file, named 'prefix.txt' and starting loop<\/p>\n<p>(2) Run Trimmomatic to clip primers (see\u00a0<\/p>\n<p>(2) Merge paired end (R1 and R2) reads with a 20 bp overlap<\/p>\n<p>(3) Perform split library command in QIIME, filter sequences with Q score 30 (-q 29)<\/p>\n<p>(4) Clip primers. Allows sequences to have either forward or reverse primers\u00a0<\/p>\n<p>Note I am using Stoeck et al. 2010 V4 primers specifically for microbial eukaryotes<\/p>\n<p>(5) Combine clipped sequences<\/p>\n<p>(6) Move excess files to 'split_*' directories which were created during the split library step<\/p>\n<p>(7) Length filter: seqlength_cutoff.pl [input.fasta] [min] [max] [output.fasta]<\/p>\n<p>(8) Chimera check with vsearch (uchime) using a reference database<\/p>\n<p>\u00a0- You will need to acquire reference database that is best for your sample type. I am using the PR2 database. Alternatively, you can change the command to run vsearch chimera checking de novo. This will take longer.<\/p>\n<p>(9) Move excess files (chimeras) to split directories<\/p>\n<p>(10) Combine all reads together<\/p>\n<p>\u00a0<\/p>\n<p>Required programs:<\/p>\n<p>- QIIME<\/p>\n<p>- cutadapt<\/p>\n<p>- vsearch<\/p>\n<p>\u00a0<\/p>\n<p>Required components:<\/p>\n<p>- Forward and reverse primer sequences, I'm using V4 Stoeck et al. 2010 primers\u00a0<\/p>\n<p>- reference database<\/p>\n<p>-\u00a0seqlength_cutoff.pl (see script abo)<\/p>","order_id":"0","name":"Description","data_by_id":"0","type_id":"1","source_data":{"description":"<p>Steps of script noted here:<\/p>\n<p>(1) Import prefix file, named 'prefix.txt' and starting loop<\/p>\n<p>(2) Run Trimmomatic to clip primers (see\u00a0<\/p>\n<p>(2) Merge paired end (R1 and R2) reads with a 20 bp overlap<\/p>\n<p>(3) Perform split library command in QIIME, filter sequences with Q score 30 (-q 29)<\/p>\n<p>(4) Clip primers. Allows sequences to have either forward or reverse primers\u00a0<\/p>\n<p>Note I am using Stoeck et al. 2010 V4 primers specifically for microbial eukaryotes<\/p>\n<p>(5) Combine clipped sequences<\/p>\n<p>(6) Move excess files to 'split_*' directories which were created during the split library step<\/p>\n<p>(7) Length filter: seqlength_cutoff.pl [input.fasta] [min] [max] [output.fasta]<\/p>\n<p>(8) Chimera check with vsearch (uchime) using a reference database<\/p>\n<p>\u00a0- You will need to acquire reference database that is best for your sample type. I am using the PR2 database. Alternatively, you can change the command to run vsearch chimera checking de novo. This will take longer.<\/p>\n<p>(9) Move excess files (chimeras) to split directories<\/p>\n<p>(10) Combine all reads together<\/p>\n<p>\u00a0<\/p>\n<p>Required programs:<\/p>\n<p>- QIIME<\/p>\n<p>- cutadapt<\/p>\n<p>- vsearch<\/p>\n<p>\u00a0<\/p>\n<p>Required components:<\/p>\n<p>- Forward and reverse primer sequences, I'm using V4 Stoeck et al. 2010 primers\u00a0<\/p>\n<p>- reference database<\/p>\n<p>-\u00a0seqlength_cutoff.pl (see script abo)<\/p>"},"is_project":0},{"component_id":"1008638","previous_id":"1008637","original_id":"422480","guid":"7A7A68F7004144A2980DFC674BFB877C","previous_guid":"C200A199023645FD908A75F8A76E18F7","component_type_id":"6","data_id":null,"data":"Perl script to QC each fastq file","order_id":"1","name":"Section","data_by_id":"0","type_id":"6","source_data":{"section":"Perl script to QC each fastq file"},"is_project":0},{"component_id":"1008639","previous_id":"1008638","original_id":"487116","guid":"A199E4DA94ED48549A7754F3E5AE0F00","previous_guid":"7A7A68F7004144A2980DFC674BFB877C","component_type_id":"15","data_id":"2258","data":"","order_id":"2","name":"Command","data_by_id":"1","type_id":"15","source_data":{"name":"#! \/usr\/bin\/perl -w\nopen INFILE, \"prefix.txt\";\n@prefix = ();\nwhile (<INFILE>)\n{ chomp;\n  push(@prefix, $_);\n}\nclose INFILE;\n#(1) Import prefix file, named \"prefix.txt\" and starting loop\n\nfor $i(@prefix)\n{\n#(2) Merge paired end (R1 and R2) reads with a 20 bp overlap\nprint \"join_paired_ends.py -f \",$i,\"_L001_R1_001.fastq -r \",$i,\"_L001_R2_001.fastq -o joined_\",$i,\" -j 20\\n\"; \nprint \"mv joined_\",$i,\"\/fastqjoin.join.fastq \",$i,\"_merged.fastq\\n\";\n\n#(3) Perform split library command in QIIME, filter sequences with Q score 30 (-q 29)\nprint \"split_libraries_fastq.py -i \",$i,\"_merged.fastq -m \",$i,\"_map.txt --barcode_type 'not-barcoded' --sample_ids \",$i,\" -q 29 -n 0 -o split_\",$i,\"\\n\";\nprint \"mv split_\",$i,\"\/seqs.fna \",$i,\".merged.Q30.fasta\\n\";\n\n#(4) Clip primers. Allows sequences to have either forward or reverse primers \n#(4.1) Searches for forward primer, discard seqs without those primers\nprint \"cutadapt -g CCAGCASCYGCGGTAATTCC -O 3 --discard-untrimmed -m 10 -o \",$i,\".assembled.clipped.regF.fasta \",$i,\".merged.Q30.fasta >> \",$i,\".filter.log\\n\";\n\n#Name discarded reads from 4.1 \"discard_regF.fasta\"\nprint \"cutadapt -g CCAGCASCYGCGGTAATTCC -O 3 --untrimmed-output discard_regF.fasta -m 10 -o tmp.fasta \",$i,\".merged.Q30.fasta >> \",$i,\".filter.log\\n\";\nprint \"rm tmp.fasta\\n\"; #remove tmp (which is a duplicate)\n#4.2 Check discarded for reverse primer\nprint \"cutadapt -a TYRATCAAGAACGAAAGT -O 3 --discard-untrimmed -m 10 -o \",$i,\".assembled.clipped.regR.fasta discard_regF.fasta>> \",$i,\".filter.log\\n\";\n\n#(5) Combine clipped sequences\nprint \"cat \",$i,\".assembled.clipped.regF.fasta \",$i,\".assembled.clipped.regR.fasta >> \",$i,\".assembled.clipped.fasta\\n\"; \n\n#(6) Move excess files to \"split_*\" directories which were created during the split library step\nprint \"mv \",$i,\"*reg* split_\",$i,\"\/\\n\"; #move excess files from trimming to split file\nprint \"mv \",$i,\".filter.log split_\",$i,\"\/\\n\";\n\n# (7) Length filter: seqlength_cutoff.pl [input.fasta] [min] [max] [output.fasta] \nprint \"seqlength_cutoff.pl \",$i,\".assembled.clipped.fasta 150 500 \",$i,\".assembled.clipped.len.fasta\\n\";\n\n#(8) Chimera check with vsearch (uchime) using a reference database\nprint \"vsearch --uchime_ref \",$i,\".assembled.clipped.len.fasta --db \/galadriel\/sarah\/PR2\/pr2.qiime.fasta --uchimeout \",$i,\".uchimeinfo_ref --chimeras \",$i,\".chimeras_ref.fasta --strand plus --nonchimeras \",$i,\".assembled.clipped.len.nc.final.fasta \\n\";\n\n#(9) Move excess files (chimeras) to split directories\nprint \"mv \",$i,\".chimeras_ref.fasta split_\",$i,\"\/\\n\"; #move excess chimera files to split dir\nprint \"mv \",$i,\".uchimeinfo_ref split_\",$i,\"\/\\n\";\n\n#(10) Combine all reads together\nprint \"cat \",$i,\".assembled.clipped.len.nc.final.fasta >> allseqs_test.fasta\\n\";\n\n}","description":"Perl script to automate running QC steps on paired end sequences. See step 4 directions for required components and programs.","os_name":"","os_version":"","can_edit":"0"},"is_project":0}]},{"id":"589144","is_changed":"0","original_id":"296084","is_skipped":"0","is_checked":"0","guid":"7C6FE5B4EF7142EE94B73629B7663851","previous_guid":"BE31A1512EDC4589BDD3BF1CEE148724","previous_id":"589143","last_modified":"1506797010","components":[{"component_id":"1008640","previous_id":0,"original_id":"433144","guid":"22E8E6B2012443068A08C3C90364EE53","previous_guid":null,"component_type_id":"1","data_id":null,"data":"<p>Product from previous script is a bunch of intermediate sequence files and the final product with all sequences combined \"allseqs_test.fasta\" in this case.<\/p>\n<p>Here, run these commands to get simple stats on each intermediate step. It is important to make sure a large percentage of sequences was not lost at a certain step - this can be indicative of processing or sequencing error. For example, if most of my samples lost &gt;50% of their sequences following the \"split_library\" command (step 3 above), I would consider reducing the Q score threshold to something less conservative (perhaps 25?). In another example, if all of the sequences were removed (or &gt;90%) during the sequence length cut off (step 7), this sample should be re-sequenced or thrown out.<\/p>","order_id":"0","name":"Description","data_by_id":"0","type_id":"1","source_data":{"description":"<p>Product from previous script is a bunch of intermediate sequence files and the final product with all sequences combined \"allseqs_test.fasta\" in this case.<\/p>\n<p>Here, run these commands to get simple stats on each intermediate step. It is important to make sure a large percentage of sequences was not lost at a certain step - this can be indicative of processing or sequencing error. For example, if most of my samples lost &gt;50% of their sequences following the \"split_library\" command (step 3 above), I would consider reducing the Q score threshold to something less conservative (perhaps 25?). In another example, if all of the sequences were removed (or &gt;90%) during the sequence length cut off (step 7), this sample should be re-sequenced or thrown out.<\/p>"},"is_project":0},{"component_id":"1008641","previous_id":"1008640","original_id":"429356","guid":"5D3A70DA53D147C7A5DE6904430C1BCF","previous_guid":"22E8E6B2012443068A08C3C90364EE53","component_type_id":"6","data_id":null,"data":"Check all steps","order_id":"1","name":"Section","data_by_id":"0","type_id":"6","source_data":{"section":"Check all steps"},"is_project":0},{"component_id":"1008642","previous_id":"1008641","original_id":"436034","guid":"F22D0DE142CF4CC790C3F8E89F908F1F","previous_guid":"5D3A70DA53D147C7A5DE6904430C1BCF","component_type_id":"15","data_id":"2259","data":"","order_id":"2","name":"Command","data_by_id":"1","type_id":"15","source_data":{"name":"abyss-fac -s 0 *_merged.fastq >>stats_merged.txt\nabyss-fac -s 0 *.merged.Q30.fasta >> stats_Q30.txt\nabyss-fac -s 0 *.assembled.clipped.fasta >> stats_primerclipped.txt\nabyss-fac -s 0 *.assembled.clipped.len.fasta >> stats_length_cutoff.txt\nabyss-fac -s 0 *.assembled.clipped.len.nc.final.fasta >> stats_chimeras.txt","description":"","os_name":"","os_version":"","can_edit":"0"},"is_project":0}]},{"id":"589145","is_changed":"0","original_id":"299324","is_skipped":"0","is_checked":"0","guid":"7A833E75AC0B4512B6D0F1C6C04DFE83","previous_guid":"7C6FE5B4EF7142EE94B73629B7663851","previous_id":"589144","last_modified":"1506797010","components":[{"component_id":"1008643","previous_id":0,"original_id":"436067","guid":"6A9C47D12561414F801486B61311E75E","previous_guid":null,"component_type_id":"1","data_id":null,"data":"<p>R script to compile all of the .txt files made in previous step.\u00a0<\/p>\n<p>\u00a0<\/p>\n<p>Again, do a final check of all samples to make sure the QC was appropriate. For our lab, I see between 20-50% sequences lost per sample (from raw reads to post-chimera check). As long as the final sequence count is &gt; 10,000 I keep the sample. Our threshold of at least 10,000 sequences (typically more) is very conservative.<\/p>\n<p>\u00a0<\/p>\n<p>Once this is done, you can clean up directory by removing any of these intermediate files.<\/p>","order_id":"0","name":"Description","data_by_id":"0","type_id":"1","source_data":{"description":"<p>R script to compile all of the .txt files made in previous step.\u00a0<\/p>\n<p>\u00a0<\/p>\n<p>Again, do a final check of all samples to make sure the QC was appropriate. For our lab, I see between 20-50% sequences lost per sample (from raw reads to post-chimera check). As long as the final sequence count is &gt; 10,000 I keep the sample. Our threshold of at least 10,000 sequences (typically more) is very conservative.<\/p>\n<p>\u00a0<\/p>\n<p>Once this is done, you can clean up directory by removing any of these intermediate files.<\/p>"},"is_project":0},{"component_id":"1008644","previous_id":"1008643","original_id":"436048","guid":"E5DA47D5A7594C049D5917FDA77CA7B2","previous_guid":"6A9C47D12561414F801486B61311E75E","component_type_id":"6","data_id":null,"data":"Check all steps","order_id":"1","name":"Section","data_by_id":"0","type_id":"6","source_data":{"section":"Check all steps"},"is_project":0},{"component_id":"1008645","previous_id":"1008644","original_id":"436063","guid":"6A071C7EE5734A8288B814B343C29964","previous_guid":"E5DA47D5A7594C049D5917FDA77CA7B2","component_type_id":"15","data_id":"2260","data":"","order_id":"2","name":"Command","data_by_id":"1","type_id":"15","source_data":{"name":"#Run R:\nstats<-c(\"stats_merged.txt\", \"stats_Q30.txt\", \"stats_primerclipped.txt\", \"stats_length_cutoff.txt\", \"stats_chimeras.txt\")\n\nfor (file in stats){\n  if (!exists(\"dataset\")){\n    dataset<-read.delim(file, header=TRUE, sep=\"\\t\",row.names=NULL)\n    dataset<-dataset[c(2,4,8,10)]\n    colnames(dataset)[1:4]<-c(file,\"Min (bp)\", \"Max (bp)\", \"File name\")\n  }\n  if (exists(\"dataset\")){\n    tmpdata<-read.delim(file, header=TRUE, sep=\"\\t\",row.names=NULL)\n    tmpdata<-tmpdata[c(2,4,8,10)]\n    colnames(tmpdata)[1:4]<-c(file,\"Min (bp)\", \"Max (bp)\", \"File name\")\n    dataset<-cbind(dataset, tmpdata)\n    rm(tmpdata)\n  }\n}\nhead(dataset)\nwrite.csv(dataset, file=\"Seq_stats_QC.csv\")","description":"Run R script to compile a QC datasheet","os_name":"","os_version":"","can_edit":"0"},"is_project":0}]},{"id":"589146","is_changed":"0","original_id":"299425","is_skipped":"0","is_checked":"0","guid":"BD148233C2F5478CAB9365C2BE54F7C5","previous_guid":"7A833E75AC0B4512B6D0F1C6C04DFE83","previous_id":"589145","last_modified":"1506797010","components":[{"component_id":"1008646","previous_id":0,"original_id":"436319","guid":"094F58EB7D9745FBA8A3E8B21681DDD9","previous_guid":null,"component_type_id":"1","data_id":null,"data":"<p>Depending on the questions you want to ask your data, decide about what type of OTU clustering you want to do (both algorithm and percent similarity).<\/p>\n<p>\u00a0<\/p>\n<p>QIIME is a great resource\u00a0for tutorials on OTU clustering -\u00a0http:\/\/qiime.org\/tutorials\/otu_picking.html#running-the-otu-picking-workflows<\/p>","order_id":"0","name":"Description","data_by_id":"0","type_id":"1","source_data":{"description":"<p>Depending on the questions you want to ask your data, decide about what type of OTU clustering you want to do (both algorithm and percent similarity).<\/p>\n<p>\u00a0<\/p>\n<p>QIIME is a great resource\u00a0for tutorials on OTU clustering -\u00a0http:\/\/qiime.org\/tutorials\/otu_picking.html#running-the-otu-picking-workflows<\/p>"},"is_project":0},{"component_id":"1008647","previous_id":"1008646","original_id":"436314","guid":"45094942E8DA4D2C9EE6BBC95716D08F","previous_guid":"094F58EB7D9745FBA8A3E8B21681DDD9","component_type_id":"6","data_id":null,"data":"OTU-clustering","order_id":"1","name":"Section","data_by_id":"0","type_id":"6","source_data":{"section":"OTU-clustering"},"is_project":0}]},{"id":"589147","is_changed":"0","original_id":"584050","is_skipped":"0","is_checked":"0","guid":"A73C2D1EC0AE4E008E4573D0D3323AC4","previous_guid":"BD148233C2F5478CAB9365C2BE54F7C5","previous_id":"589146","last_modified":"1506797010","components":[{"component_id":"1008648","previous_id":0,"original_id":"996322","guid":"6C265FE36A5948A19EA61794E170BD60","previous_guid":null,"component_type_id":"6","data_id":null,"data":"Analysis","order_id":"0","name":"Section","data_by_id":"0","type_id":"6","source_data":{"section":"Analysis"},"is_project":0},{"component_id":"1008649","previous_id":"1008648","original_id":"996321","guid":"D7BC5CEBE3E249788F44D54DE91A75CB","previous_guid":"6C265FE36A5948A19EA61794E170BD60","component_type_id":"1","data_id":null,"data":"<p>For examples of preliminary analyses and figure generation in R see: https:\/\/github.com\/shu251\/PreliminaryFigures_V4_tagseq<\/p>\n<p>\u00a0<\/p>\n<p>\u00a0<\/p>","order_id":"1","name":"Description","data_by_id":"0","type_id":"1","source_data":{"description":"<p>For examples of preliminary analyses and figure generation in R see: https:\/\/github.com\/shu251\/PreliminaryFigures_V4_tagseq<\/p>\n<p>\u00a0<\/p>\n<p>\u00a0<\/p>"},"is_project":0}]},{"id":"589148","is_changed":"0","original_id":"0","is_skipped":"0","is_checked":"0","guid":"45B424351479482F8A1570C5C91C747B","previous_guid":null,"previous_id":"0","last_modified":"1506797614","components":[{"component_id":"1008651","previous_id":0,"original_id":"0","guid":"20FFBEB206E4403D869D11506A29A056","previous_guid":null,"component_type_id":"6","data_id":"0","data":"Pre-processing","order_id":"0","name":"Section","data_by_id":"0","type_id":"6","source_data":{"section":"Pre-processing"},"is_project":0},{"component_id":"1008650","previous_id":"1008651","original_id":"0","guid":"3BCEC5EA424D4B36B70E547FB8C84DB6","previous_guid":"20FFBEB206E4403D869D11506A29A056","component_type_id":"1","data_id":null,"data":"<p>You can download test files and scripts described below from git.<\/p>","order_id":"1","name":"Description","data_by_id":"0","type_id":"1","source_data":{"description":"<p>You can download test files and scripts described below from git.<\/p>"},"is_project":0},{"component_id":"1008652","previous_id":"1008650","original_id":"0","guid":"F6E4885301BE4770BA92C6E5735022AB","previous_guid":"3BCEC5EA424D4B36B70E547FB8C84DB6","component_type_id":"15","data_id":"2261","data":"","order_id":"2","name":"Command","data_by_id":"1","type_id":"15","source_data":{"name":"git clone https:\/\/github.com\/shu251\/QC_steps_V4_tagsequencing","description":"","os_name":"","os_version":"","can_edit":"0"},"is_project":0}]},{"id":"589149","is_changed":"0","original_id":"0","is_skipped":"0","is_checked":"0","guid":"2EDFE07A11BC4796865F1D15BBE5D467","previous_guid":"86CEB279C3BF4B2096673CB42B35F63A","previous_id":"589142","last_modified":"1506798071","components":[{"component_id":"1008656","previous_id":0,"original_id":"0","guid":"F110DCA675D04586AF5826419D113948","previous_guid":null,"component_type_id":"6","data_id":"0","data":"Obtain other required scripts and files","order_id":"0","name":"Section","data_by_id":"0","type_id":"6","source_data":{"section":"Obtain other required scripts and files"},"is_project":0},{"component_id":"1008655","previous_id":"1008656","original_id":"0","guid":"FF5B9F6A718F4F6EA284AE888A98A107","previous_guid":"F110DCA675D04586AF5826419D113948","component_type_id":"1","data_id":null,"data":"<ul>\n<li>Fasta file with listed forward and reverse primer. (<\/li>\n<\/ul>","order_id":"1","name":"Description","data_by_id":"0","type_id":"1","source_data":{"description":"<ul>\n<li>Fasta file with listed forward and reverse primer. (<\/li>\n<\/ul>"},"is_project":0}]}]}