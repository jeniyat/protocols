{"uri":"the-colombian-signed-peace-agreement-a-text-mining-h8db9s6","version_id":"0","protocol_name":"The Colombian Signed Peace Agreement: A Text Mining Analysis of its Comprehension Difficulty","protocol_name_html":"The Colombian Signed Peace Agreement: A Text Mining Analysis of its Comprehension Difficulty","is_prepublished":"0","can_edit":"0","parent_id":null,"api_version":"1","is_new_mode":"1","last_modified":"1519884661","type_id":"1","link":"","fork_id":"","public_fork_note":"","number_of_steps":"7","has_versions":"1","first_published_date":"1496208464","publish_date":"2017-05-31 05:27:44","documents":null,"have_protocol_in_step":"0","is_protocol_in_step":"0","vendor_name":"Contributed by users","vendor_link":"https:\/\/www.protocols.io","vendor_logo":"\/img\/vendors\/1.png","mod_mins":"-45","mod_secs":"1","description":"","is_bookmarked":"0","can_reassign":"1","before_start":"","has_guidelines":"0","materials":[],"warning":"","version_class":"6117","public":"1","is_owner":"1","is_original_owner":"1","created_on":"1496205022","protocol_affiliation":"Fundaci\u00f3n Universitaria Konrad Lorenz. Universidad Pedag\u00f3gica Nacional","affiliation":"Fundaci\u00f3n Universitaria Konrad Lorenz","doi":"dx.doi.org\/10.17504\/protocols.io.h8db9s6","doi_status":"2","changed_fork_steps":null,"profile_url":"JuanC-x2z294z2y2","protocol_img":"https:\/\/s3.amazonaws.com\/pr-journal\/j5bgsgn.png","profile_image":"https:\/\/s3.amazonaws.com\/pr-journal\/j49gsgn.jpg","full_name":"Juan C. Correa","created_by":"Juan C. Correa","private_link":"DF02FA3D2041AAC8368E7C5225A080B0","original_img":"1","username":"juan-c-correa","is_retracted":"0","retraction_reason":null,"plos_id":null,"manuscript_citation":null,"journal_name":null,"is_donations_disabled":"0","is_donations_disabled_by_user":"9","item_record_id":248451,"fork_info":[],"compare_forks":[],"protocols":[],"groups":[],"number_of_shared_runs":[],"ownership_history":[],"keywords":"","transfer_to_user":[],"sub_transfer":false,"is_transfer_pending":false,"number_of_bookmarks":"1","collections":[],"tags":[],"archived":0,"sub_authors":[],"sub_protocols_number":0,"can_edit_shared":0,"shared_runs":[],"is_shared_run":0,"is_shared":1,"banner":null,"contact_badges":[{"badge_id":"2","badge_image":"\/img\/badges\/bronze.svg","badge_description":"Author!"},{"badge_id":"5","badge_image":"\/img\/badges\/earlyadopter.svg","badge_description":"Early adopter"},{"badge_id":"6","badge_image":"\/img\/badges\/socialbutterfly.svg","badge_description":"Social butterfly"}],"number_of_comments":0,"is_locked":0,"is_locked_by":false,"authors":"Juan C. Correa, Mar\u00eda del Pilar Garc\u00eda-Chitiva and Gustavo R. Garc\u00eda-Vargas","authors_list":[{"name":"Juan C. Correa","affiliation":"Fundaci\u00f3n Universitaria Konrad Lorenz. Universidad Pedag\u00f3gica Nacional","username":null,"profile_image":null},{"name":" Mar\u00eda del Pilar Garc\u00eda-Chitiva and Gustavo R. Garc\u00eda-Vargas","affiliation":"Fundaci\u00f3n Universitaria Konrad Lorenz. Universidad Pedag\u00f3gica Nacional","username":null,"profile_image":null}],"user":{"profile_image":"https:\/\/s3.amazonaws.com\/pr-journal\/j49gsgn.jpg","username":"juan-c-correa","full_name":"Juan C. Correa","created_by":"Juan C. Correa"},"access":{"can_view":"1","can_remove":"0","can_add":"0","can_edit":0,"can_publish":0,"can_get_doi":0,"can_share":"0","can_move":"1","can_transfer":"1","can_download":"1","is_locked":"0"},"is_contact_suspended":0,"guidelines":"","status_id":"1","is_research":"1","status_info":null,"steps":[{"id":"534373","is_changed":"0","original_id":"0","is_skipped":"0","is_checked":"0","guid":"2096B8E9D9A04BEBA27F15E9ACF9F7DA","previous_guid":"DF9B23940D53485FB8054B292530AE70","previous_id":"534374","last_modified":"1496207394","components":[{"component_id":"876751","previous_id":0,"original_id":"0","guid":"1E474027DA674E198210FE5C7AEA37A3","previous_guid":null,"component_type_id":"1","data_id":"0","data":"<p>Since the Colombian peace agreement was signed\u00a0on August 25, 2016, let's download this version <a href=\"http:\/\/www.altocomisionadoparalapaz.gov.co\/mesadeconversaciones\/PDF\/acuerdo-final-1473286288.pdf\" target=\"_blank\">here<\/a>. If you have problems in downloading this version, click <a href=\"https:\/\/drive.google.com\/file\/d\/0B_OaoITre0wkY3gzRWdpLWVXSlU\/view?usp=sharing\" target=\"_blank\">here<\/a><\/p>","order_id":"0","name":"Description","data_by_id":"0","type_id":"1","source_data":{"description":"<p>Since the Colombian peace agreement was signed\u00a0on August 25, 2016, let's download this version <a href=\"http:\/\/www.altocomisionadoparalapaz.gov.co\/mesadeconversaciones\/PDF\/acuerdo-final-1473286288.pdf\" target=\"_blank\">here<\/a>. If you have problems in downloading this version, click <a href=\"https:\/\/drive.google.com\/file\/d\/0B_OaoITre0wkY3gzRWdpLWVXSlU\/view?usp=sharing\" target=\"_blank\">here<\/a><\/p>"},"is_project":0},{"component_id":"876959","previous_id":"876751","original_id":"0","guid":"C6547F299A23458B86BA224070E614D5","previous_guid":"1E474027DA674E198210FE5C7AEA37A3","component_type_id":"6","data_id":"0","data":"Download the Colombian Signed Peace Agreement","order_id":"1","name":"Section","data_by_id":"0","type_id":"6","source_data":{"section":"Download the Colombian Signed Peace Agreement"},"is_project":0}]},{"id":"534374","is_changed":"0","original_id":"0","is_skipped":"0","is_checked":"0","guid":"DF9B23940D53485FB8054B292530AE70","previous_guid":null,"previous_id":"0","last_modified":"1496207626","components":[{"component_id":"877001","previous_id":0,"original_id":"0","guid":"53A7EB4305B74F3FABC430304EA60E2A","previous_guid":null,"component_type_id":"1","data_id":"0","data":"<p>Let's see what peace agreements have occurred in Latin America as a result of Intra-State armed conflicts. This query can be accessed <a href=\"http:\/\/peacemaker.un.org\/document-search?keys=&amp;field_padate_value%5Bvalue%5D%5Bdate%5D=&amp;field_pacountry_tid=&amp;field_paregion_tid%5B%5D=17&amp;field_paconflict_tid%5B%5D=1\" target=\"_blank\">here<\/a>. We immediately see that the query shows a total of 104 documents.\u00a0\u00a0With the exception of Canada, 102 manuscripts correspond to nine Latin American countries.<\/p>","order_id":"0","name":"Description","data_by_id":"0","type_id":"1","source_data":{"description":"<p>Let's see what peace agreements have occurred in Latin America as a result of Intra-State armed conflicts. This query can be accessed <a href=\"http:\/\/peacemaker.un.org\/document-search?keys=&amp;field_padate_value%5Bvalue%5D%5Bdate%5D=&amp;field_pacountry_tid=&amp;field_paregion_tid%5B%5D=17&amp;field_paconflict_tid%5B%5D=1\" target=\"_blank\">here<\/a>. We immediately see that the query shows a total of 104 documents.\u00a0\u00a0With the exception of Canada, 102 manuscripts correspond to nine Latin American countries.<\/p>"},"is_project":0},{"component_id":"877002","previous_id":"877001","original_id":"0","guid":"316743BA865E4C118C6A539016D2A155","previous_guid":"53A7EB4305B74F3FABC430304EA60E2A","component_type_id":"6","data_id":"0","data":"Querying Latin American Intra-State armed conflicts","order_id":"1","name":"Section","data_by_id":"0","type_id":"6","source_data":{"section":"Querying Latin American Intra-State armed conflicts"},"is_project":0}]},{"id":"534504","is_changed":"0","original_id":"0","is_skipped":"0","is_checked":"0","guid":"D734CFDCAA0B4711A0FF6D8F337318F6","previous_guid":"2096B8E9D9A04BEBA27F15E9ACF9F7DA","previous_id":"534373","last_modified":"1496207684","components":[{"component_id":"877039","previous_id":0,"original_id":"0","guid":"5A336FFDA84C456B92D4C76E9AB5087F","previous_guid":null,"component_type_id":"1","data_id":"0","data":"<div>Among these nations, only three of them have gone through internal armed conflicts involving fights between guerrilla movements and local governments and have been solved with signed agreements by both parties. These countries are Colombia (1964-2016), Guatemala (1960-1996) and El Salvador (1980-1994). This shows us the relevance of comparing these agreements because of their socio-cultural similarities.<\/div>","order_id":"0","name":"Description","data_by_id":"0","type_id":"1","source_data":{"description":"<div>Among these nations, only three of them have gone through internal armed conflicts involving fights between guerrilla movements and local governments and have been solved with signed agreements by both parties. These countries are Colombia (1964-2016), Guatemala (1960-1996) and El Salvador (1980-1994). This shows us the relevance of comparing these agreements because of their socio-cultural similarities.<\/div>"},"is_project":0},{"component_id":"877022","previous_id":"877039","original_id":"0","guid":"58EE8EF98CFD4B7CA182EABA0530BF7A","previous_guid":"5A336FFDA84C456B92D4C76E9AB5087F","component_type_id":"6","data_id":"0","data":"What other peace agreements can be compared with the Colombian one?","order_id":"1","name":"Section","data_by_id":"0","type_id":"6","source_data":{"section":"What other peace agreements can be compared with the Colombian one?"},"is_project":0}]},{"id":"534535","is_changed":"0","original_id":"0","is_skipped":"0","is_checked":"0","guid":"1AECEACDE6B547728BA43F50CB48BADC","previous_guid":"D734CFDCAA0B4711A0FF6D8F337318F6","previous_id":"534504","last_modified":"1496206794","components":[{"component_id":"877071","previous_id":0,"original_id":"0","guid":"500F0C02FDB84906A115255E8A68E7AD","previous_guid":null,"component_type_id":"1","data_id":"0","data":"<p>These documents can be downloaded <a href=\"http:\/\/peacemaker.un.org\/guatemala-implementation96\" target=\"_blank\">here<\/a>\u00a0and <a href=\"http:\/\/peacemaker.un.org\/guatemala-definitiveceasefire96\" target=\"_blank\">here<\/a>.<\/p>","order_id":"0","name":"Description","data_by_id":"0","type_id":"1","source_data":{"description":"<p>These documents can be downloaded <a href=\"http:\/\/peacemaker.un.org\/guatemala-implementation96\" target=\"_blank\">here<\/a>\u00a0and <a href=\"http:\/\/peacemaker.un.org\/guatemala-definitiveceasefire96\" target=\"_blank\">here<\/a>.<\/p>"},"is_project":0},{"component_id":"877067","previous_id":"877071","original_id":"0","guid":"E18BE98C8246416E801235D5FB1E0C14","previous_guid":"500F0C02FDB84906A115255E8A68E7AD","component_type_id":"6","data_id":"0","data":"Download the Guatemalan peace agreement","order_id":"1","name":"Section","data_by_id":"0","type_id":"6","source_data":{"section":"Download the Guatemalan peace agreement"},"is_project":0}]},{"id":"534549","is_changed":"0","original_id":"0","is_skipped":"0","is_checked":"0","guid":"23A906B163624FA187609F4E37B89A60","previous_guid":"1AECEACDE6B547728BA43F50CB48BADC","previous_id":"534535","last_modified":"1496207236","components":[{"component_id":"877097","previous_id":0,"original_id":"0","guid":"A7281C4B4A6C40D3A3CF9E6CA423F553","previous_guid":null,"component_type_id":"1","data_id":"0","data":"<p>These documents can be downloaded\u00a0in the following web pages<\/p>\n<ol>\n<li><a href=\"http:\/\/peacemaker.un.org\/elsalvador-chapultepec92\" target=\"_blank\">Chapultepec agreements<\/a><\/li>\n<li><a href=\"http:\/\/peacemaker.un.org\/elsalvador-nyactI91\" target=\"_blank\">New York acts<\/a><\/li>\n<li><a href=\"http:\/\/peacemaker.un.org\/elsalvador-mexicoagreement91\" target=\"_blank\">The Mexico Agreement<\/a><\/li>\n<li><a href=\"http:\/\/peacemaker.un.org\/elsalvador-genevaagreement90\" target=\"_blank\">The Geneva agreement<\/a><\/li>\n<\/ol>","order_id":"0","name":"Description","data_by_id":"0","type_id":"1","source_data":{"description":"<p>These documents can be downloaded\u00a0in the following web pages<\/p>\n<ol>\n<li><a href=\"http:\/\/peacemaker.un.org\/elsalvador-chapultepec92\" target=\"_blank\">Chapultepec agreements<\/a><\/li>\n<li><a href=\"http:\/\/peacemaker.un.org\/elsalvador-nyactI91\" target=\"_blank\">New York acts<\/a><\/li>\n<li><a href=\"http:\/\/peacemaker.un.org\/elsalvador-mexicoagreement91\" target=\"_blank\">The Mexico Agreement<\/a><\/li>\n<li><a href=\"http:\/\/peacemaker.un.org\/elsalvador-genevaagreement90\" target=\"_blank\">The Geneva agreement<\/a><\/li>\n<\/ol>"},"is_project":0},{"component_id":"877091","previous_id":"877097","original_id":"0","guid":"00AD6742E8094256AF9E3362F496A128","previous_guid":"A7281C4B4A6C40D3A3CF9E6CA423F553","component_type_id":"6","data_id":"0","data":"Download the peace agreement of El Salvador","order_id":"1","name":"Section","data_by_id":"0","type_id":"6","source_data":{"section":"Download the peace agreement of El Salvador"},"is_project":0}]},{"id":"534590","is_changed":"0","original_id":"0","is_skipped":"0","is_checked":"0","guid":"2C4A7FA841894A0EBBAF75829CE00D39","previous_guid":"23A906B163624FA187609F4E37B89A60","previous_id":"534549","last_modified":"1496208336","components":[{"component_id":"877217","previous_id":0,"original_id":"0","guid":"386C1805E50340069357349E494ED3A2","previous_guid":null,"component_type_id":"1","data_id":"0","data":"<p>The preprocessing of these documents involved their conversion from pdf files to UTF-8 text-formatted data without headers and footers since these items present no semantic relevant information. Additional non-semantic features like badges, scanned signatures, vignettes, tables and the like were all deleted. In addition, we removed all numbers, unnecessary whitespaces, punctuation and special characters as well as Spanish stopwords.\u00a0<\/p>\n<p>These preprocessed documents can be downloaded <a href=\"https:\/\/drive.google.com\/drive\/folders\/0B_OaoITre0wkYjdnbjhURE4yd00?usp=sharing\" target=\"_blank\">here<\/a>. Note that we have both English and Spanish versions of these documents.<\/p>\n<p>If you are using Windows and these documents were downloaded in your \"downloads folder\", then your files locations should have the following address<\/p>\n<p>C::\/\/Downloads\u00a0<\/p>","order_id":"0","name":"Description","data_by_id":"0","type_id":"1","source_data":{"description":"<p>The preprocessing of these documents involved their conversion from pdf files to UTF-8 text-formatted data without headers and footers since these items present no semantic relevant information. Additional non-semantic features like badges, scanned signatures, vignettes, tables and the like were all deleted. In addition, we removed all numbers, unnecessary whitespaces, punctuation and special characters as well as Spanish stopwords.\u00a0<\/p>\n<p>These preprocessed documents can be downloaded <a href=\"https:\/\/drive.google.com\/drive\/folders\/0B_OaoITre0wkYjdnbjhURE4yd00?usp=sharing\" target=\"_blank\">here<\/a>. Note that we have both English and Spanish versions of these documents.<\/p>\n<p>If you are using Windows and these documents were downloaded in your \"downloads folder\", then your files locations should have the following address<\/p>\n<p>C::\/\/Downloads\u00a0<\/p>"},"is_project":0},{"component_id":"877169","previous_id":"877217","original_id":"0","guid":"FA7533CA4DA34CECB4C3AB995C64EB99","previous_guid":"386C1805E50340069357349E494ED3A2","component_type_id":"6","data_id":"0","data":"Preprocessing the documents","order_id":"1","name":"Section","data_by_id":"0","type_id":"6","source_data":{"section":"Preprocessing the documents"},"is_project":0}]},{"id":"534797","is_changed":"0","original_id":"0","is_skipped":"0","is_checked":"0","guid":"E3F96A2B46024B30A7ED5AC0FB17F527","previous_guid":"2C4A7FA841894A0EBBAF75829CE00D39","previous_id":"534590","last_modified":"1496208391","components":[{"component_id":"877589","previous_id":0,"original_id":"0","guid":"1A313073B3FD430F87EF98A45F193840","previous_guid":null,"component_type_id":"1","data_id":"0","data":"<p># The aim of this Script is to provide the reader an easy-to-use <br \/># procedure that allows the replication of our findings \u00a0<br \/># This script works for the original accords which were written in Spanish.<\/p>\n<p>################################# <br \/>### INITIALIZING THE ANALYSIS ###<br \/>#################################<br \/>if(!require(tm)){<br \/> install.packages('tm')<br \/>}<br \/># Load the required packages for Preprocesing our documents<br \/>library(tm)<\/p>\n<p><br \/># Create an object that defines the local directory in<br \/># which you saved the documents of the Colombian Signed Peace Agreement<\/p>\n<p>######################<br \/>###### COLOMBIA ######<br \/>######################<\/p>\n<p>\u00a0<\/p>\n<p>#replace the address where you downloaded the documents<br \/>documents &lt;- file.path('\/home\/lenovo\/investigacion\/Documents\/Colombia (es)')<br \/>dir(documents)<\/p>\n<p># Create another object as a corpus containing all parts of the Colombian<br \/># Agreement<br \/>ColombianDocs &lt;- Corpus(DirSource(documents))<br \/># You can check the contents of this last object like this<br \/>summary(ColombianDocs)<br \/>#Now lets begin with the preprocessing<br \/>#Remove punctuation<br \/>ColombianDocs &lt;- tm_map(ColombianDocs, removePunctuation)<br \/>#Remove Numbers<br \/>ColombianDocs &lt;- tm_map(ColombianDocs, removeNumbers)<br \/>#Convert all words in lowercase<br \/>ColombianDocs &lt;- tm_map(ColombianDocs, tolower)<br \/>#Remove Stopwords<br \/>ColombianDocs &lt;- tm_map(ColombianDocs, removeWords, stopwords('spanish'))<br \/>#Remove additional white spaces between words<br \/>ColombianDocs &lt;- tm_map(ColombianDocs, stripWhitespace)<br \/>#Save The Colombian Signed Peace Agreement as Plain Document<br \/>ColombianDocs &lt;- tm_map(ColombianDocs, PlainTextDocument)<br \/>#Begin the Analysis by creating a Document-Term Matrix<br \/>dtm &lt;- DocumentTermMatrix(ColombianDocs)<br \/>#You can check the dtm by typing<br \/>dtm<br \/># You can transpose this matrix, If you want<br \/>tdm &lt;- TermDocumentMatrix(ColombianDocs)<br \/># Let's explore terms frequencies<br \/>freq &lt;- colSums(as.matrix(dtm))<br \/># Now let's order these terms from least frequents to most frequents ones. This 'ord' object<br \/># will be used later when computing wordcloud.<br \/>ord &lt;- order(freq)<br \/># Let's remove sparse terms from this Term-Document Matrix with, say 10% empty space<br \/>NSTDM &lt;- removeSparseTerms(tdm, 0.1)<br \/># Let's see most and least frequent words in all documents<br \/>freq[tail(ord)]<br \/>freq[head(ord)]<br \/># Do you want to export this info as a table in Excel?<br \/>FreqTerms &lt;- as.matrix(tdm)<br \/>dim(FreqTerms)<br \/>write.csv(FreqTerms, file = 'ColombianFrequentTerms.csv')<br \/># Note that terms are in rows, and columns represent each document<br \/># Let's open this new matrix<br \/>if(!require(readr)){<br \/> install.packages('readr')<br \/>}<br \/>library(readr)<br \/>ColombianFrequentTerms &lt;- read_csv('~\/ColombianFrequentTerms.csv')<br \/>names(ColombianFrequentTerms) &lt;-c('Words', 'Addendum', 'Point 1', 'Point 2', 'Point 3', 'Point 4', 'Point 5', 'Point 6')<br \/>ColombianFrequentTerms$WordTotalFrequency &lt;- rowSums(ColombianFrequentTerms[,2:8])<br \/># Let's take a look to the Wordcloud of the Colombian Agreement<br \/># that includes most frequent words (those that appear at least<br \/># 25 times in the whole document)<br \/>if(!require(wordcloud)){<br \/> install.packages('wordcloud')<br \/>}<br \/>library(wordcloud)<br \/>set.seed(142)<br \/>wordcloud(names(freq), freq, min.freq=25)<\/p>\n<p>if(!require(koRpus)){<br \/> install.packages('koRpus')<br \/>}<br \/># Now, let's tokenize our documents<br \/>library(koRpus)<br \/>Addendum &lt;- tokenize('\/home\/lenovo\/investigacion\/Documents\/Colombia (es)\/protocolos.txt', lang = 'es')<br \/>Point1 &lt;- tokenize('\/home\/lenovo\/investigacion\/Documents\/Colombia (es)\/Punto1.txt', lang = 'es')<br \/>Point2 &lt;- tokenize('\/home\/lenovo\/investigacion\/Documents\/Colombia (es)\/Punto2.txt', lang = 'es')<br \/>Point3 &lt;- tokenize('\/home\/lenovo\/investigacion\/Documents\/Colombia (es)\/Punto3.txt', lang = 'es')<br \/>Point4 &lt;- tokenize('\/home\/lenovo\/investigacion\/Documents\/Colombia (es)\/Punto4.txt', lang = 'es')<br \/>Point5 &lt;- tokenize('\/home\/lenovo\/investigacion\/Documents\/Colombia (es)\/Punto5.txt', lang = 'es')<br \/>Point6 &lt;- tokenize('\/home\/lenovo\/investigacion\/Documents\/Colombia (es)\/Punto6.txt', lang = 'es')<br \/># Let's calculate the SMOG grading for all these documents<br \/>SMOG(Addendum)<br \/>SMOG(Point1)<br \/>SMOG(Point2)<br \/>SMOG(Point3)<br \/>SMOG(Point4)<br \/>SMOG(Point5)<br \/>SMOG(Point6)<br \/># Since the SMOG algorithm provides a double output (i.e., the grading instruction and the age of a person),<br \/># we can build a dataset that contains these values for all the documents of Colombia, Guatemala and El Salvador.<br \/># To do that, we need to repeat the same procedures for the other countries.<\/p>\n<p>######################<br \/>###### SALVADOR ######<br \/>######################<br \/>library(tm)<br \/>Salvador &lt;- file.path('\/home\/lenovo\/investigacion\/Documents\/Salvador')<br \/>dir(Salvador)<br \/>SalvadorDocs &lt;- Corpus(DirSource(Salvador))<br \/># You can check the contents of this last object like this<br \/>summary(SalvadorDocs)<br \/>#Now lets begin with the preprocessing<br \/>#Remove punctuation<br \/>SalvadorDocs &lt;- tm_map(SalvadorDocs, removePunctuation)<br \/>#Remove Numbers<br \/>SalvadorDocs &lt;- tm_map(SalvadorDocs, removeNumbers)<br \/>#Convert all words in lowercase<br \/>SalvadorDocs &lt;- tm_map(SalvadorDocs, tolower)<br \/>#Remove Stopwords<br \/>SalvadorDocs &lt;- tm_map(SalvadorDocs, removeWords, stopwords('spanish'))<br \/>#Remove additional white spaces between words<br \/>SalvadorDocs &lt;- tm_map(SalvadorDocs, stripWhitespace)<br \/>#Save The Colombian Signed Peace Agreement as Plain Document<br \/>SalvadorDocs &lt;- tm_map(SalvadorDocs, PlainTextDocument)<br \/>#Begin the Analysis by creating a Document-Term Matrix<br \/>dtmSalvador &lt;- DocumentTermMatrix(SalvadorDocs)<br \/>#You can check the dtm by typing<br \/>dtmSalvador<br \/># You can transpose this matrix, If you want<br \/>tdmSalvador &lt;- TermDocumentMatrix(SalvadorDocs)<br \/># Let's explore terms frequencies<br \/>freqSalvador &lt;- colSums(as.matrix(dtmSalvador))<br \/># Now let's order these terms from least frequents to most frequents ones. This 'ord' object<br \/># will be used later when computing wordcloud.<br \/>ordSalvador &lt;- order(freqSalvador)<br \/># Let's remove sparse terms from this Term-Document Matrix with, say 10% empty space<br \/>NSTDMsalvador &lt;- removeSparseTerms(tdmSalvador, 0.1)<br \/># Let's see most and least frequent words in all documents<br \/>freqSalvador[tail(ordSalvador)]<br \/>freqSalvador[head(ordSalvador)]<br \/># Do you want to export this info as a table in Excel?<br \/>FreqTermsSalvador &lt;- as.matrix(tdmSalvador)<br \/>dim(FreqTermsSalvador)<br \/>write.csv(FreqTermsSalvador, file = 'FrequentTermsSalvador.csv')<br \/># Note that terms are in rows, and columns represent each document<br \/># Let's open this new matrix<br \/>library(readr)<br \/>FrequentTermsSalvador &lt;- read_csv('~\/FrequentTermsSalvador.csv')<br \/>names(FrequentTermsSalvador) &lt;-c('Words', 'Act', 'Cap1', 'Cap2', 'Cap3', 'Cap4', 'Cap5', 'Cap6', 'Cap7', 'Cap8', 'Cap9', 'DecFin', 'Intro')<br \/>FrequentTermsSalvador$WordTotalFrequency &lt;- rowSums(FrequentTermsSalvador[,2:13])<br \/># Let's take a look to the Wordcloud of the Salvadoran Agreement<br \/># that includes most frequent words (those that appear at least<br \/># 25 times in the whole document)<br \/>library(wordcloud)<br \/>set.seed(142)<br \/>wordcloud(names(freqSalvador), freqSalvador, min.freq=25)<\/p>\n<p># Now, let's tokenize our documents<br \/>library(koRpus)<br \/>Acts &lt;- tokenize('\/home\/lenovo\/investigacion\/Documents\/Salvador\/Actas.txt', lang ='es')<br \/>Cap1 &lt;- tokenize('\/home\/lenovo\/investigacion\/Documents\/Salvador\/Cap1.txt', lang = 'es')<br \/>Cap2 &lt;- tokenize('\/home\/lenovo\/investigacion\/Documents\/Salvador\/Cap2.txt', lang = 'es')<br \/>Cap3 &lt;- tokenize('\/home\/lenovo\/investigacion\/Documents\/Salvador\/Cap3.txt', lang = 'es')<br \/>Cap4 &lt;- tokenize('\/home\/lenovo\/investigacion\/Documents\/Salvador\/Cap4.txt', lang = 'es')<br \/>Cap5 &lt;- tokenize('\/home\/lenovo\/investigacion\/Documents\/Salvador\/Cap5.txt', lang = 'es')<br \/>Cap6 &lt;- tokenize('\/home\/lenovo\/investigacion\/Documents\/Salvador\/Cap6.txt', lang = 'es')<br \/>Cap7 &lt;- tokenize('\/home\/lenovo\/investigacion\/Documents\/Salvador\/Cap7.txt', lang = 'es')<br \/>Cap8 &lt;- tokenize('\/home\/lenovo\/investigacion\/Documents\/Salvador\/Cap8.txt', lang = 'es')<br \/>Cap9 &lt;- tokenize('\/home\/lenovo\/investigacion\/Documents\/Salvador\/Cap9.txt', lang = 'es')<br \/>DecFin &lt;- tokenize('\/home\/lenovo\/investigacion\/Documents\/Salvador\/DecFin.txt', lang = 'es')<br \/>Intro &lt;- tokenize('\/home\/lenovo\/investigacion\/Documents\/Salvador\/Intro.txt', lang = 'es')<br \/># Let's calculate the SMOG grading for all these documents<br \/>SMOG(Acts)<br \/>SMOG(Cap1)<br \/>SMOG(Cap2)<br \/>SMOG(Cap3)<br \/>SMOG(Cap4)<br \/>SMOG(Cap5)<br \/>SMOG(Cap6)<br \/>SMOG(Cap7)<br \/>SMOG(Cap8)<br \/>SMOG(Cap9)<br \/>SMOG(DecFin)<br \/>SMOG(Intro)<\/p>\n<p>#######################<br \/>###### GUATEMALA ######<br \/>#######################<br \/>library(tm)<br \/>Guatemala &lt;- file.path('\/home\/lenovo\/investigacion\/Documents\/Guatemala')<br \/>dir(Guatemala)<br \/>GuatemalaDocs &lt;- Corpus(DirSource(Guatemala))<br \/>summary(GuatemalaDocs)<br \/>#Now lets begin with the preprocessing<br \/>#Remove punctuation<br \/>GuatemalaDocs &lt;- tm_map(GuatemalaDocs, removePunctuation)<br \/>#Remove Numbers<br \/>GuatemalaDocs &lt;- tm_map(GuatemalaDocs, removeNumbers)<br \/>#Convert all words in lowercase<br \/>GuatemalaDocs &lt;- tm_map(GuatemalaDocs, tolower)<br \/>#Remove Stopwords<br \/>GuatemalaDocs &lt;- tm_map(GuatemalaDocs, removeWords, stopwords('spanish'))<br \/>#Remove additional white spaces between words<br \/>GuatemalaDocs &lt;- tm_map(GuatemalaDocs, stripWhitespace)<br \/>#Save The Colombian Signed Peace Agreement as Plain Document<br \/>GuatemalaDocs &lt;- tm_map(GuatemalaDocs, PlainTextDocument)<br \/>#Begin the Analysis by creating a Document-Term Matrix<br \/>dtmGuatemala &lt;- DocumentTermMatrix(GuatemalaDocs)<br \/>#You can check the dtm by typing<br \/>dtmGuatemala<br \/># You can transpose this matrix, If you want<br \/>tdmGuatemala &lt;- TermDocumentMatrix(GuatemalaDocs)<br \/># Let's explore terms frequencies<br \/>freqGuatemala &lt;- colSums(as.matrix(dtmGuatemala))<br \/># Now let's order these terms from least frequents to most frequents ones. This 'ord' object<br \/># will be used later when computing wordcloud.<br \/>ordGuatemala &lt;- order(freqGuatemala)<br \/># Let's remove sparse terms from this Term-Document Matrix with, say 10% empty space<br \/>NSTDMguatemala &lt;- removeSparseTerms(tdmGuatemala, 0.1)<br \/># Let's see most and least frequent words in all documents<br \/>freqGuatemala[tail(ordGuatemala)]<br \/>freqGuatemala[head(ordGuatemala)]<br \/># Do you want to export this info as a table in Excel?<br \/>FreqTermsGuatemala &lt;- as.matrix(tdmGuatemala)<br \/>dim(FreqTermsGuatemala)<br \/>write.csv(FreqTermsGuatemala, file = 'FrequentTermsGuatemala.csv')<br \/># Note that terms are in rows, and columns represent each document<br \/># Let's open this new matrix<br \/>library(readr)<br \/>FrequentTermsGuatemala &lt;- read_csv('~\/FrequentTermsGuatemala.csv')<br \/>names(FrequentTermsGuatemala) &lt;-c('Words', 'Caps1', 'Caps2', 'Caps3', 'Caps4', 'Caps5', 'Caps6', 'Caps7', 'Caps8', 'Caps9', 'Caps10', 'Caps11', 'Caps12', 'ProtGua')<br \/>FrequentTermsGuatemala$WordTotalFrequency &lt;- rowSums(FrequentTermsGuatemala[,2:14])<br \/># Let's take a look to the Wordcloud of the Guatemalian Agreement<br \/># that includes most frequent words (those that appear at least<br \/># 25 times in the whole document)<br \/>library(wordcloud)<br \/>set.seed(142)<br \/>wordcloud(names(freqGuatemala), freqGuatemala, min.freq=25)<\/p>\n<p># Now, let's tokenize our documents<br \/>library(koRpus)<br \/>Caps1 &lt;- tokenize('\/home\/lenovo\/investigacion\/Documents\/Guatemala\/Caps1.txt', lang = 'es')<br \/>Caps2 &lt;- tokenize('\/home\/lenovo\/investigacion\/Documents\/Guatemala\/Caps2.txt', lang = 'es')<br \/>Caps3 &lt;- tokenize('\/home\/lenovo\/investigacion\/Documents\/Guatemala\/Caps3.txt', lang = 'es')<br \/>Caps4 &lt;- tokenize('\/home\/lenovo\/investigacion\/Documents\/Guatemala\/Caps4.txt', lang = 'es')<br \/>Caps5 &lt;- tokenize('\/home\/lenovo\/investigacion\/Documents\/Guatemala\/Caps5.txt', lang = 'es')<br \/>Caps6 &lt;- tokenize('\/home\/lenovo\/investigacion\/Documents\/Guatemala\/Caps6.txt', lang = 'es')<br \/>Caps7 &lt;- tokenize('\/home\/lenovo\/investigacion\/Documents\/Guatemala\/Caps7.txt', lang = 'es')<br \/>Caps8 &lt;- tokenize('\/home\/lenovo\/investigacion\/Documents\/Guatemala\/Caps8.txt', lang = 'es')<br \/>Caps9 &lt;- tokenize('\/home\/lenovo\/investigacion\/Documents\/Guatemala\/Caps9.txt', lang = 'es')<br \/>Caps10 &lt;- tokenize('\/home\/lenovo\/investigacion\/Documents\/Guatemala\/Caps10.txt', lang = 'es')<br \/>Caps11 &lt;- tokenize('\/home\/lenovo\/investigacion\/Documents\/Guatemala\/Caps11.txt', lang = 'es')<br \/>Caps12 &lt;- tokenize('\/home\/lenovo\/investigacion\/Documents\/Guatemala\/Caps12.txt', lang = 'es')<br \/>ProtGua &lt;- tokenize('\/home\/lenovo\/investigacion\/Documents\/Guatemala\/ProtocoloGuatemala.txt', lang = 'es')<br \/># Let's calculate the SMOG grading for all these documents<br \/>SMOG(Caps1)<br \/>SMOG(Caps2)<br \/>SMOG(Caps3)<br \/>SMOG(Caps4)<br \/>SMOG(Caps5)<br \/>SMOG(Caps6)<br \/>SMOG(Caps7)<br \/>SMOG(Caps8)<br \/>SMOG(Caps9)<br \/>SMOG(Caps10)<br \/>SMOG(Caps11)<br \/>SMOG(Caps12)<br \/>SMOG(ProtGua)<\/p>\n<p>################################################<br \/>### ANALYZING ALL PEACE AGREEMENTS AT ONCE #####<br \/>################################################<\/p>\n<p># We can build a new dataset with the values resulting from the SMOG analyses that we <br \/># just applied to all documents<br \/>Country &lt;- c('Colombia', 'Colombia', 'Colombia', 'Colombia', 'Colombia', 'Colombia', 'Colombia', 'Salvador', 'Salvador', 'Salvador', 'Salvador', 'Salvador', 'Salvador', 'Salvador', 'Salvador', 'Salvador', 'Salvador', 'Salvador', 'Salvador', 'Guatemala', 'Guatemala', 'Guatemala', 'Guatemala', 'Guatemala', 'Guatemala', 'Guatemala', 'Guatemala', 'Guatemala', 'Guatemala', 'Guatemala', 'Guatemala', 'Guatemala')<br \/>TextID &lt;- c('Addendum', 'Point1', 'Point2', 'Point3', 'Point4', 'Point5', 'Point6', 'Acts', 'Cap1', 'Cap2', 'Cap3', 'Cap4', 'Cap5', 'Cap6', 'Cap7', 'Cap8', 'Cap9', 'DecFin', 'Intro', 'Caps1', 'Caps2', 'Caps3', 'Caps4', 'Caps5', 'Caps6', 'Caps7', 'Caps8', 'Caps9', 'Caps10', 'Caps11', 'Caps12', 'ProtGua')<br \/>Smog &lt;- c(18.71, 19.19, 21.05, 19.17, 21.1, 21.11, 18.94, 14.8, 18.84, 19.6, 24.85, 21.64, 21.51, 15.9, 17.3, 18.51, 10.14, 14.96, 19.85, 19.29, 18.58, 18.25, 19.29, 20.15, 20.79, 19.71, 17.02, 20.33, 19.16, 18.32, 18.79, 17.11)<br \/>Age &lt;- c(23.71, 24.19, 26.05, 24.17, 26.1, 26.11, 23.94, 19.8, 23.84, 24.6, 29.85, 26.64, 26.51, 20.9, 22.3, 23.51, 15.14, 19.96, 24.85, 24.29, 23.58, 23.25, 24.29, 25.15, 25.79, 24.71, 22.02, 25.33, 24.16, 23.32, 23.79, 22.11)<br \/>PeaceReadability &lt;- data.frame(Country, TextID, Smog, Age)<br \/># Let's export this dataset to an Excel file<br \/>write.csv(PeaceReadability, file = 'PeaceReadability.csv')<br \/># Let's take a look at the resulting SMOG grading<br \/>library(psych)<br \/>describe.by(PeaceReadability$Smog, group = PeaceReadability$country)<br \/>describe.by(PeaceReadability$Age, group = PeaceReadability$country)<br \/># Now let's take a look at the total of polysyllables.<br \/>library(qdap)<br \/>library(tibble)<br \/>ColombianPolysyllables &lt;- as_tibble(combo_syllable_sum(ColombianFrequentTerms$Words))<br \/>GuatemalanPolysyllables &lt;- as_tibble(combo_syllable_sum(FrequentTermsGuatemala$Words))<br \/>SalvadoranPolysyllables &lt;- as_tibble(combo_syllable_sum(FrequentTermsSalvador$Words))<br \/>describe(ColombianPolysyllables$polysyllable.count)<br \/>describe(GuatemalanPolysyllables$polysyllable.count)<br \/>describe(SalvadoranPolysyllables$polysyllable.count) <br \/>library(ggplot2) <br \/>ggplot(PeaceReadability, aes(Smog, fill = Country, colour = Country)) + geom_density(alpha = 0.1) <br \/># What about the age that the person must be to fully understand these text?<br \/>ggplot(PeaceReadability, aes(Age, fill = Country, colour = Country)) + geom_density(alpha = 0.1) <br \/># Do these graphs indicate significant statistical differences between the accords? Let's<br \/># test it<br \/>fit &lt;- aov(Smog ~ Country, data=PeaceReadability)<br \/>summary(fit)<br \/># The results show that the differences among these peace accords proved to be not significant.<br \/>#<br \/># Now, let's analyze all documents in just one 'big' corpus<br \/>LatinAmericans &lt;- file.path('\/home\/lenovo\/investigacion\/Documents\/LatinAmericanAgreements')<br \/>dir(LatinAmericans)<br \/>library(tm)<br \/># Create another object as a corpus containing all parts of the Colombian<br \/># Agreement<br \/>LatinAmericans &lt;- Corpus(DirSource(LatinAmericans))<br \/># You can check the contents of this last object like this<br \/>summary(LatinAmericans)<br \/>LatinDocs &lt;- summary(LatinAmericans)<br \/>#Now lets begin with the preprocessing<br \/>#Remove punctuation<br \/>LatinAmericans &lt;- tm_map(LatinAmericans, removePunctuation)<br \/>#Remove Numbers<br \/>LatinAmericans &lt;- tm_map(LatinAmericans, removeNumbers)<br \/>#Convert all words in lowercase<br \/>LatinAmericans &lt;- tm_map(LatinAmericans, tolower)<br \/>#Remove Stopwords<br \/>LatinAmericans &lt;- tm_map(LatinAmericans, removeWords, stopwords('spanish'))<br \/>#Remove additional white spaces between words<br \/>LatinAmericans &lt;- tm_map(LatinAmericans, stripWhitespace)<br \/>#Save The Colombian Signed Peace Agreement as Plain Document<br \/>LatinAmericans &lt;- tm_map(LatinAmericans, PlainTextDocument)<br \/># Let's apply stemming procedure for retrieving suffices of words<br \/>LatinAmericans &lt;- tm_map(LatinAmericans, stemDocument, language = 'spanish')<br \/>#Begin the Analysis by creating a Document-Term Matrix<br \/>dtmLatin &lt;- DocumentTermMatrix(LatinAmericans)<br \/>#You can check the dtm by typing<br \/>dtmLatin<br \/># You can transpose this matrix, If you want<br \/>tdmLatin &lt;- TermDocumentMatrix(LatinAmericans)<br \/># Let's explore terms frequencies<br \/>freqLatin &lt;- colSums(as.matrix(dtmLatin))<br \/># Now let's order these terms from least frequents to most frequents ones. This 'ord' object<br \/># will be used later when computing wordcloud.<br \/>ordLatin &lt;- order(freqLatin)<br \/># Let's remove sparse terms from this Term-Document Matrix with, say 10% empty space<br \/>NSTDMLatin &lt;- removeSparseTerms(tdmLatin, 0.1)<br \/># Let's see most and least frequent words in all documents<br \/>freqLatin[tail(ordLatin)]<br \/>freqLatin[head(ordLatin)]<br \/># Do you want to export this info as a table in Excel?<br \/>FreqTermsLatin &lt;- as.matrix(tdmLatin)<br \/>dim(FreqTermsLatin)<br \/>write.csv(FreqTermsLatin, file = 'LatinFrequentTerms.csv')<br \/># Note that terms are in rows, and columns represent each document<br \/># Let's open this new matrix<br \/>library(readr)<br \/>LatinFrequentTerms &lt;- read_csv('~\/LatinFrequentTerms.csv')<br \/>names(LatinFrequentTerms) &lt;-c('Words', 'col1', 'col2', 'col3', 'col4', 'col5', 'col6', 'col7', 'gua1', 'gua2', 'gua3', 'gua4', 'gua5', 'gua6', 'gua7', 'gua8', 'gua9', 'gua10', 'gua11', 'gua12', 'gua13', 'sal1', 'sal2', 'sal3', 'sal4', 'sal5', 'sal6', 'sal7', 'sal8', 'sal9', 'sal10', 'sal11', 'sal12')<br \/>LatinFrequentTerms$WordTotalFrequency &lt;- rowSums(LatinFrequentTerms[,2:8])<br \/># Let's take a look to the Wordcloud of the Colombian Agreement<br \/># that includes most frequent words (those that appear at least<br \/># 25 times in the whole document)<br \/>library(wordcloud)<br \/>set.seed(142)<br \/>wordcloud(names(freqLatin), freqLatin, min.freq=50)<br \/># Let's plot the most common frequent words of all three agreements<br \/>library(ggplot2)<br \/>CommonFrequentTerms &lt;- subset(LatinFrequentTerms, WordTotalFrequency&gt;180)<br \/>ggplot(CommonFrequentTerms,aes(x= reorder(Words,-WordTotalFrequency),WordTotalFrequency)) + geom_bar(stat ='identity') + ylab('Frequency') + xlab('Words') + theme(axis.text.x = element_text(angle = 90, hjust = 1))<\/p>","order_id":"0","name":"Description","data_by_id":"0","type_id":"1","source_data":{"description":"<p># The aim of this Script is to provide the reader an easy-to-use <br \/># procedure that allows the replication of our findings \u00a0<br \/># This script works for the original accords which were written in Spanish.<\/p>\n<p>################################# <br \/>### INITIALIZING THE ANALYSIS ###<br \/>#################################<br \/>if(!require(tm)){<br \/> install.packages('tm')<br \/>}<br \/># Load the required packages for Preprocesing our documents<br \/>library(tm)<\/p>\n<p><br \/># Create an object that defines the local directory in<br \/># which you saved the documents of the Colombian Signed Peace Agreement<\/p>\n<p>######################<br \/>###### COLOMBIA ######<br \/>######################<\/p>\n<p>\u00a0<\/p>\n<p>#replace the address where you downloaded the documents<br \/>documents &lt;- file.path('\/home\/lenovo\/investigacion\/Documents\/Colombia (es)')<br \/>dir(documents)<\/p>\n<p># Create another object as a corpus containing all parts of the Colombian<br \/># Agreement<br \/>ColombianDocs &lt;- Corpus(DirSource(documents))<br \/># You can check the contents of this last object like this<br \/>summary(ColombianDocs)<br \/>#Now lets begin with the preprocessing<br \/>#Remove punctuation<br \/>ColombianDocs &lt;- tm_map(ColombianDocs, removePunctuation)<br \/>#Remove Numbers<br \/>ColombianDocs &lt;- tm_map(ColombianDocs, removeNumbers)<br \/>#Convert all words in lowercase<br \/>ColombianDocs &lt;- tm_map(ColombianDocs, tolower)<br \/>#Remove Stopwords<br \/>ColombianDocs &lt;- tm_map(ColombianDocs, removeWords, stopwords('spanish'))<br \/>#Remove additional white spaces between words<br \/>ColombianDocs &lt;- tm_map(ColombianDocs, stripWhitespace)<br \/>#Save The Colombian Signed Peace Agreement as Plain Document<br \/>ColombianDocs &lt;- tm_map(ColombianDocs, PlainTextDocument)<br \/>#Begin the Analysis by creating a Document-Term Matrix<br \/>dtm &lt;- DocumentTermMatrix(ColombianDocs)<br \/>#You can check the dtm by typing<br \/>dtm<br \/># You can transpose this matrix, If you want<br \/>tdm &lt;- TermDocumentMatrix(ColombianDocs)<br \/># Let's explore terms frequencies<br \/>freq &lt;- colSums(as.matrix(dtm))<br \/># Now let's order these terms from least frequents to most frequents ones. This 'ord' object<br \/># will be used later when computing wordcloud.<br \/>ord &lt;- order(freq)<br \/># Let's remove sparse terms from this Term-Document Matrix with, say 10% empty space<br \/>NSTDM &lt;- removeSparseTerms(tdm, 0.1)<br \/># Let's see most and least frequent words in all documents<br \/>freq[tail(ord)]<br \/>freq[head(ord)]<br \/># Do you want to export this info as a table in Excel?<br \/>FreqTerms &lt;- as.matrix(tdm)<br \/>dim(FreqTerms)<br \/>write.csv(FreqTerms, file = 'ColombianFrequentTerms.csv')<br \/># Note that terms are in rows, and columns represent each document<br \/># Let's open this new matrix<br \/>if(!require(readr)){<br \/> install.packages('readr')<br \/>}<br \/>library(readr)<br \/>ColombianFrequentTerms &lt;- read_csv('~\/ColombianFrequentTerms.csv')<br \/>names(ColombianFrequentTerms) &lt;-c('Words', 'Addendum', 'Point 1', 'Point 2', 'Point 3', 'Point 4', 'Point 5', 'Point 6')<br \/>ColombianFrequentTerms$WordTotalFrequency &lt;- rowSums(ColombianFrequentTerms[,2:8])<br \/># Let's take a look to the Wordcloud of the Colombian Agreement<br \/># that includes most frequent words (those that appear at least<br \/># 25 times in the whole document)<br \/>if(!require(wordcloud)){<br \/> install.packages('wordcloud')<br \/>}<br \/>library(wordcloud)<br \/>set.seed(142)<br \/>wordcloud(names(freq), freq, min.freq=25)<\/p>\n<p>if(!require(koRpus)){<br \/> install.packages('koRpus')<br \/>}<br \/># Now, let's tokenize our documents<br \/>library(koRpus)<br \/>Addendum &lt;- tokenize('\/home\/lenovo\/investigacion\/Documents\/Colombia (es)\/protocolos.txt', lang = 'es')<br \/>Point1 &lt;- tokenize('\/home\/lenovo\/investigacion\/Documents\/Colombia (es)\/Punto1.txt', lang = 'es')<br \/>Point2 &lt;- tokenize('\/home\/lenovo\/investigacion\/Documents\/Colombia (es)\/Punto2.txt', lang = 'es')<br \/>Point3 &lt;- tokenize('\/home\/lenovo\/investigacion\/Documents\/Colombia (es)\/Punto3.txt', lang = 'es')<br \/>Point4 &lt;- tokenize('\/home\/lenovo\/investigacion\/Documents\/Colombia (es)\/Punto4.txt', lang = 'es')<br \/>Point5 &lt;- tokenize('\/home\/lenovo\/investigacion\/Documents\/Colombia (es)\/Punto5.txt', lang = 'es')<br \/>Point6 &lt;- tokenize('\/home\/lenovo\/investigacion\/Documents\/Colombia (es)\/Punto6.txt', lang = 'es')<br \/># Let's calculate the SMOG grading for all these documents<br \/>SMOG(Addendum)<br \/>SMOG(Point1)<br \/>SMOG(Point2)<br \/>SMOG(Point3)<br \/>SMOG(Point4)<br \/>SMOG(Point5)<br \/>SMOG(Point6)<br \/># Since the SMOG algorithm provides a double output (i.e., the grading instruction and the age of a person),<br \/># we can build a dataset that contains these values for all the documents of Colombia, Guatemala and El Salvador.<br \/># To do that, we need to repeat the same procedures for the other countries.<\/p>\n<p>######################<br \/>###### SALVADOR ######<br \/>######################<br \/>library(tm)<br \/>Salvador &lt;- file.path('\/home\/lenovo\/investigacion\/Documents\/Salvador')<br \/>dir(Salvador)<br \/>SalvadorDocs &lt;- Corpus(DirSource(Salvador))<br \/># You can check the contents of this last object like this<br \/>summary(SalvadorDocs)<br \/>#Now lets begin with the preprocessing<br \/>#Remove punctuation<br \/>SalvadorDocs &lt;- tm_map(SalvadorDocs, removePunctuation)<br \/>#Remove Numbers<br \/>SalvadorDocs &lt;- tm_map(SalvadorDocs, removeNumbers)<br \/>#Convert all words in lowercase<br \/>SalvadorDocs &lt;- tm_map(SalvadorDocs, tolower)<br \/>#Remove Stopwords<br \/>SalvadorDocs &lt;- tm_map(SalvadorDocs, removeWords, stopwords('spanish'))<br \/>#Remove additional white spaces between words<br \/>SalvadorDocs &lt;- tm_map(SalvadorDocs, stripWhitespace)<br \/>#Save The Colombian Signed Peace Agreement as Plain Document<br \/>SalvadorDocs &lt;- tm_map(SalvadorDocs, PlainTextDocument)<br \/>#Begin the Analysis by creating a Document-Term Matrix<br \/>dtmSalvador &lt;- DocumentTermMatrix(SalvadorDocs)<br \/>#You can check the dtm by typing<br \/>dtmSalvador<br \/># You can transpose this matrix, If you want<br \/>tdmSalvador &lt;- TermDocumentMatrix(SalvadorDocs)<br \/># Let's explore terms frequencies<br \/>freqSalvador &lt;- colSums(as.matrix(dtmSalvador))<br \/># Now let's order these terms from least frequents to most frequents ones. This 'ord' object<br \/># will be used later when computing wordcloud.<br \/>ordSalvador &lt;- order(freqSalvador)<br \/># Let's remove sparse terms from this Term-Document Matrix with, say 10% empty space<br \/>NSTDMsalvador &lt;- removeSparseTerms(tdmSalvador, 0.1)<br \/># Let's see most and least frequent words in all documents<br \/>freqSalvador[tail(ordSalvador)]<br \/>freqSalvador[head(ordSalvador)]<br \/># Do you want to export this info as a table in Excel?<br \/>FreqTermsSalvador &lt;- as.matrix(tdmSalvador)<br \/>dim(FreqTermsSalvador)<br \/>write.csv(FreqTermsSalvador, file = 'FrequentTermsSalvador.csv')<br \/># Note that terms are in rows, and columns represent each document<br \/># Let's open this new matrix<br \/>library(readr)<br \/>FrequentTermsSalvador &lt;- read_csv('~\/FrequentTermsSalvador.csv')<br \/>names(FrequentTermsSalvador) &lt;-c('Words', 'Act', 'Cap1', 'Cap2', 'Cap3', 'Cap4', 'Cap5', 'Cap6', 'Cap7', 'Cap8', 'Cap9', 'DecFin', 'Intro')<br \/>FrequentTermsSalvador$WordTotalFrequency &lt;- rowSums(FrequentTermsSalvador[,2:13])<br \/># Let's take a look to the Wordcloud of the Salvadoran Agreement<br \/># that includes most frequent words (those that appear at least<br \/># 25 times in the whole document)<br \/>library(wordcloud)<br \/>set.seed(142)<br \/>wordcloud(names(freqSalvador), freqSalvador, min.freq=25)<\/p>\n<p># Now, let's tokenize our documents<br \/>library(koRpus)<br \/>Acts &lt;- tokenize('\/home\/lenovo\/investigacion\/Documents\/Salvador\/Actas.txt', lang ='es')<br \/>Cap1 &lt;- tokenize('\/home\/lenovo\/investigacion\/Documents\/Salvador\/Cap1.txt', lang = 'es')<br \/>Cap2 &lt;- tokenize('\/home\/lenovo\/investigacion\/Documents\/Salvador\/Cap2.txt', lang = 'es')<br \/>Cap3 &lt;- tokenize('\/home\/lenovo\/investigacion\/Documents\/Salvador\/Cap3.txt', lang = 'es')<br \/>Cap4 &lt;- tokenize('\/home\/lenovo\/investigacion\/Documents\/Salvador\/Cap4.txt', lang = 'es')<br \/>Cap5 &lt;- tokenize('\/home\/lenovo\/investigacion\/Documents\/Salvador\/Cap5.txt', lang = 'es')<br \/>Cap6 &lt;- tokenize('\/home\/lenovo\/investigacion\/Documents\/Salvador\/Cap6.txt', lang = 'es')<br \/>Cap7 &lt;- tokenize('\/home\/lenovo\/investigacion\/Documents\/Salvador\/Cap7.txt', lang = 'es')<br \/>Cap8 &lt;- tokenize('\/home\/lenovo\/investigacion\/Documents\/Salvador\/Cap8.txt', lang = 'es')<br \/>Cap9 &lt;- tokenize('\/home\/lenovo\/investigacion\/Documents\/Salvador\/Cap9.txt', lang = 'es')<br \/>DecFin &lt;- tokenize('\/home\/lenovo\/investigacion\/Documents\/Salvador\/DecFin.txt', lang = 'es')<br \/>Intro &lt;- tokenize('\/home\/lenovo\/investigacion\/Documents\/Salvador\/Intro.txt', lang = 'es')<br \/># Let's calculate the SMOG grading for all these documents<br \/>SMOG(Acts)<br \/>SMOG(Cap1)<br \/>SMOG(Cap2)<br \/>SMOG(Cap3)<br \/>SMOG(Cap4)<br \/>SMOG(Cap5)<br \/>SMOG(Cap6)<br \/>SMOG(Cap7)<br \/>SMOG(Cap8)<br \/>SMOG(Cap9)<br \/>SMOG(DecFin)<br \/>SMOG(Intro)<\/p>\n<p>#######################<br \/>###### GUATEMALA ######<br \/>#######################<br \/>library(tm)<br \/>Guatemala &lt;- file.path('\/home\/lenovo\/investigacion\/Documents\/Guatemala')<br \/>dir(Guatemala)<br \/>GuatemalaDocs &lt;- Corpus(DirSource(Guatemala))<br \/>summary(GuatemalaDocs)<br \/>#Now lets begin with the preprocessing<br \/>#Remove punctuation<br \/>GuatemalaDocs &lt;- tm_map(GuatemalaDocs, removePunctuation)<br \/>#Remove Numbers<br \/>GuatemalaDocs &lt;- tm_map(GuatemalaDocs, removeNumbers)<br \/>#Convert all words in lowercase<br \/>GuatemalaDocs &lt;- tm_map(GuatemalaDocs, tolower)<br \/>#Remove Stopwords<br \/>GuatemalaDocs &lt;- tm_map(GuatemalaDocs, removeWords, stopwords('spanish'))<br \/>#Remove additional white spaces between words<br \/>GuatemalaDocs &lt;- tm_map(GuatemalaDocs, stripWhitespace)<br \/>#Save The Colombian Signed Peace Agreement as Plain Document<br \/>GuatemalaDocs &lt;- tm_map(GuatemalaDocs, PlainTextDocument)<br \/>#Begin the Analysis by creating a Document-Term Matrix<br \/>dtmGuatemala &lt;- DocumentTermMatrix(GuatemalaDocs)<br \/>#You can check the dtm by typing<br \/>dtmGuatemala<br \/># You can transpose this matrix, If you want<br \/>tdmGuatemala &lt;- TermDocumentMatrix(GuatemalaDocs)<br \/># Let's explore terms frequencies<br \/>freqGuatemala &lt;- colSums(as.matrix(dtmGuatemala))<br \/># Now let's order these terms from least frequents to most frequents ones. This 'ord' object<br \/># will be used later when computing wordcloud.<br \/>ordGuatemala &lt;- order(freqGuatemala)<br \/># Let's remove sparse terms from this Term-Document Matrix with, say 10% empty space<br \/>NSTDMguatemala &lt;- removeSparseTerms(tdmGuatemala, 0.1)<br \/># Let's see most and least frequent words in all documents<br \/>freqGuatemala[tail(ordGuatemala)]<br \/>freqGuatemala[head(ordGuatemala)]<br \/># Do you want to export this info as a table in Excel?<br \/>FreqTermsGuatemala &lt;- as.matrix(tdmGuatemala)<br \/>dim(FreqTermsGuatemala)<br \/>write.csv(FreqTermsGuatemala, file = 'FrequentTermsGuatemala.csv')<br \/># Note that terms are in rows, and columns represent each document<br \/># Let's open this new matrix<br \/>library(readr)<br \/>FrequentTermsGuatemala &lt;- read_csv('~\/FrequentTermsGuatemala.csv')<br \/>names(FrequentTermsGuatemala) &lt;-c('Words', 'Caps1', 'Caps2', 'Caps3', 'Caps4', 'Caps5', 'Caps6', 'Caps7', 'Caps8', 'Caps9', 'Caps10', 'Caps11', 'Caps12', 'ProtGua')<br \/>FrequentTermsGuatemala$WordTotalFrequency &lt;- rowSums(FrequentTermsGuatemala[,2:14])<br \/># Let's take a look to the Wordcloud of the Guatemalian Agreement<br \/># that includes most frequent words (those that appear at least<br \/># 25 times in the whole document)<br \/>library(wordcloud)<br \/>set.seed(142)<br \/>wordcloud(names(freqGuatemala), freqGuatemala, min.freq=25)<\/p>\n<p># Now, let's tokenize our documents<br \/>library(koRpus)<br \/>Caps1 &lt;- tokenize('\/home\/lenovo\/investigacion\/Documents\/Guatemala\/Caps1.txt', lang = 'es')<br \/>Caps2 &lt;- tokenize('\/home\/lenovo\/investigacion\/Documents\/Guatemala\/Caps2.txt', lang = 'es')<br \/>Caps3 &lt;- tokenize('\/home\/lenovo\/investigacion\/Documents\/Guatemala\/Caps3.txt', lang = 'es')<br \/>Caps4 &lt;- tokenize('\/home\/lenovo\/investigacion\/Documents\/Guatemala\/Caps4.txt', lang = 'es')<br \/>Caps5 &lt;- tokenize('\/home\/lenovo\/investigacion\/Documents\/Guatemala\/Caps5.txt', lang = 'es')<br \/>Caps6 &lt;- tokenize('\/home\/lenovo\/investigacion\/Documents\/Guatemala\/Caps6.txt', lang = 'es')<br \/>Caps7 &lt;- tokenize('\/home\/lenovo\/investigacion\/Documents\/Guatemala\/Caps7.txt', lang = 'es')<br \/>Caps8 &lt;- tokenize('\/home\/lenovo\/investigacion\/Documents\/Guatemala\/Caps8.txt', lang = 'es')<br \/>Caps9 &lt;- tokenize('\/home\/lenovo\/investigacion\/Documents\/Guatemala\/Caps9.txt', lang = 'es')<br \/>Caps10 &lt;- tokenize('\/home\/lenovo\/investigacion\/Documents\/Guatemala\/Caps10.txt', lang = 'es')<br \/>Caps11 &lt;- tokenize('\/home\/lenovo\/investigacion\/Documents\/Guatemala\/Caps11.txt', lang = 'es')<br \/>Caps12 &lt;- tokenize('\/home\/lenovo\/investigacion\/Documents\/Guatemala\/Caps12.txt', lang = 'es')<br \/>ProtGua &lt;- tokenize('\/home\/lenovo\/investigacion\/Documents\/Guatemala\/ProtocoloGuatemala.txt', lang = 'es')<br \/># Let's calculate the SMOG grading for all these documents<br \/>SMOG(Caps1)<br \/>SMOG(Caps2)<br \/>SMOG(Caps3)<br \/>SMOG(Caps4)<br \/>SMOG(Caps5)<br \/>SMOG(Caps6)<br \/>SMOG(Caps7)<br \/>SMOG(Caps8)<br \/>SMOG(Caps9)<br \/>SMOG(Caps10)<br \/>SMOG(Caps11)<br \/>SMOG(Caps12)<br \/>SMOG(ProtGua)<\/p>\n<p>################################################<br \/>### ANALYZING ALL PEACE AGREEMENTS AT ONCE #####<br \/>################################################<\/p>\n<p># We can build a new dataset with the values resulting from the SMOG analyses that we <br \/># just applied to all documents<br \/>Country &lt;- c('Colombia', 'Colombia', 'Colombia', 'Colombia', 'Colombia', 'Colombia', 'Colombia', 'Salvador', 'Salvador', 'Salvador', 'Salvador', 'Salvador', 'Salvador', 'Salvador', 'Salvador', 'Salvador', 'Salvador', 'Salvador', 'Salvador', 'Guatemala', 'Guatemala', 'Guatemala', 'Guatemala', 'Guatemala', 'Guatemala', 'Guatemala', 'Guatemala', 'Guatemala', 'Guatemala', 'Guatemala', 'Guatemala', 'Guatemala')<br \/>TextID &lt;- c('Addendum', 'Point1', 'Point2', 'Point3', 'Point4', 'Point5', 'Point6', 'Acts', 'Cap1', 'Cap2', 'Cap3', 'Cap4', 'Cap5', 'Cap6', 'Cap7', 'Cap8', 'Cap9', 'DecFin', 'Intro', 'Caps1', 'Caps2', 'Caps3', 'Caps4', 'Caps5', 'Caps6', 'Caps7', 'Caps8', 'Caps9', 'Caps10', 'Caps11', 'Caps12', 'ProtGua')<br \/>Smog &lt;- c(18.71, 19.19, 21.05, 19.17, 21.1, 21.11, 18.94, 14.8, 18.84, 19.6, 24.85, 21.64, 21.51, 15.9, 17.3, 18.51, 10.14, 14.96, 19.85, 19.29, 18.58, 18.25, 19.29, 20.15, 20.79, 19.71, 17.02, 20.33, 19.16, 18.32, 18.79, 17.11)<br \/>Age &lt;- c(23.71, 24.19, 26.05, 24.17, 26.1, 26.11, 23.94, 19.8, 23.84, 24.6, 29.85, 26.64, 26.51, 20.9, 22.3, 23.51, 15.14, 19.96, 24.85, 24.29, 23.58, 23.25, 24.29, 25.15, 25.79, 24.71, 22.02, 25.33, 24.16, 23.32, 23.79, 22.11)<br \/>PeaceReadability &lt;- data.frame(Country, TextID, Smog, Age)<br \/># Let's export this dataset to an Excel file<br \/>write.csv(PeaceReadability, file = 'PeaceReadability.csv')<br \/># Let's take a look at the resulting SMOG grading<br \/>library(psych)<br \/>describe.by(PeaceReadability$Smog, group = PeaceReadability$country)<br \/>describe.by(PeaceReadability$Age, group = PeaceReadability$country)<br \/># Now let's take a look at the total of polysyllables.<br \/>library(qdap)<br \/>library(tibble)<br \/>ColombianPolysyllables &lt;- as_tibble(combo_syllable_sum(ColombianFrequentTerms$Words))<br \/>GuatemalanPolysyllables &lt;- as_tibble(combo_syllable_sum(FrequentTermsGuatemala$Words))<br \/>SalvadoranPolysyllables &lt;- as_tibble(combo_syllable_sum(FrequentTermsSalvador$Words))<br \/>describe(ColombianPolysyllables$polysyllable.count)<br \/>describe(GuatemalanPolysyllables$polysyllable.count)<br \/>describe(SalvadoranPolysyllables$polysyllable.count) <br \/>library(ggplot2) <br \/>ggplot(PeaceReadability, aes(Smog, fill = Country, colour = Country)) + geom_density(alpha = 0.1) <br \/># What about the age that the person must be to fully understand these text?<br \/>ggplot(PeaceReadability, aes(Age, fill = Country, colour = Country)) + geom_density(alpha = 0.1) <br \/># Do these graphs indicate significant statistical differences between the accords? Let's<br \/># test it<br \/>fit &lt;- aov(Smog ~ Country, data=PeaceReadability)<br \/>summary(fit)<br \/># The results show that the differences among these peace accords proved to be not significant.<br \/>#<br \/># Now, let's analyze all documents in just one 'big' corpus<br \/>LatinAmericans &lt;- file.path('\/home\/lenovo\/investigacion\/Documents\/LatinAmericanAgreements')<br \/>dir(LatinAmericans)<br \/>library(tm)<br \/># Create another object as a corpus containing all parts of the Colombian<br \/># Agreement<br \/>LatinAmericans &lt;- Corpus(DirSource(LatinAmericans))<br \/># You can check the contents of this last object like this<br \/>summary(LatinAmericans)<br \/>LatinDocs &lt;- summary(LatinAmericans)<br \/>#Now lets begin with the preprocessing<br \/>#Remove punctuation<br \/>LatinAmericans &lt;- tm_map(LatinAmericans, removePunctuation)<br \/>#Remove Numbers<br \/>LatinAmericans &lt;- tm_map(LatinAmericans, removeNumbers)<br \/>#Convert all words in lowercase<br \/>LatinAmericans &lt;- tm_map(LatinAmericans, tolower)<br \/>#Remove Stopwords<br \/>LatinAmericans &lt;- tm_map(LatinAmericans, removeWords, stopwords('spanish'))<br \/>#Remove additional white spaces between words<br \/>LatinAmericans &lt;- tm_map(LatinAmericans, stripWhitespace)<br \/>#Save The Colombian Signed Peace Agreement as Plain Document<br \/>LatinAmericans &lt;- tm_map(LatinAmericans, PlainTextDocument)<br \/># Let's apply stemming procedure for retrieving suffices of words<br \/>LatinAmericans &lt;- tm_map(LatinAmericans, stemDocument, language = 'spanish')<br \/>#Begin the Analysis by creating a Document-Term Matrix<br \/>dtmLatin &lt;- DocumentTermMatrix(LatinAmericans)<br \/>#You can check the dtm by typing<br \/>dtmLatin<br \/># You can transpose this matrix, If you want<br \/>tdmLatin &lt;- TermDocumentMatrix(LatinAmericans)<br \/># Let's explore terms frequencies<br \/>freqLatin &lt;- colSums(as.matrix(dtmLatin))<br \/># Now let's order these terms from least frequents to most frequents ones. This 'ord' object<br \/># will be used later when computing wordcloud.<br \/>ordLatin &lt;- order(freqLatin)<br \/># Let's remove sparse terms from this Term-Document Matrix with, say 10% empty space<br \/>NSTDMLatin &lt;- removeSparseTerms(tdmLatin, 0.1)<br \/># Let's see most and least frequent words in all documents<br \/>freqLatin[tail(ordLatin)]<br \/>freqLatin[head(ordLatin)]<br \/># Do you want to export this info as a table in Excel?<br \/>FreqTermsLatin &lt;- as.matrix(tdmLatin)<br \/>dim(FreqTermsLatin)<br \/>write.csv(FreqTermsLatin, file = 'LatinFrequentTerms.csv')<br \/># Note that terms are in rows, and columns represent each document<br \/># Let's open this new matrix<br \/>library(readr)<br \/>LatinFrequentTerms &lt;- read_csv('~\/LatinFrequentTerms.csv')<br \/>names(LatinFrequentTerms) &lt;-c('Words', 'col1', 'col2', 'col3', 'col4', 'col5', 'col6', 'col7', 'gua1', 'gua2', 'gua3', 'gua4', 'gua5', 'gua6', 'gua7', 'gua8', 'gua9', 'gua10', 'gua11', 'gua12', 'gua13', 'sal1', 'sal2', 'sal3', 'sal4', 'sal5', 'sal6', 'sal7', 'sal8', 'sal9', 'sal10', 'sal11', 'sal12')<br \/>LatinFrequentTerms$WordTotalFrequency &lt;- rowSums(LatinFrequentTerms[,2:8])<br \/># Let's take a look to the Wordcloud of the Colombian Agreement<br \/># that includes most frequent words (those that appear at least<br \/># 25 times in the whole document)<br \/>library(wordcloud)<br \/>set.seed(142)<br \/>wordcloud(names(freqLatin), freqLatin, min.freq=50)<br \/># Let's plot the most common frequent words of all three agreements<br \/>library(ggplot2)<br \/>CommonFrequentTerms &lt;- subset(LatinFrequentTerms, WordTotalFrequency&gt;180)<br \/>ggplot(CommonFrequentTerms,aes(x= reorder(Words,-WordTotalFrequency),WordTotalFrequency)) + geom_bar(stat ='identity') + ylab('Frequency') + xlab('Words') + theme(axis.text.x = element_text(angle = 90, hjust = 1))<\/p>"},"is_project":0},{"component_id":"877559","previous_id":"877589","original_id":"0","guid":"AF6B6881F63644D58ABBEA806A1B2C21","previous_guid":"1A313073B3FD430F87EF98A45F193840","component_type_id":"6","data_id":"0","data":"Running the analysis (with an R script)","order_id":"1","name":"Section","data_by_id":"0","type_id":"6","source_data":{"section":"Running the analysis (with an R script)"},"is_project":0}]}]}