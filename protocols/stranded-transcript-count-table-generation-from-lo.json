{"id":18158,"title":"Stranded Transcript Count Table Generation from Long Reads","title_html":"Stranded Transcript Count Table Generation from Long Reads","image":{"source":"https:\/\/www.protocols.io\/img\/default_protocol.png","placeholder":"https:\/\/www.protocols.io\/img\/default_protocol.png"},"doi":"dx.doi.org\/10.17504\/protocols.io.vyne7ve","doi_status":2,"uri":"stranded-transcript-count-table-generation-from-lo-vyne7ve","type_id":1,"published_on":1543468874,"version_id":1,"created_on":1543438547,"categories":null,"creator":{"name":"David Eccles","affiliation":"Malaghan Institute of Medical Research (NZ)","username":"david-eccles","link":null,"image":{"source":"https:\/\/s3.amazonaws.com\/pr-journal\/vi7jpt6.jpg","placeholder":"https:\/\/s3.amazonaws.com\/pr-journal\/vi7jpt6.jpg"},"badges":[{"id":2,"image":{"source":"\/img\/badges\/bronze.svg","placeholder":"\/img\/badges\/bronze.svg"},"name":"Author"},{"id":6,"image":{"source":"\/img\/badges\/socialbutterfly.svg","placeholder":"\/img\/badges\/socialbutterfly.svg"},"name":"Social butterfly"}],"research_interests":null},"journal":null,"journal_name":null,"journal_link":null,"public":1,"has_versions":1,"link":null,"number_of_steps":16,"authors":[{"name":"David Eccles","affiliation":"Malaghan Institute of Medical Research (NZ)","username":"david-eccles","link":null,"image":{"source":"https:\/\/s3.amazonaws.com\/pr-journal\/vi7jpt6.jpg","placeholder":"https:\/\/s3.amazonaws.com\/pr-journal\/vi7jpt6.jpg"},"badges":[],"research_interests":null}],"versions":[],"groups":[{"id":269,"uri":"awesome-DNA-from-all-kingdoms-of-life","title":"MinION user group for high molecular weight DNA extraction from all kingdoms","image":{"source":"https:\/\/s3.amazonaws.com\/pr-journal\/ftfb5nw.jpg","placeholder":"https:\/\/s3.amazonaws.com\/pr-journal\/ftfb5nw.jpg"},"tech_support":{"email":null,"phone":null,"hide_contact":0,"use_email":0},"is_member":0,"request":{"id":269,"flag":0,"is_my":false,"uid":0,"image":{"source":"https:\/\/s3.amazonaws.com\/pr-journal\/ftfb5nw.jpg","placeholder":"https:\/\/s3.amazonaws.com\/pr-journal\/ftfb5nw.jpg"},"is_member":0}}],"has_subprotocols":0,"is_subprotocol":0,"is_bookmarked":0,"forks_count":{"private":0,"public":0},"steps":[{"id":686385,"guid":"3999B10523294E7495F5E97FB0DDFCE2","previous_id":null,"previous_guid":null,"modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"DCD6580E940943938AA585658786B0E0","order_id":1,"type_id":6,"title":"Section","source":{"title":"Index Preparation"}},{"id":1054723,"guid":"A00D6046010D46C18E3D3EF0477E38FD","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">Prepare transcript index (see Guidelines for data sources)<\/div><div class = \"text-block\"><pre><code><div class = \"text-blocks\"><div class = \"text-block\">lastdb Mus_musculus.GRCm38.cds.all.fa <(zcat Mus_musculus.GRCm38.cds.all.fa.gz)<\/div><\/div><\/code><\/pre><\/div><\/div>"}}],"cases":null,"data":null,"section":null,"section_color":null},{"id":686386,"guid":"0D7DBA0BAFD34961B1037A4EC1D1F5F9","previous_id":686400,"previous_guid":"2663432DC7A14C408FE8EBF72A465C10","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"A8FCC98C66AA4703BCE7FA4B70569EAF","order_id":1,"type_id":6,"title":"Section","source":{"title":"Transcriptome Mapping"}},{"id":1054723,"guid":"C9077167ECF8457BA660697703A20749","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">Reads are mapped to the transcriptome with LAST.<\/div><div class = \"text-block\"><span>The results of that mapping can be piped through <\/span><span style = \"font-style:italic;\">last-map-probs<\/span><span> to exclude unlikely hits, then through <\/span><\/div><div class = \"text-block\"><a style = \"text-decoration:underline;color:blue;cursor:pointer;\"><span style = \":;\">maf_bcsplit.pl<\/span><\/a><\/div><div class = \"text-block\"> to convert to a one-line-per-mapping CSV format. This CSV format is further processed to make sure that there is only one mapping per transcript-read pair, and then aggregated to sum up counts per transcript.<\/div><div class = \"text-block\"><pre><code><div class = \"text-blocks\"><div class = \"text-block\">mkdir -p mapped<\/div><div class = \"text-block\">cat used_barcodes.txt | while read bc<\/div><div class = \"text-block\">  do echo \"** ${bc} **\";<\/div><div class = \"text-block\">  lastal -P 10 Mus_musculus.GRCm38.cds.all.fa <(pv demultiplexed\/${bc}\/${bc}_reads_dirAdjusted.fasta.gz | zcat) | \\<\/div><div class = \"text-block\">    last-map-probs | ~\/scripts\/maf_bcsplit.pl | tail -n +2 | \\<\/div><div class = \"text-block\">    awk -F',' '{print $1,$2,$3}' | sort | uniq | \\<\/div><div class = \"text-block\">    awk -v \"bc=${bc}\" '{print bc,$2,$3}' | sort | uniq -c | gzip > mapped\/trnCounts_LAST_${bc}_vs_Mmus_transcriptome.txt.gz;<\/div><div class = \"text-block\">done<\/div><\/div><\/code><\/pre><\/div><\/div>"}}],"cases":null,"data":null,"section":null,"section_color":null},{"id":686387,"guid":"9CEEFF042FF0406083764CF418B14A75","previous_id":686386,"previous_guid":"0D7DBA0BAFD34961B1037A4EC1D1F5F9","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"53FC339FA6A74DC3B73818415F42FB77","order_id":1,"type_id":6,"title":"Section","source":{"title":"Annotation and Result generation"}},{"id":1054723,"guid":"A72314C1558B44CBAE4AC7AC1242507B","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">Transcript counts are merged with ensembl gene annotation, then converted into wide format (one line per transcript) using an R script.<\/div><div class = \"text-block\">The transcript annotation in this case is from ensembl BioMart (see Guidelines for more details).<\/div><div class = \"text-block\"><pre><code><div class = \"text-blocks\"><div class = \"text-block\">#!\/usr\/bin\/env Rscript<\/div><div class = \"text-block\">library(dplyr);<\/div><div class = \"text-block\">library(tidyr);<\/div><div class = \"text-block\">## load ensemble transcript metadata (including gene name)<\/div><div class = \"text-block\">ensembl.df <- as.tbl(read.delim('ensembl_mm10_geneFeatureLocations.txt.gz',                          <\/div><div class = \"text-block\">  col.names=c('transcript','Description','Start','End',<\/div><div class = \"text-block\">              'Strand','Gene','Chr'),<\/div><div class = \"text-block\">  stringsAsFactors=FALSE));<\/div><div class = \"text-block\">ensembl.df$Description <- sub(' \\\\[.*$','',ensembl.df$Description);<\/div><div class = \"text-block\">ensembl.df$Description <- sub('^(.{50}).+$','\\\\1...',ensembl.df$Description);<\/div><div class = \"text-block\">ensembl.df[,1:7] <- ensembl.df[,c(1,7,5,3,4,2,6)];<\/div><div class = \"text-block\">colnames(ensembl.df)[1:7] <- colnames(ensembl.df)[c(1,7,5,3,4,2,6)];<\/div><div class = \"text-block\">options(scipen=15); ## don't show scientific notation for large positions<\/div><div class = \"text-block\">## load used barcode identifiers<\/div><div class = \"text-block\">bcNames <- readLines('used_barcodes.txt');<\/div><div class = \"text-block\">## load count data into 'narrow' array (one line per count)<\/div><div class = \"text-block\">trn.counts <- tibble(); for(bc in bcNames){<\/div><div class = \"text-block\">  trn.counts <-<\/div><div class = \"text-block\">    bind_rows(trn.counts,<\/div><div class = \"text-block\">      as.tbl(read.table(<\/div><div class = \"text-block\">        sprintf('mapped\/trnCounts_LAST_%s_vs_Mmus_transcriptome.txt.gz', bc),<\/div><div class = \"text-block\">        col.names=c('count','barcode','transcript','dir'),<\/div><div class = \"text-block\">        stringsAsFactors=FALSE)));<\/div><div class = \"text-block\">}<\/div><div class = \"text-block\">## remove revision number from transcript names (if present)<\/div><div class = \"text-block\">trn.counts$transcript <- sub('\\\\.[0-9]+$','',trn.counts$transcript);<\/div><div class = \"text-block\">## convert to wide format (one line per transcript)<\/div><div class = \"text-block\">trn.counts.wide <- spread(trn.counts, barcode, count) %>%<\/div><div class = \"text-block\">  mutate(dir = c('+'='fwd', '-'='rev')[dir]);<\/div><div class = \"text-block\">for(bd in colnames(trn.counts.wide[,-1])){<\/div><div class = \"text-block\">  trn.counts.wide[[bd]] <- replace_na(trn.counts.wide[[bd]],0);<\/div><div class = \"text-block\">}<\/div><div class = \"text-block\">## merge ensembl metadata with transcript counts<\/div><div class = \"text-block\">gene.counts.wide <- inner_join(ensembl.df, trn.counts.wide, by='transcript');<\/div><div class = \"text-block\">gene.counts.wide <- gene.counts.wide[order(-rowSums(gene.counts.wide[,-(1:8)])),];<\/div><div class = \"text-block\">## write result out to a file<\/div><div class = \"text-block\">write.csv(gene.counts.wide, file='wide_transcript_counts_LAST.csv', <\/div><div class = \"text-block\">  row.names=FALSE);<\/div><\/div><\/code><\/pre><\/div><\/div>"}}],"cases":null,"data":null,"section":null,"section_color":null},{"id":686388,"guid":"B2FA03F1C24E4B0CA5DF2104D150BEE9","previous_id":686391,"previous_guid":"1AF6CA5413C544C99547D33BFC4171A3","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"30EB7658ECA946DC85E8700DE376C740","order_id":1,"type_id":6,"title":"Section","source":{"title":"Read Correction"}},{"id":1054723,"guid":"EB33398BC09346EC8261EE98D7A05A26","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">Correct collated reads with canu (v1.8+). To make sure that all reads are considered, the genomeSize parameter should be set to about 1\/20 of the total number of uncorrected bases.<\/div><div class = \"text-block\"><pre><code><div class = \"text-blocks\"><div class = \"text-block\">canu -correct overlapper=minimap genomeSize=400M \\<\/div><div class = \"text-block\">  minReadLength=100 minOverlapLength=30 -p canu_corrected -d canu_corrected -nanopore-raw .\/called_pass.fastq.gz \\<\/div><div class = \"text-block\">  .\/called_fail.fastq.gz<\/div><\/div><\/code><\/pre><\/div><\/div>"}}],"cases":null,"data":null,"section":null,"section_color":null},{"id":686389,"guid":"350BE152AF574DA78BE2F6B8E6BF3A36","previous_id":686385,"previous_guid":"3999B10523294E7495F5E97FB0DDFCE2","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"DE500BAB5A7340CB968505FD9CAAC401","order_id":1,"type_id":6,"title":"Section","source":{"title":"Index Preparation"}},{"id":1054723,"guid":"67211D1FB2214A41932302BA6F1B616E","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">\u00a0Prepare barcode adapter index<\/div><div class = \"text-block\"><pre><code><div class = \"text-blocks\"><div class = \"text-block\">lastdb -uNEAR -R01 barcode_base.fa barcode_base.fa<\/div><\/div><\/code><\/pre><\/div><\/div>"}},{"id":1054723,"guid":"28F814BDC359420680822CA0554E768A","order_id":2,"type_id":23,"title":"file","source":{"source":"https:\/\/s3.amazonaws.com\/pr-journal\/5jwjpt6.fa","placeholder":"https:\/\/stage.protocols.io\/img\/extensions\/file.png","original_name":"barcode_base.fa"}}],"cases":null,"data":null,"section":null,"section_color":null},{"id":686390,"guid":"747128E0FC274675AED1823E513D084C","previous_id":686389,"previous_guid":"350BE152AF574DA78BE2F6B8E6BF3A36","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"00363EE69B12475CB0C0232EC186C142","order_id":1,"type_id":6,"title":"Section","source":{"title":"Index Preparation"}},{"id":1054723,"guid":"D2436733EF5746D88AB41A81D4A6B59B","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">Prepare cDNA adapter index<\/div><div class = \"text-block\"><pre><code><div class = \"text-blocks\"><div class = \"text-block\">lastdb -uNEAR -R01 adapter_seqs.fa adapter_seqs.fa<\/div><\/div><\/code><\/pre><\/div><\/div>"}},{"id":1054723,"guid":"20D39CF346E04724A9F99A8C5B8D8DD1","order_id":2,"type_id":23,"title":"file","source":{"source":"https:\/\/s3.amazonaws.com\/pr-journal\/5jvjpt6.fa","placeholder":"https:\/\/stage.protocols.io\/img\/extensions\/file.png","original_name":"adapter_seqs.fa"}}],"cases":null,"data":null,"section":null,"section_color":null},{"id":686391,"guid":"1AF6CA5413C544C99547D33BFC4171A3","previous_id":686390,"previous_guid":"747128E0FC274675AED1823E513D084C","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"6E4D36553D9947A389C80B619A616989","order_id":1,"type_id":6,"title":"Section","source":{"title":"Read Correction"}},{"id":1054723,"guid":"1ADDEDEB4BF848D382B9296CA688F646","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">Collate basecalled reads into separate files for pass and fail (but all barcodes thrown together)<\/div><div class = \"text-block\"><pre><code><div class = \"text-blocks\"><div class = \"text-block\">pv workspace\/fail\/*\/*.fastq | gzip > called_fail.fastq.gz<\/div><div class = \"text-block\">pv workspace\/pass\/*\/*.fastq | gzip > called_pass.fastq.gz<\/div><\/div><\/code><\/pre><\/div><\/div>"}}],"cases":null,"data":null,"section":null,"section_color":null},{"id":686392,"guid":"2E2243C359404675BE85CEEA210A4091","previous_id":686388,"previous_guid":"B2FA03F1C24E4B0CA5DF2104D150BEE9","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"75D63D4C1C9A42B49AA7407B7C006EB8","order_id":1,"type_id":6,"title":"Section","source":{"title":"Read Correction"}},{"id":1054723,"guid":"1C8BB5C54FE0429B901291C9C70C4492","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">Identify corrected reads using <\/div><div class = \"text-block\"><a style = \"text-decoration:underline;color:blue;cursor:pointer;\"><span style = \":;\">fastx-length.pl<\/span><\/a><\/div><div class = \"text-block\"><pre><code><div class = \"text-blocks\"><div class = \"text-block\">~\/scripts\/fastx-length.pl <(pv canu_corrected\/canu_corrected.correctedReads.fasta.gz) | \\<\/div><div class = \"text-block\">  awk '{print $2}' | gzip > corrected_readNames.txt.gz<\/div><\/div><\/code><\/pre><\/div><\/div>"}}],"cases":null,"data":null,"section":null,"section_color":null},{"id":686393,"guid":"A1A5CBD55EE0447F9FAB087FF8D46CE6","previous_id":686392,"previous_guid":"2E2243C359404675BE85CEEA210A4091","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"D6F762828E084668996BD439E3A2F363","order_id":1,"type_id":6,"title":"Section","source":{"title":"Read Correction"}},{"id":1054723,"guid":"62556A007AD748DD937536593802B536","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">Extract uncorrected reads using <\/div><div class = \"text-block\"><a style = \"text-decoration:underline;color:blue;cursor:pointer;\"><span style = \":;\">fastx-fetch.pl<\/span><\/a><\/div><div class = \"text-block\"><pre><code><div class = \"text-blocks\"><div class = \"text-block\">pv called_fail.fastq.gz called_pass.fastq.gz | ~\/scripts\/fastx-fetch.pl -v -i corrected_readNames.txt.gz | gzip > uncorrected_all.fastq.gz<\/div><\/div><\/code><\/pre><\/div><\/div>"}}],"cases":null,"data":null,"section":null,"section_color":null},{"id":686394,"guid":"EE639AC9A9434207825CC15451D88B88","previous_id":686393,"previous_guid":"A1A5CBD55EE0447F9FAB087FF8D46CE6","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"50844A6166AC43019D6AA3F6CFD11686","order_id":1,"type_id":6,"title":"Section","source":{"title":"Read Correction"}},{"id":1054723,"guid":"3742B23AA78446E4BCCFB1E100D4A688","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">Join corrected and uncorrected reads. The uncorrected reads are converted to fasta format with <\/div><div class = \"text-block\"><a style = \"text-decoration:underline;color:blue;cursor:pointer;\"><span style = \":;\">fastq2fasta.pl<\/span><\/a><\/div><div class = \"text-block\"> to make the joined file formats consistent.<\/div><div class = \"text-block\"><pre><code><div class = \"text-blocks\"><div class = \"text-block\">pv uncorrected_all.fastq.gz | zcat | fastq2fasta.pl | gzip > uncorrected_all.fasta.gz<\/div><div class = \"text-block\">pv uncorrected_all.fasta.gz canu_corrected\/canu_corrected.correctedReads.fasta.gz | zcat | \\<\/div><div class = \"text-block\">  gzip > uncorrected_corrected_all.fasta.gz<\/div><\/div><\/code><\/pre><\/div><\/div>"}}],"cases":null,"data":null,"section":null,"section_color":null},{"id":686395,"guid":"0DFB39352410488A9B03BE86AACE7922","previous_id":686394,"previous_guid":"EE639AC9A9434207825CC15451D88B88","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"C11682910BA84F908722C6E171E8B64C","order_id":1,"type_id":6,"title":"Section","source":{"title":"Demultiplexing"}},{"id":1054723,"guid":"9ACC76C4B8844C708CA707DEEDD66378","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\"><span>Map <\/span><span style = \"font-style:italic;\">uncorrected reads<\/span><span> to barcode sequences to generate CSV file of assignments. Canu v1.8 is very good at trimming off repetitive adapter sequences (including barcodes).<\/span><\/div><div class = \"text-block\"><pre><code><div class = \"text-blocks\"><div class = \"text-block\">lastal -Q 1 -P 10 barcode_base.fa <(pv called_*.fastq.gz | \\<\/div><div class = \"text-block\">    zcat) | ~\/scripts\/maf_bcsplit.pl | \\<\/div><div class = \"text-block\">  gzip > barcode_assignments_all.csv.gz<\/div><\/div><\/code><\/pre><\/div><\/div>"}}],"cases":null,"data":null,"section":null,"section_color":null},{"id":686396,"guid":"90195EAD0B7343429AA06561DD9288FB","previous_id":686395,"previous_guid":"0DFB39352410488A9B03BE86AACE7922","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"F17A3AFFEC8F4B23B00004EF9D711670","order_id":1,"type_id":6,"title":"Section","source":{"title":"Demultiplexing"}},{"id":1054723,"guid":"DECBF1BC5F054F00AD946BE493C3851C","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\"><span>Map <\/span><span style = \"font-style:italic;\">uncorrected reads<\/span><span> to adapter sequences to generate CSV file of assignments.<\/span><\/div><div class = \"text-block\"><pre><code><div class = \"text-blocks\"><div class = \"text-block\">lastal -Q 1 -P 10 adapter_seqs.fa <(pv called_*.fastq.gz | \\<\/div><div class = \"text-block\">    zcat) | ~\/scripts\/maf_bcsplit.pl | \\<\/div><div class = \"text-block\">  gzip > adapter_assignments_all.csv.gz<\/div><\/div><\/code><\/pre><\/div><\/div>"}}],"cases":null,"data":null,"section":null,"section_color":null},{"id":686397,"guid":"52DCF03B0C4E4744BC62CDFC4560F761","previous_id":686396,"previous_guid":"90195EAD0B7343429AA06561DD9288FB","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"ABDEC99710FC472CB41770BA8080542B","order_id":1,"type_id":6,"title":"Section","source":{"title":"Demultiplexing"}},{"id":1054723,"guid":"5E21F922402A448A877C91370F75992A","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">Create 'wide' table indicating barcode\/adapter assignments. This R script creates files 'barcode-adapter_assignments_ideal.csv.gz' and 'barcode-adapter_assignments_valid.csv.gz'.<\/div><div class = \"text-block\"><pre><code><div class = \"text-blocks\"><div class = \"text-block\">#!\/usr\/bin\/env Rscript<\/div><div class = \"text-block\">bc.df <- read.csv('barcode_assignments_all.csv.gz');<\/div><div class = \"text-block\">ad.df <- read.csv('adapter_assignments_all.csv.gz');<\/div><div class = \"text-block\">library(dplyr);<\/div><div class = \"text-block\">library(tidyr);<\/div><div class = \"text-block\">## Create table of adapter additions<\/div><div class = \"text-block\">ad.tbl <- group_by(ad.df, query, target, dir) %>%<\/div><div class = \"text-block\">     summarise() %>%<\/div><div class = \"text-block\">     unite(tdir, target, dir, sep='.') %>% mutate(present=TRUE) %>%<\/div><div class = \"text-block\">     spread(tdir, present);<\/div><div class = \"text-block\">## collapse multiple query\/target pairs into one<\/div><div class = \"text-block\">bc.tbl <- group_by(bc.df, query, target) %>%<\/div><div class = \"text-block\">  summarise(dir=paste(unique(dir), collapse='\/'));<\/div><div class = \"text-block\">bc.wide <- spread(bc.tbl, target, dir);<\/div><div class = \"text-block\">## identify reads with a unique barcode<\/div><div class = \"text-block\">bc.unique.tbl <- group_by(bc.tbl, query) %>% summarise(n = n()) %>%<\/div><div class = \"text-block\">     filter(n == 1) %>% select(-n) %>% left_join(bc.tbl, by='query') %>%<\/div><div class = \"text-block\">     left_join(ad.tbl, by='query', copy=TRUE);<\/div><div class = \"text-block\">bc.unique.tbl$`ONT_SSP.-`[is.na(bc.unique.tbl$`ONT_SSP.-`)] <- FALSE;<\/div><div class = \"text-block\">bc.unique.tbl$`ONT_SSP.+`[is.na(bc.unique.tbl$`ONT_SSP.+`)] <- FALSE;<\/div><div class = \"text-block\">bc.unique.tbl$`ONT_VNP.-`[is.na(bc.unique.tbl$`ONT_VNP.-`)] <- FALSE;<\/div><div class = \"text-block\">bc.unique.tbl$`ONT_VNP.+`[is.na(bc.unique.tbl$`ONT_VNP.+`)] <- FALSE;<\/div><div class = \"text-block\">colnames(bc.unique.tbl) <- c('query','target','bcDir','SSPrev','SSPfwd','VNPrev','VNPfwd');<\/div><div class = \"text-block\">## read is considerd 'valid' (for now) if at least one primer matches<\/div><div class = \"text-block\">bc.valid.tbl <- filter(bc.unique.tbl, (SSPrev | VNPfwd | VNPrev | SSPfwd));<\/div><div class = \"text-block\">## ideal reads have forward and reverse cDNA adapters in opposing orientations bc.ideal.tbl <- filter(bc.unique.tbl, <\/div><div class = \"text-block\">  ((SSPrev & !SSPfwd & VNPfwd & !VNPrev) | <\/div><div class = \"text-block\">   (!SSPrev & SSPfwd & !VNPfwd & VNPrev)));<\/div><div class = \"text-block\">write.csv(bc.ideal.tbl, row.names=FALSE,<\/div><div class = \"text-block\">  file=gzfile('barcode-adapter_assignments_ideal.csv.gz'), quote=FALSE);<\/div><div class = \"text-block\">write.csv(bc.valid.tbl, row.names=FALSE,<\/div><div class = \"text-block\">  file=gzfile('barcode-adapter_assignments_valid.csv.gz'), quote=FALSE);<\/div><\/div><\/code><\/pre><\/div><\/div>"}}],"cases":null,"data":null,"section":null,"section_color":null},{"id":686398,"guid":"06CB28AA2BBE4F4CA683F57D79F8FD55","previous_id":686399,"previous_guid":"2D50278370E3454D8E274F8C90047532","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"FF133F89E90845D6998B827906319C31","order_id":1,"type_id":6,"title":"Section","source":{"title":"Demultiplexing"}},{"id":1054723,"guid":"CBAB9BDE2FBB44F0B10B7849A7C0DFEB","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">Demultiplex valid reads (combined corrected and uncorrected) by barcodes using <\/div><div class = \"text-block\"><a style = \"text-decoration:underline;color:blue;cursor:pointer;\"><span style = \":;\">fastx-fetch.pl<\/span><\/a><\/div><div class = \"text-block\"><pre><code><div class = \"text-blocks\"><div class = \"text-block\">cat used_barcodes.txt | while read bc<\/div><div class = \"text-block\">  do echo \"** ${bc} **\"<\/div><div class = \"text-block\">  mkdir -p demultiplexed\/${bc};<\/div><div class = \"text-block\">  pv uncorrected_corrected_all.fasta.gz |  \\<\/div><div class = \"text-block\">    ~\/scripts\/fastx-fetch.pl -i <(zgrep ${bc} barcode-adapter_assignments_ideal.csv.gz | awk -F',' '{print $1}')  | \\<\/div><div class = \"text-block\">  gzip > demultiplexed\/${bc}\/${bc}_reads_all.fasta.gz;<\/div><div class = \"text-block\">done<\/div><\/div><\/code><\/pre><\/div><\/div>"}}],"cases":null,"data":null,"section":null,"section_color":null},{"id":686399,"guid":"2D50278370E3454D8E274F8C90047532","previous_id":686397,"previous_guid":"52DCF03B0C4E4744BC62CDFC4560F761","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"9FCFD9ED041D43BD86767B11F53510E0","order_id":1,"type_id":6,"title":"Section","source":{"title":"Demultiplexing"}},{"id":1054723,"guid":"78BAA9FFF9684522B63B147ABB11840F","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">Create a list of used barcodes<\/div><div class = \"text-block\"><pre><code><div class = \"text-blocks\"><div class = \"text-block\">zcat barcode-adapter_assignments_ideal.csv.gz | awk -F',' '{print $2}' | \\<\/div><div class = \"text-block\">  sort | uniq -c | awk '{if($1 > 100){print $2}}' > used_barcodes.txt<\/div><\/div><\/code><\/pre><\/div><\/div>"}}],"cases":null,"data":null,"section":null,"section_color":null},{"id":686400,"guid":"2663432DC7A14C408FE8EBF72A465C10","previous_id":686398,"previous_guid":"06CB28AA2BBE4F4CA683F57D79F8FD55","modified_on":0,"protocol_id":0,"components":[{"id":1054723,"guid":"7780BEE6367B4D21BD60C48093D3B36E","order_id":1,"type_id":6,"title":"Section","source":{"title":"Demultiplexing"}},{"id":1054723,"guid":"43FA83F5BD8F4BBB93740B3DCCD84F5C","order_id":1,"type_id":1,"title":"description","source":{"description":"<div class = \"text-blocks\"><div class = \"text-block\">Demultiplex barcode-demultiplexed reads by SSP direction.<\/div><div class = \"text-block\">Note that the last four values in the 'wide' table refer to the reverse and forward mappings of the SSP and VNP primers respectively). The reverse reads are reverse-complemented with <\/div><div class = \"text-block\"><a style = \"text-decoration:underline;color:blue;cursor:pointer;\"><span style = \":;\">fastx-rc.pl<\/span><\/a><\/div><div class = \"text-block\">, followed by a final concatenation to simplify the subsequent alignment steps.<\/div><div class = \"text-block\"><pre><code><div class = \"text-blocks\"><div class = \"text-block\">cat used_barcodes.txt | while read bc<\/div><div class = \"text-block\">  do echo \"** ${bc}\/fwd **\";<\/div><div class = \"text-block\">  pv demultiplexed\/${bc}\/${bc}_reads_all.fasta.gz |  \\<\/div><div class = \"text-block\">    ~\/scripts\/fastx-fetch.pl -i <(zgrep 'FALSE,TRUE,TRUE,FALSE$' barcode-adapter_assignments_ideal.csv.gz | awk -F',' '{print $1}')  | \\<\/div><div class = \"text-block\">  gzip > demultiplexed\/${bc}\/${bc}_reads_fwd.fasta.gz;<\/div><div class = \"text-block\">  echo \"** ${bc}\/rev **\";<\/div><div class = \"text-block\">  pv demultiplexed\/${bc}\/${bc}_reads_all.fasta.gz |  \\<\/div><div class = \"text-block\">    ~\/scripts\/fastx-fetch.pl -i <(zgrep 'TRUE,FALSE,FALSE,TRUE$' barcode-adapter_assignments_ideal.csv.gz | awk -F',' '{print $1}')  | \\<\/div><div class = \"text-block\">  fastx-rc.pl | gzip > demultiplexed\/${bc}\/${bc}_reads_rev.fasta.gz;<\/div><div class = \"text-block\">  pv demultiplexed\/${bc}\/${bc}_reads_fwd.fasta.gz demultiplexed\/${bc}\/${bc}_reads_rev.fasta.gz | zcat | \\<\/div><div class = \"text-block\">    gzip > demultiplexed\/${bc}\/${bc}_reads_dirAdjusted.fasta.gz<\/div><div class = \"text-block\">done<\/div><\/div><\/code><\/pre><\/div><\/div>"}}],"cases":null,"data":null,"section":null,"section_color":null}],"materials":[],"description":"<div class = \"text-blocks\"><div class = \"text-block\">This protocol is for comparing two different samples at the transcript level, using long reads that are mapped to transcripts.<\/div><div class = \"text-block\"><span style = \"font-weight:bold;\">Input(s)<\/span><span>: stranded fastq files (see steps 1-8 of <\/span><a style = \"text-decoration:underline;color:blue;cursor:pointer;\"><span style = \":;\">Stranded Mapping from Long Reads<\/span><\/a><span>), transcript reference fasta file, annotation file<\/span><\/div><div class = \"text-block\"><span style = \"font-weight:bold;\">Output(s):<\/span><span> transcript table, sorted by differential coverage, annotated with gene name \/ description \/ location<\/span><\/div><\/div>"}