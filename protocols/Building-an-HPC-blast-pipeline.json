{"uri":"Building-an-HPC-blast-pipeline-d5a82d","version_id":"0","protocol_name":"Building an HPC blast pipeline","protocol_name_html":"Building an HPC blast pipeline","is_prepublished":"0","can_edit":"0","parent_id":null,"api_version":"2","is_new_mode":"1","last_modified":"1521612001","type_id":"1","link":"","fork_id":"","public_fork_note":"","number_of_steps":"17","has_versions":"0","first_published_date":"1447127754","publish_date":"2015-11-25 01:47:02","documents":null,"have_protocol_in_step":"0","is_protocol_in_step":"0","vendor_name":"Contributed by users","vendor_link":"https:\/\/www.protocols.io","vendor_logo":"\/img\/vendors\/1.png","mod_mins":"-45","mod_secs":"1","description":"This tutorial shows you how to create a pipeline on the University of Arizona HPC. \u00a0Specifically, we will be creating a pipeline to run blast, using scripts you are writing or have already written from ABE 487 weeks <a href=\"https:\/\/github.com\/kyclark\/abe487\/tree\/master\/lab\/week10\" target=\"_blank\">10 <\/a>and <a href=\"https:\/\/github.com\/kyclark\/abe487\/tree\/master\/lab\/week11\" target=\"_blank\">11<\/a>. \u00a0The pipeline will do the following:<br \/>1. \u00a0split each of the files from the night\/day transcriptome into files with 10,000 sequences each<br \/>2. \u00a0run blastp against\u00a0<span class=\"s1\"> uniprot_sprot.fasta<br \/><\/span>3. \u00a0parse the blast results<br \/><br \/>","is_bookmarked":"0","can_reassign":"1","before_start":"","has_guidelines":"1","materials":[],"warning":"","version_class":"1922","public":"1","is_owner":"1","is_original_owner":"1","created_on":"1446567230","protocol_affiliation":"University of Arizona","affiliation":"University of Arizona","doi":"dx.doi.org\/10.17504\/protocols.io.d5a82d","doi_status":"2","changed_fork_steps":"","profile_url":"Bonnie-13y2c433","protocol_img":"https:\/\/www.protocols.io\/img\/default_protocol.png","profile_image":"https:\/\/s3.amazonaws.com\/pr-journal\/ee4bvtw.jpg","full_name":"Bonnie Hurwitz","created_by":"Bonnie Hurwitz","private_link":"41EDEF36BDA604780E61108B20FA399B","original_img":"1","username":"bonnie-hurwitz","is_retracted":"0","retraction_reason":null,"plos_id":null,"manuscript_citation":null,"journal_name":null,"is_donations_disabled":"0","is_donations_disabled_by_user":"9","item_record_id":213623,"fork_info":[],"compare_forks":[],"protocols":[],"groups":[{"group_id":"52","group_uri":"hurwitz-lab","group_name":"Hurwitz Lab","group_logo":"https:\/\/s3.amazonaws.com\/pr-journal\/iscwwe.png","requested_uid":null,"request_flag":null,"my_request":"1"},{"group_id":"83","group_uri":"abe487builtenv","group_name":"ABE487_BuiltEnv","group_logo":"","requested_uid":null,"request_flag":null,"my_request":"1"},{"group_id":"84","group_uri":"abe487hmp","group_name":"ABE487_HMP","group_logo":"","requested_uid":null,"request_flag":null,"my_request":"1"},{"group_id":"85","group_uri":"abe487emp","group_name":"ABE487_EMP","group_logo":"","requested_uid":null,"request_flag":null,"my_request":"1"}],"number_of_shared_runs":[],"ownership_history":[],"keywords":"","transfer_to_user":[],"sub_transfer":false,"is_transfer_pending":false,"number_of_bookmarks":"2","collections":[],"tags":[],"archived":0,"sub_authors":[],"sub_protocols_number":0,"can_edit_shared":0,"shared_runs":[],"is_shared_run":0,"is_shared":1,"banner":null,"contact_badges":[{"badge_id":"4","badge_image":"\/img\/badges\/gold.svg","badge_description":"Gold power author!"},{"badge_id":"5","badge_image":"\/img\/badges\/earlyadopter.svg","badge_description":"Early adopter"},{"badge_id":"6","badge_image":"\/img\/badges\/socialbutterfly.svg","badge_description":"Social butterfly"}],"number_of_comments":0,"is_locked":0,"is_locked_by":false,"authors":"Bonnie Hurwitz","authors_list":[{"name":"Bonnie Hurwitz","affiliation":"University of Arizona","username":null,"profile_image":null}],"user":{"profile_image":"https:\/\/s3.amazonaws.com\/pr-journal\/ee4bvtw.jpg","username":"bonnie-hurwitz","full_name":"Bonnie Hurwitz","created_by":"Bonnie Hurwitz"},"access":{"can_view":"1","can_remove":"0","can_add":"0","can_edit":0,"can_publish":0,"can_get_doi":0,"can_share":"0","can_move":"1","can_transfer":"1","can_download":"1","is_locked":"0"},"is_contact_suspended":0,"guidelines":"Before starting this tutorial, you need to complete the scripts from the computational homework for week <a href=\"https:\/\/github.com\/kyclark\/abe487\/blob\/master\/lab\/week10\/problems.md\" target=\"_blank\">10<\/a> and <a href=\"https:\/\/github.com\/kyclark\/abe487\/blob\/master\/lab\/week10\/problems.md\" target=\"_blank\">11<\/a>.<br \/><br \/>","status_id":"1","is_research":"1","status_info":null,"steps":[{"id":"135149","is_changed":"0","original_id":"0","is_skipped":"0","is_checked":"0","guid":"0E8D144D92604EAE89D7E42255E7CE5D","previous_guid":null,"previous_id":"0","last_modified":"1502718672","components":[{"component_id":"976104","previous_id":0,"original_id":"0","guid":"528A23D22F444DD2928FEFC069711D9A","previous_guid":null,"component_type_id":"6","data_id":null,"data":null,"order_id":"0","name":"Section","data_by_id":"0","type_id":"6","source_data":{"section":null},"is_project":0},{"component_id":"135281","previous_id":"976104","original_id":"0","guid":"3A1797649E514129B54C1FE5042B2F2F","previous_guid":"528A23D22F444DD2928FEFC069711D9A","component_type_id":"1","data_id":"0","data":"Login to the hpc (at the University of Arizona) with\u00a0your\u00a0user name","order_id":"1","name":"Description","data_by_id":"0","type_id":"1","source_data":{"description":"Login to the hpc (at the University of Arizona) with\u00a0your\u00a0user name"},"is_project":0},{"component_id":"136984","previous_id":"135281","original_id":"0","guid":"416D5AFAF6DC434389382C9A3EBB499F","previous_guid":"3A1797649E514129B54C1FE5042B2F2F","component_type_id":"26","data_id":"9263","data":"","order_id":"2","name":"Note","data_by_id":"1","type_id":"26","source_data":{"annotation_id":"9263","thread_id":"9263","id":"9263","thread_title":"Annotation on step 9 of Building an HPC blast pipeline","uri":"annotation-on-step-9-of-building-an-hpc-blast-pipeline","thread_uri":"annotation-on-step-9-of-building-an-hpc-blast-pipeline","step_id":"135900","protocol_uri":"Building-an-HPC-blast-pipeline-d5a82d","protocol_name":"Building an HPC blast pipeline","protocol_name_html":"Building an HPC blast pipeline","annotation":"Note that this script runs on the head node. \u00a0This script is not compute intensive, and we need to create the smaller files first, before we can distribute the data on the cluster as smaller blast jobs.","thread_text":"Note that this script runs on the head node. \u00a0This script is not compute intensive, and we need to create the smaller files first, before we can distribute the data on the cluster as smaller blast jobs.","body":"Note that this script runs on the head node. \u00a0This script is not compute intensive, and we need to create the smaller files first, before we can distribute the data on the cluster as smaller blast jobs.","is_private":"0","public_protocol":"1","can_edit":0,"can_delete":"0","show_name":"0","created_date":"1447127606","created_on":"1447127606","modified_on":"1447263072","last_updated":"1447263072","profile_image":"https:\/\/s3.amazonaws.com\/pr-journal\/ee4bvtw.jpg","full_name":"Bonnie Hurwitz","affiliation":"University of Arizona","username":"bonnie-hurwitz","email":"bhurwitz@email.arizona.edu","pa_useranme":"bonnie-hurwitz","comments":[]},"is_project":0},{"component_id":"136851","previous_id":"136984","original_id":"0","guid":"7B97E3C2A17F4F4285CF5D0B9C0398CD","previous_guid":"416D5AFAF6DC434389382C9A3EBB499F","component_type_id":"15","data_id":"131","data":"","order_id":"3","name":"Command","data_by_id":"1","type_id":"15","source_data":{"name":"ssh username@login.hpc.arizona.edu","description":"","os_name":"","os_version":"","can_edit":"1"},"is_project":0}]},{"id":"135150","is_changed":"0","original_id":"0","is_skipped":"0","is_checked":"0","guid":"B09D9567BA9B43CF829C9AE088F81D06","previous_guid":"0E8D144D92604EAE89D7E42255E7CE5D","previous_id":"135149","last_modified":"1502718672","components":[{"component_id":"976105","previous_id":0,"original_id":"0","guid":"2D96327281DD4604AC79B57ACEC9059B","previous_guid":null,"component_type_id":"6","data_id":null,"data":null,"order_id":"0","name":"Section","data_by_id":"0","type_id":"6","source_data":{"section":null},"is_project":0},{"component_id":"135282","previous_id":"976105","original_id":"0","guid":"A0474D6E2DE14E9DB6E7E60F3CDB82A4","previous_guid":"2D96327281DD4604AC79B57ACEC9059B","component_type_id":"1","data_id":"0","data":"Create a directory for the pipeline","order_id":"1","name":"Description","data_by_id":"0","type_id":"1","source_data":{"description":"Create a directory for the pipeline"},"is_project":0},{"component_id":"136815","previous_id":"135282","original_id":"0","guid":"93EF058776FE4B1A901FCCACC8CE584C","previous_guid":"A0474D6E2DE14E9DB6E7E60F3CDB82A4","component_type_id":"15","data_id":"118","data":null,"order_id":"2","name":"Command","data_by_id":"1","type_id":"15","source_data":{"name":"mkdir hpc-blast\ncd hpc-blast","description":"","os_name":"","os_version":"","can_edit":"1"},"is_project":0}]},{"id":"135151","is_changed":"0","original_id":"0","is_skipped":"0","is_checked":"0","guid":"043221BB00BF45028377B51D0F0007A9","previous_guid":"B09D9567BA9B43CF829C9AE088F81D06","previous_id":"135150","last_modified":"1502718672","components":[{"component_id":"976106","previous_id":0,"original_id":"0","guid":"8137B3C61AA24E019D305F3B28471F5E","previous_guid":null,"component_type_id":"6","data_id":null,"data":null,"order_id":"0","name":"Section","data_by_id":"0","type_id":"6","source_data":{"section":null},"is_project":0},{"component_id":"135283","previous_id":"976106","original_id":"0","guid":"9C81F815FA794F519012D5901E65DC17","previous_guid":"8137B3C61AA24E019D305F3B28471F5E","component_type_id":"1","data_id":"0","data":"Go to the hpc-blast directory and create sub directories to hold std-err, std-out, data, blastdb, blast-results and scripts.","order_id":"1","name":"Description","data_by_id":"0","type_id":"1","source_data":{"description":"Go to the hpc-blast directory and create sub directories to hold std-err, std-out, data, blastdb, blast-results and scripts."},"is_project":0},{"component_id":"136817","previous_id":"135283","original_id":"0","guid":"373402E55B7D43358BF692C3F4194DEC","previous_guid":"9C81F815FA794F519012D5901E65DC17","component_type_id":"15","data_id":"119","data":null,"order_id":"2","name":"Command","data_by_id":"1","type_id":"15","source_data":{"name":"mkdir std-err std-out data blastdb blast-results scripts","description":"","os_name":"","os_version":"","can_edit":"1"},"is_project":0}]},{"id":"135152","is_changed":"0","original_id":"0","is_skipped":"0","is_checked":"0","guid":"3079CA462495499EB94F07B153FC3DA2","previous_guid":"043221BB00BF45028377B51D0F0007A9","previous_id":"135151","last_modified":"1502718672","components":[{"component_id":"976107","previous_id":0,"original_id":"0","guid":"836368C2C28E4A9DA89A5F241CC976AA","previous_guid":null,"component_type_id":"6","data_id":null,"data":null,"order_id":"0","name":"Section","data_by_id":"0","type_id":"6","source_data":{"section":null},"is_project":0},{"component_id":"135284","previous_id":"976107","original_id":"0","guid":"B98F0780EB284E50B3186A368B79FF46","previous_guid":"836368C2C28E4A9DA89A5F241CC976AA","component_type_id":"1","data_id":"0","data":"Go to the blastdb directory and create the blast database.","order_id":"1","name":"Description","data_by_id":"0","type_id":"1","source_data":{"description":"Go to the blastdb directory and create the blast database."},"is_project":0},{"component_id":"136850","previous_id":"135284","original_id":"0","guid":"8FE756DBFFF04D7ABF974A88C94CC270","previous_guid":"B98F0780EB284E50B3186A368B79FF46","component_type_id":"26","data_id":"9260","data":"","order_id":"2","name":"Note","data_by_id":"1","type_id":"26","source_data":{"annotation_id":"9260","thread_id":"9260","id":"9260","thread_title":"Annotation on step 4 of Building an HPC blast pipeline","uri":"annotation-on-step-4-of-building-an-hpc-blast-pipeline","thread_uri":"annotation-on-step-4-of-building-an-hpc-blast-pipeline","step_id":"135152","protocol_uri":"Building-an-HPC-blast-pipeline-d5a82d","protocol_name":"Building an HPC blast pipeline","protocol_name_html":"Building an HPC blast pipeline","annotation":"go to the blastdb directory<br \/>load irods<br \/>get the peptides from the Gordon Betty Moore Foundation Marine Microbes in iPlant.<br \/>load blast<br \/>create the blast database to compare against<br \/>go up a directory","thread_text":"go to the blastdb directory<br \/>load irods<br \/>get the peptides from the Gordon Betty Moore Foundation Marine Microbes in iPlant.<br \/>load blast<br \/>create the blast database to compare against<br \/>go up a directory","body":"go to the blastdb directory<br \/>load irods<br \/>get the peptides from the Gordon Betty Moore Foundation Marine Microbes in iPlant.<br \/>load blast<br \/>create the blast database to compare against<br \/>go up a directory","is_private":"0","public_protocol":"1","can_edit":0,"can_delete":"0","show_name":"0","created_date":"1447126679","created_on":"1447126679","modified_on":"1447126697","last_updated":"1447126697","profile_image":"https:\/\/s3.amazonaws.com\/pr-journal\/ee4bvtw.jpg","full_name":"Bonnie Hurwitz","affiliation":"University of Arizona","username":"bonnie-hurwitz","email":"bhurwitz@email.arizona.edu","pa_useranme":"bonnie-hurwitz","comments":[]},"is_project":0},{"component_id":"136819","previous_id":"136850","original_id":"0","guid":"BD8E7653CF444C33BEBE794A78492ABA","previous_guid":"8FE756DBFFF04D7ABF974A88C94CC270","component_type_id":"15","data_id":"120","data":null,"order_id":"3","name":"Command","data_by_id":"1","type_id":"15","source_data":{"name":"cd blastdb\nmodule load irods\niget \/iplant\/home\/shared\/imicrobe\/projects\/43\/CAM_PROJ_MarineMicrobes.pep.fa\nmodule load blast\nmakeblastdb -in CAM_PROJ_MarineMicrobes.pep.fa -dbtype prot\ncd ..","description":"","os_name":"","os_version":"","can_edit":"1"},"is_project":0}]},{"id":"135153","is_changed":"0","original_id":"0","is_skipped":"0","is_checked":"0","guid":"45EC969C568D441F923BE56AED1FCCF9","previous_guid":"3079CA462495499EB94F07B153FC3DA2","previous_id":"135152","last_modified":"1502718673","components":[{"component_id":"976108","previous_id":0,"original_id":"0","guid":"123C4D5348DF4E7C9FDE18615E59CA9C","previous_guid":null,"component_type_id":"6","data_id":null,"data":null,"order_id":"0","name":"Section","data_by_id":"0","type_id":"6","source_data":{"section":null},"is_project":0},{"component_id":"135285","previous_id":"976108","original_id":"0","guid":"0A9246E0E9994EDBA4AEA2AEA078F9D3","previous_guid":"123C4D5348DF4E7C9FDE18615E59CA9C","component_type_id":"1","data_id":"0","data":"Copy the input files over from iPlant. \u00a0We will be using the day\/night transcriptomes we discussed last week.<span class=\"s1\"><br \/><\/span>","order_id":"1","name":"Description","data_by_id":"0","type_id":"1","source_data":{"description":"Copy the input files over from iPlant. \u00a0We will be using the day\/night transcriptomes we discussed last week.<span class=\"s1\"><br \/><\/span>"},"is_project":0},{"component_id":"136849","previous_id":"135285","original_id":"0","guid":"5AAC88FAB3E140BD83FA1DB0658A6E04","previous_guid":"0A9246E0E9994EDBA4AEA2AEA078F9D3","component_type_id":"26","data_id":"9259","data":"","order_id":"2","name":"Note","data_by_id":"1","type_id":"26","source_data":{"annotation_id":"9259","thread_id":"9259","id":"9259","thread_title":"Annotation on step 5 of Building an HPC blast pipeline","uri":"annotation-on-step-5-of-building-an-hpc-blast-pipeline","thread_uri":"annotation-on-step-5-of-building-an-hpc-blast-pipeline","step_id":"135153","protocol_uri":"Building-an-HPC-blast-pipeline-d5a82d","protocol_name":"Building an HPC blast pipeline","protocol_name_html":"Building an HPC blast pipeline","annotation":"go to the data directory<br \/>change directories in irods to the day\/night transcriptome data directory<br \/>get the day transcriptome fasta file<br \/>get the night transcriptome fasta file<br \/>go up a directory","thread_text":"go to the data directory<br \/>change directories in irods to the day\/night transcriptome data directory<br \/>get the day transcriptome fasta file<br \/>get the night transcriptome fasta file<br \/>go up a directory","body":"go to the data directory<br \/>change directories in irods to the day\/night transcriptome data directory<br \/>get the day transcriptome fasta file<br \/>get the night transcriptome fasta file<br \/>go up a directory","is_private":"0","public_protocol":"1","can_edit":0,"can_delete":"0","show_name":"0","created_date":"1447126661","created_on":"1447126661","modified_on":"1447126697","last_updated":"1447126697","profile_image":"https:\/\/s3.amazonaws.com\/pr-journal\/ee4bvtw.jpg","full_name":"Bonnie Hurwitz","affiliation":"University of Arizona","username":"bonnie-hurwitz","email":"bhurwitz@email.arizona.edu","pa_useranme":"bonnie-hurwitz","comments":[]},"is_project":0},{"component_id":"136821","previous_id":"136849","original_id":"0","guid":"78138779B22644BE9320F335C012DABA","previous_guid":"5AAC88FAB3E140BD83FA1DB0658A6E04","component_type_id":"15","data_id":"121","data":null,"order_id":"3","name":"Command","data_by_id":"1","type_id":"15","source_data":{"name":"cd data\nicd \/iplant\/home\/shared\/imicrobe\/class\/night_day\niget\u00a0SRR006596_day.fasta\niget\u00a0SRR006597_night.fasta\ncd ..","description":"","os_name":"","os_version":"","can_edit":"1"},"is_project":0}]},{"id":"135154","is_changed":"0","original_id":"0","is_skipped":"0","is_checked":"0","guid":"F2F271F3D0F947749AE9E24D278665DD","previous_guid":"45EC969C568D441F923BE56AED1FCCF9","previous_id":"135153","last_modified":"1502718673","components":[{"component_id":"976109","previous_id":0,"original_id":"0","guid":"11AD54B407AE4BDEA4B900080408A8EB","previous_guid":null,"component_type_id":"6","data_id":null,"data":null,"order_id":"0","name":"Section","data_by_id":"0","type_id":"6","source_data":{"section":null},"is_project":0},{"component_id":"135286","previous_id":"976109","original_id":"0","guid":"68AAAE778DD446A0B4FA9983A8D88163","previous_guid":"11AD54B407AE4BDEA4B900080408A8EB","component_type_id":"1","data_id":"0","data":"You will use two of the\u00a0Perl scripts from the homework\u00a0in the hpc pipeline. \u00a0Put these into the scripts directory.","order_id":"1","name":"Description","data_by_id":"0","type_id":"1","source_data":{"description":"You will use two of the\u00a0Perl scripts from the homework\u00a0in the hpc pipeline. \u00a0Put these into the scripts directory."},"is_project":0},{"component_id":"136848","previous_id":"135286","original_id":"0","guid":"299E4264EA73449B8BDE3089C82A21B6","previous_guid":"68AAAE778DD446A0B4FA9983A8D88163","component_type_id":"26","data_id":"9258","data":"","order_id":"2","name":"Note","data_by_id":"1","type_id":"26","source_data":{"annotation_id":"9258","thread_id":"9258","id":"9258","thread_title":"Annotation on step 6 of Building an HPC blast pipeline","uri":"annotation-on-step-6-of-building-an-hpc-blast-pipeline","thread_uri":"annotation-on-step-6-of-building-an-hpc-blast-pipeline","step_id":"135154","protocol_uri":"Building-an-HPC-blast-pipeline-d5a82d","protocol_name":"Building an HPC blast pipeline","protocol_name_html":"Building an HPC blast pipeline","annotation":"go to the scripts directory<br \/>copy the <a href=\"https:\/\/github.com\/hurwitzlab\/public-protocols\/blob\/master\/abe487\/hpc-blast\/scripts\/01-fasta-splitter.pl\" target=\"_blank\">fasta-splitter <\/a>and <a href=\"https:\/\/github.com\/hurwitzlab\/public-protocols\/blob\/master\/abe487\/hpc-blast\/scripts\/04-blast-search.pl\" target=\"_blank\">blast-search<\/a> perl programs from your homework to the scripts dir.<br \/>note you will need to change the path to point to the location of the scripts in your home directory.","thread_text":"go to the scripts directory<br \/>copy the <a href=\"https:\/\/github.com\/hurwitzlab\/public-protocols\/blob\/master\/abe487\/hpc-blast\/scripts\/01-fasta-splitter.pl\" target=\"_blank\">fasta-splitter <\/a>and <a href=\"https:\/\/github.com\/hurwitzlab\/public-protocols\/blob\/master\/abe487\/hpc-blast\/scripts\/04-blast-search.pl\" target=\"_blank\">blast-search<\/a> perl programs from your homework to the scripts dir.<br \/>note you will need to change the path to point to the location of the scripts in your home directory.","body":"go to the scripts directory<br \/>copy the <a href=\"https:\/\/github.com\/hurwitzlab\/public-protocols\/blob\/master\/abe487\/hpc-blast\/scripts\/01-fasta-splitter.pl\" target=\"_blank\">fasta-splitter <\/a>and <a href=\"https:\/\/github.com\/hurwitzlab\/public-protocols\/blob\/master\/abe487\/hpc-blast\/scripts\/04-blast-search.pl\" target=\"_blank\">blast-search<\/a> perl programs from your homework to the scripts dir.<br \/>note you will need to change the path to point to the location of the scripts in your home directory.","is_private":"0","public_protocol":"1","can_edit":0,"can_delete":"0","show_name":"0","created_date":"1447126645","created_on":"1447126645","modified_on":"1448415548","last_updated":"1448415548","profile_image":"https:\/\/s3.amazonaws.com\/pr-journal\/ee4bvtw.jpg","full_name":"Bonnie Hurwitz","affiliation":"University of Arizona","username":"bonnie-hurwitz","email":"bhurwitz@email.arizona.edu","pa_useranme":"bonnie-hurwitz","comments":[]},"is_project":0},{"component_id":"136823","previous_id":"136848","original_id":"0","guid":"F0A4B4DF0EC142B487BE58F827828B28","previous_guid":"299E4264EA73449B8BDE3089C82A21B6","component_type_id":"15","data_id":"122","data":"","order_id":"3","name":"Command","data_by_id":"1","type_id":"15","source_data":{"name":"cd scripts\ncp \/my-path\/week10\/01-fasta-splitter.pl 01-fasta-splitter.pl\u00a0\ncp \/my-path\/week11\/01-bio-searchio.pl 01-bio-searchio.pl\ncd ..","description":"","os_name":"","os_version":"","can_edit":"1"},"is_project":0}]},{"id":"135893","is_changed":"0","original_id":"0","is_skipped":"0","is_checked":"0","guid":"555EEEA0F3B14818A5BEAE38DA2F3E6A","previous_guid":"F2F271F3D0F947749AE9E24D278665DD","previous_id":"135154","last_modified":"1502718677","components":[{"component_id":"976275","previous_id":0,"original_id":"0","guid":"AA85A667AE3D4CAA8B1CCD0C3F1BC26A","previous_guid":null,"component_type_id":"6","data_id":null,"data":null,"order_id":"0","name":"Section","data_by_id":"0","type_id":"6","source_data":{"section":null},"is_project":0},{"component_id":"136825","previous_id":"976275","original_id":"0","guid":"D2BEE98A1DC446B7A3CD668A936EF96C","previous_guid":"AA85A667AE3D4CAA8B1CCD0C3F1BC26A","component_type_id":"1","data_id":"0","data":"<strong><a href=\"https:\/\/github.com\/hurwitzlab\/public-protocols\/blob\/master\/abe487\/hpc-blast\/config.sh\" target=\"_blank\">config.sh<\/a>:<\/strong> Now we need to create the config.sh script. \u00a0This script will contain all of the environmental variables that the user will be able to modify for running blast. \u00a0The idea of this script is to give the user one place to make any changes they need to run their particular blast job. \u00a0The user should not have to go in and change any of the scripts in the 'scripts' directory. \u00a0Instead, we will capture all of these variable here.<br \/>* note the the config.sh script is in the hpc-blast directory (in the first part of the pipeline), where it is easy for the user to modify it.","order_id":"1","name":"Description","data_by_id":"0","type_id":"1","source_data":{"description":"<strong><a href=\"https:\/\/github.com\/hurwitzlab\/public-protocols\/blob\/master\/abe487\/hpc-blast\/config.sh\" target=\"_blank\">config.sh<\/a>:<\/strong> Now we need to create the config.sh script. \u00a0This script will contain all of the environmental variables that the user will be able to modify for running blast. \u00a0The idea of this script is to give the user one place to make any changes they need to run their particular blast job. \u00a0The user should not have to go in and change any of the scripts in the 'scripts' directory. \u00a0Instead, we will capture all of these variable here.<br \/>* note the the config.sh script is in the hpc-blast directory (in the first part of the pipeline), where it is easy for the user to modify it."},"is_project":0},{"component_id":"136847","previous_id":"136825","original_id":"0","guid":"1D6C5A71E2FA4537929F4B9AD14FF1F7","previous_guid":"D2BEE98A1DC446B7A3CD668A936EF96C","component_type_id":"26","data_id":"9257","data":"","order_id":"2","name":"Note","data_by_id":"1","type_id":"26","source_data":{"annotation_id":"9257","thread_id":"9257","id":"9257","thread_title":"Annotation on step 7 of Building an HPC blast pipeline","uri":"annotation-on-step-7-of-building-an-hpc-blast-pipeline","thread_uri":"annotation-on-step-7-of-building-an-hpc-blast-pipeline","step_id":"135893","protocol_uri":"Building-an-HPC-blast-pipeline-d5a82d","protocol_name":"Building an HPC blast pipeline","protocol_name_html":"Building an HPC blast pipeline","annotation":"set the parameters for the location of the directories<br \/><br \/>set the blast parameters that the user can change (e.g. e-value, blast program, and database to compare against). Note that we created the blast database in a previous step.","thread_text":"set the parameters for the location of the directories<br \/><br \/>set the blast parameters that the user can change (e.g. e-value, blast program, and database to compare against). Note that we created the blast database in a previous step.","body":"set the parameters for the location of the directories<br \/><br \/>set the blast parameters that the user can change (e.g. e-value, blast program, and database to compare against). Note that we created the blast database in a previous step.","is_private":"0","public_protocol":"1","can_edit":0,"can_delete":"0","show_name":"0","created_date":"1447126625","created_on":"1447126625","modified_on":"1447126697","last_updated":"1447126697","profile_image":"https:\/\/s3.amazonaws.com\/pr-journal\/ee4bvtw.jpg","full_name":"Bonnie Hurwitz","affiliation":"University of Arizona","username":"bonnie-hurwitz","email":"bhurwitz@email.arizona.edu","pa_useranme":"bonnie-hurwitz","comments":[]},"is_project":0},{"component_id":"136826","previous_id":"136847","original_id":"0","guid":"0620B55143E445CC92BB90674F9E2923","previous_guid":"1D6C5A71E2FA4537929F4B9AD14FF1F7","component_type_id":"15","data_id":"123","data":"","order_id":"3","name":"Command","data_by_id":"1","type_id":"15","source_data":{"name":"vi config.sh\n\n#enter all of the text below \n------------------------------\n\n#!\/bin\/bash\n\n# directories we need\nexport CWD=$PWD\nexport SCRIPT_DIR=\"$CWD\/scripts\"\nexport FASTA_DIR=\"$CWD\/data\"\nexport STDERR_DIR=\"$CWD\/std-err\"\nexport STDOUT_DIR=\"$CWD\/std-out\"\nexport SPLIT_FA_DIR=\"$FASTA_DIR\/faSplit\"\nexport SPLIT_READ_CT=\"25000\"\nexport BLAST_OUT_DIR=\"$CWD\/blast-results\"\n\n# BLAST parameters\nexport EVAL=\"1e-10\"\nexport BLAST=\"blastx\"\nexport BLASTDB=\"$CWD\/blastdb\/CAM_PROJ_MarineMicrobes.pep.fa\"","description":"","os_name":"","os_version":"","can_edit":"1"},"is_project":0}]},{"id":"135895","is_changed":"0","original_id":"0","is_skipped":"0","is_checked":"0","guid":"FF93FC003F8A49D0929D531D90F9E42E","previous_guid":"555EEEA0F3B14818A5BEAE38DA2F3E6A","previous_id":"135893","last_modified":"1502718677","components":[{"component_id":"976276","previous_id":0,"original_id":"0","guid":"B4FFA02BB08840CABB5F6AAD4E79C26D","previous_guid":null,"component_type_id":"6","data_id":null,"data":null,"order_id":"0","name":"Section","data_by_id":"0","type_id":"6","source_data":{"section":null},"is_project":0},{"component_id":"136829","previous_id":"976276","original_id":"0","guid":"B1BD108AD80B4324B1D2156DD4940783","previous_guid":"B4FFA02BB08840CABB5F6AAD4E79C26D","component_type_id":"1","data_id":"0","data":"<strong><a href=\"https:\/\/github.com\/hurwitzlab\/public-protocols\/blob\/master\/abe487\/hpc-blast\/blast-pipeline.sh\" target=\"_blank\">blast-pipeline.sh<\/a>:<\/strong>Now we will create the \"driver script\", the script that is used to run each part of the pipeline.","order_id":"1","name":"Description","data_by_id":"0","type_id":"1","source_data":{"description":"<strong><a href=\"https:\/\/github.com\/hurwitzlab\/public-protocols\/blob\/master\/abe487\/hpc-blast\/blast-pipeline.sh\" target=\"_blank\">blast-pipeline.sh<\/a>:<\/strong>Now we will create the \"driver script\", the script that is used to run each part of the pipeline."},"is_project":0},{"component_id":"136831","previous_id":"136829","original_id":"0","guid":"2C385816470E418DBB0A18F9D9CA5F40","previous_guid":"B1BD108AD80B4324B1D2156DD4940783","component_type_id":"26","data_id":"9254","data":"","order_id":"2","name":"Note","data_by_id":"1","type_id":"26","source_data":{"annotation_id":"9254","thread_id":"9254","id":"9254","thread_title":"Annotation on step 8 of Building an HPC blast pipeline","uri":"annotation-on-step-8-of-building-an-hpc-blast-pipeline","thread_uri":"annotation-on-step-8-of-building-an-hpc-blast-pipeline","step_id":"135895","protocol_uri":"Building-an-HPC-blast-pipeline-d5a82d","protocol_name":"Building an HPC blast pipeline","protocol_name_html":"Building an HPC blast pipeline","annotation":"Note that steps 1-3 are run on the head node of the cluster, these steps are not compute intensive. These steps set up the environmental variables and split up the fasta files into smaller chunks to run on the cluster. Step 4 runs blast and parses the blast results on the cluster once the blast analysis has finished. Note that these are being sent to compute nodes using the \"qsub\" command, and that the environmental variables that are useful for each step are being sent along as well. Also note that the second step is \"held\" until the first step completes. You can set this to run, only in the case that the prior step completes without errors \"afterok\" or no matter what \"afterany\". The first requires that none of the jobs produces an error. Also note that we are using a job array \"-J 1-NUM_SPLIT_FILES\", where the number of split files is equal to the total split file for that file. Also, note that the qsub commands run shell scripts that execute the actual work.","thread_text":"Note that steps 1-3 are run on the head node of the cluster, these steps are not compute intensive. These steps set up the environmental variables and split up the fasta files into smaller chunks to run on the cluster. Step 4 runs blast and parses the blast results on the cluster once the blast analysis has finished. Note that these are being sent to compute nodes using the \"qsub\" command, and that the environmental variables that are useful for each step are being sent along as well. Also note that the second step is \"held\" until the first step completes. You can set this to run, only in the case that the prior step completes without errors \"afterok\" or no matter what \"afterany\". The first requires that none of the jobs produces an error. Also note that we are using a job array \"-J 1-NUM_SPLIT_FILES\", where the number of split files is equal to the total split file for that file. Also, note that the qsub commands run shell scripts that execute the actual work.","body":"Note that steps 1-3 are run on the head node of the cluster, these steps are not compute intensive. These steps set up the environmental variables and split up the fasta files into smaller chunks to run on the cluster. Step 4 runs blast and parses the blast results on the cluster once the blast analysis has finished. Note that these are being sent to compute nodes using the \"qsub\" command, and that the environmental variables that are useful for each step are being sent along as well. Also note that the second step is \"held\" until the first step completes. You can set this to run, only in the case that the prior step completes without errors \"afterok\" or no matter what \"afterany\". The first requires that none of the jobs produces an error. Also note that we are using a job array \"-J 1-NUM_SPLIT_FILES\", where the number of split files is equal to the total split file for that file. Also, note that the qsub commands run shell scripts that execute the actual work.","is_private":"0","public_protocol":"1","can_edit":0,"can_delete":"0","show_name":"0","created_date":"1447113322","created_on":"1447113322","modified_on":"1447126697","last_updated":"1447126697","profile_image":"https:\/\/s3.amazonaws.com\/pr-journal\/ee4bvtw.jpg","full_name":"Bonnie Hurwitz","affiliation":"University of Arizona","username":"bonnie-hurwitz","email":"bhurwitz@email.arizona.edu","pa_useranme":"bonnie-hurwitz","comments":[]},"is_project":0},{"component_id":"137902","previous_id":"136831","original_id":"0","guid":"D1582A145C8E4EB298E46EBF7C85DA0B","previous_guid":"2C385816470E418DBB0A18F9D9CA5F40","component_type_id":"13","data_id":"9325","data":"","order_id":"3","name":"Comment","data_by_id":"1","type_id":"13","source_data":{"annotation_id":"9325","thread_id":"9325","id":"9325","thread_title":"Annotation on step 8 of Building an HPC blast pipeline","uri":"annotation-on-step-8-of-building-an-hpc-blast-pipeline1","thread_uri":"annotation-on-step-8-of-building-an-hpc-blast-pipeline1","step_id":"135895","protocol_uri":"Building-an-HPC-blast-pipeline-d5a82d","protocol_name":"Building an HPC blast pipeline","protocol_name_html":"Building an HPC blast pipeline","annotation":"If you get the error\u00a0<span style=\"color: #222222; font-family: arial, sans-serif; font-size: 12.8px; line-height: normal;\">\"qsub: Bad GID for job execution\", you should\u00a0double-check your group name. Enter \"va\" on the command line to see which group you are in. For Steps 10 and 11, make sure the first $PBS line is set to THAT group.<\/span>","thread_text":"If you get the error\u00a0<span style=\"color: #222222; font-family: arial, sans-serif; font-size: 12.8px; line-height: normal;\">\"qsub: Bad GID for job execution\", you should\u00a0double-check your group name. Enter \"va\" on the command line to see which group you are in. For Steps 10 and 11, make sure the first $PBS line is set to THAT group.<\/span>","body":"If you get the error\u00a0<span style=\"color: #222222; font-family: arial, sans-serif; font-size: 12.8px; line-height: normal;\">\"qsub: Bad GID for job execution\", you should\u00a0double-check your group name. Enter \"va\" on the command line to see which group you are in. For Steps 10 and 11, make sure the first $PBS line is set to THAT group.<\/span>","is_private":"0","public_protocol":"1","can_edit":0,"can_delete":"0","show_name":"1","created_date":"1447706095","created_on":"1447706095","modified_on":"1447706095","last_updated":"1447706095","profile_image":"\/img\/avatars\/009.png","full_name":"Nicholas Lytal","affiliation":null,"username":"nicholas-lytal","email":"bhurwitz@email.arizona.edu","pa_useranme":"bonnie-hurwitz","comments":[]},"is_project":0},{"component_id":"136836","previous_id":"137907","original_id":"0","guid":"B82A75A9DD8A4D038569E2D41500F665","previous_guid":"D1582A145C8E4EB298E46EBF7C85DA0B","component_type_id":"15","data_id":"126","data":"","order_id":"4","name":"Command","data_by_id":"1","type_id":"15","source_data":{"name":"vi blast-pipeline.sh\n\n#enter all of the text below \n------------------------------\n\n#!\/bin\/sh\n\n# Step1: get the env variables and create a list of files\nsource .\/config.sh\n\n# Step 2: get all of the fasta files for input\ncd \"$FASTA_DIR\"\nexport FILES_LIST=\"$FASTA_DIR\/files-list\"\npwd\nls *.fasta | sed \"s\/^\\.\\\/\/\/\" > $FILES_LIST\n\n# Step 3: split the fasta files into smaller chunks\n$SCRIPT_DIR\/run-fasta-splitter.sh\n\n# Step 4: run blast on each of the file chunks\nwhile read FILE; do\n    export FILE=\"$FILE\"\n    cd $SPLIT_FA_DIR\n    export SPLIT_FILES_LIST=\"$SPLIT_FA_DIR\/split.$FILE\"\n    ls $FILE.* > $SPLIT_FILES_LIST\n    NUM_SPLIT_FILES=$(wc -l $SPLIT_FILES_LIST | cut -d ' ' -f 1)\n\n    ## run blast on each of the smaller chunks against a blast database\n    JOB_ID1=$(qsub -v SCRIPT_DIR,SPLIT_FA_DIR,BLAST,EVAL,BLASTDB,BLAST_OUT_DIR,FILE -N blast -e \"$STDERR_DIR\" -o \"$STDOUT_DIR\" -J 1-$NUM_SPLIT_FILES $SCRIPT_DIR\/run-blast.sh)\n\n    ## parse the blast results for each of the chunked files\n    JOB_ID2=$(qsub -v SCRIPT_DIR,BLAST_OUT_DIR,FILE -W depend=afterany:$JOB_ID1 -e \"$STDERR_DIR\" -o \"$STDOUT_DIR\" -J 1-$NUM_SPLIT_FILES $SCRIPT_DIR\/run-parse-blast.sh)\n\ndone < $FILES_LIST","description":"","os_name":"","os_version":"","can_edit":"1"},"is_project":0}]},{"id":"135900","is_changed":"0","original_id":"0","is_skipped":"0","is_checked":"0","guid":"27FFF7DEAF4C48548C2B35567F766F18","previous_guid":"FF93FC003F8A49D0929D531D90F9E42E","previous_id":"135895","last_modified":"1502718677","components":[{"component_id":"976277","previous_id":0,"original_id":"0","guid":"8615195E3C9340A6A40C32E1C01D4C30","previous_guid":null,"component_type_id":"6","data_id":null,"data":null,"order_id":"0","name":"Section","data_by_id":"0","type_id":"6","source_data":{"section":null},"is_project":0},{"component_id":"136839","previous_id":"976277","original_id":"0","guid":"9D80933A8E194A1DA87C0117BC11BE43","previous_guid":"8615195E3C9340A6A40C32E1C01D4C30","component_type_id":"1","data_id":"0","data":"<strong><a href=\"https:\/\/github.com\/hurwitzlab\/public-protocols\/blob\/master\/abe487\/hpc-blast\/scripts\/run-fasta-splitter.sh\" target=\"_blank\">run-fasta-splitter.sh<\/a>.<\/strong> Create a shell script that runs the fasta splitter perl code.","order_id":"1","name":"Description","data_by_id":"0","type_id":"1","source_data":{"description":"<strong><a href=\"https:\/\/github.com\/hurwitzlab\/public-protocols\/blob\/master\/abe487\/hpc-blast\/scripts\/run-fasta-splitter.sh\" target=\"_blank\">run-fasta-splitter.sh<\/a>.<\/strong> Create a shell script that runs the fasta splitter perl code."},"is_project":0},{"component_id":"136889","previous_id":"136839","original_id":"0","guid":"EBFA652793CE4B16A9D4196E82E6ADA6","previous_guid":"9D80933A8E194A1DA87C0117BC11BE43","component_type_id":"26","data_id":"9263","data":"","order_id":"2","name":"Note","data_by_id":"1","type_id":"26","source_data":{"annotation_id":"9263","thread_id":"9263","id":"9263","thread_title":"Annotation on step 9 of Building an HPC blast pipeline","uri":"annotation-on-step-9-of-building-an-hpc-blast-pipeline","thread_uri":"annotation-on-step-9-of-building-an-hpc-blast-pipeline","step_id":"135900","protocol_uri":"Building-an-HPC-blast-pipeline-d5a82d","protocol_name":"Building an HPC blast pipeline","protocol_name_html":"Building an HPC blast pipeline","annotation":"Note that this script runs on the head node. \u00a0This script is not compute intensive, and we need to create the smaller files first, before we can distribute the data on the cluster as smaller blast jobs.","thread_text":"Note that this script runs on the head node. \u00a0This script is not compute intensive, and we need to create the smaller files first, before we can distribute the data on the cluster as smaller blast jobs.","body":"Note that this script runs on the head node. \u00a0This script is not compute intensive, and we need to create the smaller files first, before we can distribute the data on the cluster as smaller blast jobs.","is_private":"0","public_protocol":"1","can_edit":0,"can_delete":"0","show_name":"0","created_date":"1447127606","created_on":"1447127606","modified_on":"1447263072","last_updated":"1447263072","profile_image":"https:\/\/s3.amazonaws.com\/pr-journal\/ee4bvtw.jpg","full_name":"Bonnie Hurwitz","affiliation":"University of Arizona","username":"bonnie-hurwitz","email":"bhurwitz@email.arizona.edu","pa_useranme":"bonnie-hurwitz","comments":[]},"is_project":0},{"component_id":"136840","previous_id":"136889","original_id":"0","guid":"7263CCB86DDB4D1583B03A3694399DE3","previous_guid":"EBFA652793CE4B16A9D4196E82E6ADA6","component_type_id":"15","data_id":"127","data":"","order_id":"3","name":"Command","data_by_id":"1","type_id":"15","source_data":{"name":"cd scripts\n\nvi run-fasta-splitter.sh \n\n#enter the text below \n\n#!\/bin\/bash\n\nsource \/usr\/share\/Modules\/init\/bash\n\nif [[ ! -d \"$SPLIT_FA_DIR\" ]]; then\n    echo Cannot find faSplit \\\"$SPLIT_FA_DIR\\\"\n    mkdir -p $SPLIT_FA_DIR\nfi\n\nif [[ ! -e \"$FILES_LIST\" ]]; then\n    echo Cannot find files list \\\"$FILES_LIST\\\"\n    exit 1\nfi\n\ncd $FASTA_DIR\nwhile read FILE; do\n   echo $FILE\n   $SCRIPT_DIR\/01-fasta-splitter.pl -n $SPLIT_READ_CT -o $SPLIT_FA_DIR $FILE\ndone < $FILES_LIST","description":"","os_name":"","os_version":"","can_edit":"1"},"is_project":0}]},{"id":"135901","is_changed":"0","original_id":"0","is_skipped":"0","is_checked":"0","guid":"1E4A6FFB05B54BE685526F312F5BD8A1","previous_guid":"27FFF7DEAF4C48548C2B35567F766F18","previous_id":"135900","last_modified":"1502718677","components":[{"component_id":"976278","previous_id":0,"original_id":"0","guid":"63542318FD714E46A5B697F46A45BF7E","previous_guid":null,"component_type_id":"6","data_id":null,"data":null,"order_id":"0","name":"Section","data_by_id":"0","type_id":"6","source_data":{"section":null},"is_project":0},{"component_id":"136841","previous_id":"976278","original_id":"0","guid":"BBDCC5B634524B95863A71D9E0C3BD67","previous_guid":"63542318FD714E46A5B697F46A45BF7E","component_type_id":"1","data_id":"0","data":"<a href=\"https:\/\/github.com\/hurwitzlab\/public-protocols\/blob\/master\/abe487\/hpc-blast\/scripts\/run-blast.sh\" target=\"_blank\">run-blast.sh<\/a>: Create a shell script that runs blast on a compute node.","order_id":"1","name":"Description","data_by_id":"0","type_id":"1","source_data":{"description":"<a href=\"https:\/\/github.com\/hurwitzlab\/public-protocols\/blob\/master\/abe487\/hpc-blast\/scripts\/run-blast.sh\" target=\"_blank\">run-blast.sh<\/a>: Create a shell script that runs blast on a compute node."},"is_project":0},{"component_id":"136870","previous_id":"136841","original_id":"0","guid":"1F61E4562FA14550BD95BADD75C97377","previous_guid":"BBDCC5B634524B95863A71D9E0C3BD67","component_type_id":"26","data_id":"9261","data":"","order_id":"2","name":"Note","data_by_id":"1","type_id":"26","source_data":null,"is_project":0},{"component_id":"136843","previous_id":"136870","original_id":"0","guid":"C5E52C1EDC854906A60FF99DF87B6481","previous_guid":"1F61E4562FA14550BD95BADD75C97377","component_type_id":"15","data_id":"128","data":"","order_id":"3","name":"Command","data_by_id":"1","type_id":"15","source_data":{"name":"vi run-blast.sh\n\n# enter the text below\n\n#!\/bin\/bash\n\n#PBS -W group_list=bhurwitz\n#PBS -q windfall\n#PBS -l jobtype=cluster_only\n#PBS -l select=1:ncpus=2:mem=4gb\n#PBS -l place=pack:shared\n#PBS -l walltime=24:00:00\n#PBS -l cput=24:00:00\n#PBS -M youruser@email.arizona.edu\n#PBS -m bea\n\n# BLAST parameters\nNUM_THREADS=2    # make sure this is requested in the above \"select\"\nDESC=10\nALN=10\nMAX_HSPS=10\n\nmodule load blast\ncd \"$SPLIT_FA_DIR\"\nFASTA=\"$SPLIT_FA_DIR\/$FILE.${PBS_ARRAY_INDEX}\"\n\n# run blast on each file chunk\n$BLAST -query $FASTA -db $BLASTDB -evalue $EVAL -out $BLAST_OUT_DIR\/$FILE.${PBS_ARRAY_INDEX}.blastout -max_hsps $MAX_HSPS -num_descriptions $DESC -num_alignments $ALN -num_threads $NUM_THREADS","description":"","os_name":"","os_version":"","can_edit":"1"},"is_project":0}]},{"id":"135902","is_changed":"0","original_id":"0","is_skipped":"0","is_checked":"0","guid":"FF4D8EE476564A6DAF57961145A763F2","previous_guid":"1E4A6FFB05B54BE685526F312F5BD8A1","previous_id":"135901","last_modified":"1502718677","components":[{"component_id":"976279","previous_id":0,"original_id":"0","guid":"FAB3B976F46443619B251710970FCDFF","previous_guid":null,"component_type_id":"6","data_id":null,"data":null,"order_id":"0","name":"Section","data_by_id":"0","type_id":"6","source_data":{"section":null},"is_project":0},{"component_id":"136844","previous_id":"976279","original_id":"0","guid":"5299E6970E1F49CEA403639D2E543C0E","previous_guid":"FAB3B976F46443619B251710970FCDFF","component_type_id":"1","data_id":"0","data":"<strong><a href=\"https:\/\/github.com\/hurwitzlab\/public-protocols\/blob\/master\/abe487\/hpc-blast\/scripts\/run-parse-blast.sh\" target=\"_blank\">run-parse-blast.sh<\/a>:<\/strong>Create a shell script to parse the blast output that runs on a compute node on the cluster.","order_id":"1","name":"Description","data_by_id":"0","type_id":"1","source_data":{"description":"<strong><a href=\"https:\/\/github.com\/hurwitzlab\/public-protocols\/blob\/master\/abe487\/hpc-blast\/scripts\/run-parse-blast.sh\" target=\"_blank\">run-parse-blast.sh<\/a>:<\/strong>Create a shell script to parse the blast output that runs on a compute node on the cluster."},"is_project":0},{"component_id":"136873","previous_id":"136844","original_id":"0","guid":"03F2EA057C56436A80CFBF803951A505","previous_guid":"5299E6970E1F49CEA403639D2E543C0E","component_type_id":"26","data_id":"9262","data":"","order_id":"2","name":"Note","data_by_id":"1","type_id":"26","source_data":{"annotation_id":"9262","thread_id":"9262","id":"9262","thread_title":"Annotation on step 11 of Building an HPC blast pipeline","uri":"annotation-on-step-11-of-building-an-hpc-blast-pipeline","thread_uri":"annotation-on-step-11-of-building-an-hpc-blast-pipeline","step_id":"135902","protocol_uri":"Building-an-HPC-blast-pipeline-d5a82d","protocol_name":"Building an HPC blast pipeline","protocol_name_html":"Building an HPC blast pipeline","annotation":"Like the previous script the PBS commands at the beginning of the script indicate the resource needed to run the job. \u00a0Also note that we need to load blast and perl, to access blast commands and the version of perl with bioperl installed. \u00a0Also note that we are using the variable ${PBS_ARRAY_INDEX}. \u00a0This variable stores information about which blast job we are running from 1-NUM_SPLIT_FILES that is specified in the driver script with a \"-J\"","thread_text":"Like the previous script the PBS commands at the beginning of the script indicate the resource needed to run the job. \u00a0Also note that we need to load blast and perl, to access blast commands and the version of perl with bioperl installed. \u00a0Also note that we are using the variable ${PBS_ARRAY_INDEX}. \u00a0This variable stores information about which blast job we are running from 1-NUM_SPLIT_FILES that is specified in the driver script with a \"-J\"","body":"Like the previous script the PBS commands at the beginning of the script indicate the resource needed to run the job. \u00a0Also note that we need to load blast and perl, to access blast commands and the version of perl with bioperl installed. \u00a0Also note that we are using the variable ${PBS_ARRAY_INDEX}. \u00a0This variable stores information about which blast job we are running from 1-NUM_SPLIT_FILES that is specified in the driver script with a \"-J\"","is_private":"0","public_protocol":"1","can_edit":0,"can_delete":"0","show_name":"0","created_date":"1447126697","created_on":"1447126697","modified_on":"1447263072","last_updated":"1447263072","profile_image":"https:\/\/s3.amazonaws.com\/pr-journal\/ee4bvtw.jpg","full_name":"Bonnie Hurwitz","affiliation":"University of Arizona","username":"bonnie-hurwitz","email":"bhurwitz@email.arizona.edu","pa_useranme":"bonnie-hurwitz","comments":[]},"is_project":0},{"component_id":"136846","previous_id":"136873","original_id":"0","guid":"B18A08065F314146BC5A813E28F06C05","previous_guid":"03F2EA057C56436A80CFBF803951A505","component_type_id":"15","data_id":"129","data":null,"order_id":"3","name":"Command","data_by_id":"1","type_id":"15","source_data":{"name":"vi run-parse-blast.sh\n\n# enter the text below\n\n#!\/bin\/bash\n\n#PBS -W group_list=bhurwitz\n#PBS -q windfall\n#PBS -l jobtype=cluster_only\n#PBS -l select=1:ncpus=2:mem=4gb\n#PBS -l place=pack:shared\n#PBS -l walltime=24:00:00\n#PBS -l cput=24:00:00\n#PBS -M youruser@email.arizona.edu\n#PBS -m bea\n\nmodule load blast\ncd $BLAST_OUT_DIR\nBLOUT=\"$BLAST_OUT_DIR\/$FILE.${PBS_ARRAY_INDEX}.blastout\"\necho File \\\"$FILE.${PBS_ARRAY_INDEX}.blastout\\\"\n$SCRIPT_DIR\/04-blast-search.pl $BLOUT > $BLOUT.parsed","description":"","os_name":"","os_version":"","can_edit":"1"},"is_project":0}]},{"id":"135912","is_changed":"0","original_id":"0","is_skipped":"0","is_checked":"0","guid":"A032FD6E44354EB0951E7CF437A5E8AC","previous_guid":"FF4D8EE476564A6DAF57961145A763F2","previous_id":"135902","last_modified":"1502718677","components":[{"component_id":"976280","previous_id":0,"original_id":"0","guid":"D41EC01706F24C79993C83158AACA880","previous_guid":null,"component_type_id":"6","data_id":null,"data":null,"order_id":"0","name":"Section","data_by_id":"0","type_id":"6","source_data":{"section":null},"is_project":0},{"component_id":"136876","previous_id":"976280","original_id":"0","guid":"154BB6DC1479429DBD09B8B73185EA87","previous_guid":"D41EC01706F24C79993C83158AACA880","component_type_id":"1","data_id":"0","data":"<strong><a href=\"https:\/\/github.com\/hurwitzlab\/public-protocols\/blob\/master\/abe487\/hpc-blast\/scripts\/04-blast-search.pl\" target=\"_blank\">04-blast-search.pl<\/a>:<\/strong> modify the blast search script.<br \/>Update the e-value to be less stringent.<br \/>Modify the Perl script 04-blast-search.pl\u00a0to include additional information about the hit.<br \/><br \/>","order_id":"1","name":"Description","data_by_id":"0","type_id":"1","source_data":{"description":"<strong><a href=\"https:\/\/github.com\/hurwitzlab\/public-protocols\/blob\/master\/abe487\/hpc-blast\/scripts\/04-blast-search.pl\" target=\"_blank\">04-blast-search.pl<\/a>:<\/strong> modify the blast search script.<br \/>Update the e-value to be less stringent.<br \/>Modify the Perl script 04-blast-search.pl\u00a0to include additional information about the hit.<br \/><br \/>"},"is_project":0},{"component_id":"136877","previous_id":"136876","original_id":"0","guid":"A5504FF579C9437A960E7C6E4A7552C7","previous_guid":"154BB6DC1479429DBD09B8B73185EA87","component_type_id":"15","data_id":"130","data":"","order_id":"2","name":"Command","data_by_id":"1","type_id":"15","source_data":{"name":"# make a few modifications in the 01-bio-searchio.pl script\n# change the e-value in the script\nmy $min = 1e-10;\n\n# update the print statement\n# add additional information about the hit.\n\nsay join \"\\t\",\n                    $result->query_name, \n                    $hit->name, \n                    $hit->description, \n                    $hsp->percent_identity, \n                    $hsp->length('total'), \n                    $hsp->evalue;","description":"","os_name":"","os_version":"","can_edit":"1"},"is_project":0}]},{"id":"135914","is_changed":"0","original_id":"0","is_skipped":"0","is_checked":"0","guid":"A12DB777CE8D43CAB4D43AFD7D02C3C7","previous_guid":"A032FD6E44354EB0951E7CF437A5E8AC","previous_id":"135912","last_modified":"1502718677","components":[{"component_id":"976281","previous_id":0,"original_id":"0","guid":"861613E020224CE3AEF141B203B614F7","previous_guid":null,"component_type_id":"6","data_id":null,"data":null,"order_id":"0","name":"Section","data_by_id":"0","type_id":"6","source_data":{"section":null},"is_project":0},{"component_id":"136880","previous_id":"976281","original_id":"0","guid":"739DFECFB2434E59A664958B51D4710D","previous_guid":"861613E020224CE3AEF141B203B614F7","component_type_id":"1","data_id":"0","data":"Make all of the scripts executable and then run the pipeline.<br \/>If you don't get any errors, the pipeline will take &lt;1 day to run.","order_id":"1","name":"Description","data_by_id":"0","type_id":"1","source_data":{"description":"Make all of the scripts executable and then run the pipeline.<br \/>If you don't get any errors, the pipeline will take &lt;1 day to run."},"is_project":0},{"component_id":"136881","previous_id":"136880","original_id":"0","guid":"84E34FFFADD545BD9002033FB4F30C33","previous_guid":"739DFECFB2434E59A664958B51D4710D","component_type_id":"15","data_id":"132","data":"","order_id":"2","name":"Command","data_by_id":"1","type_id":"15","source_data":{"name":"chmod 755 *sh *pl\ncd ..\nchmod *sh\n.\/blast-pipeline.sh","description":"make sure your scripts are executable for before running","os_name":"","os_version":"","can_edit":"1"},"is_project":0}]},{"id":"135915","is_changed":"0","original_id":"0","is_skipped":"0","is_checked":"0","guid":"DD342DAA3A494103A20732139C8E8BBB","previous_guid":"A12DB777CE8D43CAB4D43AFD7D02C3C7","previous_id":"135914","last_modified":"1502718677","components":[{"component_id":"976282","previous_id":0,"original_id":"0","guid":"F6C181176A0C469B8ECAA89ED9B1CA6D","previous_guid":null,"component_type_id":"6","data_id":null,"data":null,"order_id":"0","name":"Section","data_by_id":"0","type_id":"6","source_data":{"section":null},"is_project":0},{"component_id":"136882","previous_id":"976282","original_id":"0","guid":"C169CD936AD747DE945C3DE425AE46D1","previous_guid":"F6C181176A0C469B8ECAA89ED9B1CA6D","component_type_id":"1","data_id":"0","data":"Check to see if the pipeline is running","order_id":"1","name":"Description","data_by_id":"0","type_id":"1","source_data":{"description":"Check to see if the pipeline is running"},"is_project":0},{"component_id":"136883","previous_id":"136882","original_id":"0","guid":"4E8D70CA1437440F8AB5313E85F3B261","previous_guid":"C169CD936AD747DE945C3DE425AE46D1","component_type_id":"15","data_id":"133","data":null,"order_id":"2","name":"Command","data_by_id":"1","type_id":"15","source_data":{"name":"qstat -u username","description":"for me this command is:\nqstat -u bhurwitz","os_name":"","os_version":"","can_edit":"1"},"is_project":0}]},{"id":"135916","is_changed":"0","original_id":"0","is_skipped":"0","is_checked":"0","guid":"3727C767D8884D68934A9C38D66E0AFD","previous_guid":"DD342DAA3A494103A20732139C8E8BBB","previous_id":"135915","last_modified":"1502718677","components":[{"component_id":"976283","previous_id":0,"original_id":"0","guid":"DA2D7BA7718846E9AA0CD4263FFC779D","previous_guid":null,"component_type_id":"6","data_id":null,"data":null,"order_id":"0","name":"Section","data_by_id":"0","type_id":"6","source_data":{"section":null},"is_project":0},{"component_id":"136884","previous_id":"976283","original_id":"0","guid":"092DF306D9714732BC2B2FF54ECBB60D","previous_guid":"DA2D7BA7718846E9AA0CD4263FFC779D","component_type_id":"1","data_id":"0","data":"Once the pipeline is finished running (and you don't see the jobs listed under qstat), check for std-errors and std-out.<br \/>Note you can check while the pipeline is running too.","order_id":"1","name":"Description","data_by_id":"0","type_id":"1","source_data":{"description":"Once the pipeline is finished running (and you don't see the jobs listed under qstat), check for std-errors and std-out.<br \/>Note you can check while the pipeline is running too."},"is_project":0},{"component_id":"136885","previous_id":"136884","original_id":"0","guid":"65FC9B18F7834E18947295F27541ECE4","previous_guid":"092DF306D9714732BC2B2FF54ECBB60D","component_type_id":"15","data_id":"134","data":null,"order_id":"2","name":"Command","data_by_id":"1","type_id":"15","source_data":{"name":"cd std-err\nls -1\n# you should see zero length files\ncd ..\ncd std-out\nls -l\n# you should see some description about the amount of compute time used per job","description":"","os_name":"","os_version":"","can_edit":"1"},"is_project":0}]},{"id":"135917","is_changed":"0","original_id":"0","is_skipped":"0","is_checked":"0","guid":"882DCAB0488D40CF811A451D460D1E20","previous_guid":"3727C767D8884D68934A9C38D66E0AFD","previous_id":"135916","last_modified":"1502718677","components":[{"component_id":"976284","previous_id":0,"original_id":"0","guid":"7C2E743B347E4258BB5080FF4D09D24C","previous_guid":null,"component_type_id":"6","data_id":null,"data":null,"order_id":"0","name":"Section","data_by_id":"0","type_id":"6","source_data":{"section":null},"is_project":0},{"component_id":"136886","previous_id":"976284","original_id":"0","guid":"9ADF1DC7D7544303A639836BE19B0284","previous_guid":"7C2E743B347E4258BB5080FF4D09D24C","component_type_id":"1","data_id":"0","data":"Now you try.<br \/>See if you can update the pipeline to add one final step that puts all of the parsed blast output into a single file for each of the original fasta files.<br \/>Note that you can comment out the parts of the blast-pipeline.sh that you have already run in the steps above, to test your code. \u00a0Otherwise, these will run again.<br \/>Also, before you run this final step, make sure the blast parsing is complete.<br \/>Can this run on the head node, or should we run this on a compute node?<br \/>The complete pipeline can be found in github <a href=\"https:\/\/github.com\/hurwitzlab\/public-protocols\/tree\/master\/abe487\/hpc-blast\" target=\"_blank\">here<\/a>.<br \/><br \/><br \/>","order_id":"1","name":"Description","data_by_id":"0","type_id":"1","source_data":{"description":"Now you try.<br \/>See if you can update the pipeline to add one final step that puts all of the parsed blast output into a single file for each of the original fasta files.<br \/>Note that you can comment out the parts of the blast-pipeline.sh that you have already run in the steps above, to test your code. \u00a0Otherwise, these will run again.<br \/>Also, before you run this final step, make sure the blast parsing is complete.<br \/>Can this run on the head node, or should we run this on a compute node?<br \/>The complete pipeline can be found in github <a href=\"https:\/\/github.com\/hurwitzlab\/public-protocols\/tree\/master\/abe487\/hpc-blast\" target=\"_blank\">here<\/a>.<br \/><br \/><br \/>"},"is_project":0}]},{"id":"135918","is_changed":"0","original_id":"0","is_skipped":"0","is_checked":"0","guid":"80F266D157AA45308A2465F1F4962601","previous_guid":"882DCAB0488D40CF811A451D460D1E20","previous_id":"135917","last_modified":"1502718677","components":[{"component_id":"976285","previous_id":0,"original_id":"0","guid":"C8F29E52C52A4C2E9079D9A4D4967062","previous_guid":null,"component_type_id":"6","data_id":null,"data":null,"order_id":"0","name":"Section","data_by_id":"0","type_id":"6","source_data":{"section":null},"is_project":0},{"component_id":"136887","previous_id":"976285","original_id":"0","guid":"87471B31ACAC49DF95623FA841164E25","previous_guid":"C8F29E52C52A4C2E9079D9A4D4967062","component_type_id":"1","data_id":"0","data":"Commit your code to your own github abe487 repository using the directory:<br \/>hpc-blast","order_id":"1","name":"Description","data_by_id":"0","type_id":"1","source_data":{"description":"Commit your code to your own github abe487 repository using the directory:<br \/>hpc-blast"},"is_project":0}]}]}